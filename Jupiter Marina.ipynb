{"cells":[{"metadata":{},"cell_type":"markdown","source":"KABAHITA JUPITER MARINA\n2019/HD07/24828U\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing data\ntest_data = pd.read_csv(\"/kaggle/input/ace-class-assignment/Test.csv\", header=0, sep=\",\")\namp_train = pd.read_csv(\"/kaggle/input/ace-class-assignment/AMP_TrainSet.csv\", header=0, sep=\",\")\namp_train.head()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## General data attributes and descriptive statistics"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Describing general data attributes\ntrain_dim=amp_train.shape #gets the dimensions of the tranining dataset\ntest_dim= test_data.shape #gets the dimensions of the tesing dataset\nprint(train_dim)\nprint(test_dim)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the test data has one attribute less than the train data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"atr_types=amp_train.dtypes #gets the data type for each column in training dataset\n\natr_types\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amp_train.isnull().sum() # gets the sum of the missing values/observations in each column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" All attributes have complete observations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Descriptive statistics \nstats=amp_train.describe()\nstats","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the summary statistics, its visible that some of the attributes like FULL_CHARGE, FULL_AcidicMolPerc and\tFULL_OOBM850104  have outlier values basing on the values of the 75% quartile and maximum values "},{"metadata":{},"cell_type":"markdown","source":"# Class distributions\n\nSometimes, observations from the different classes may not be equal, these may need special handling, so its important to note the class distributions, as if they are uneven, they may bias our model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CLass distibutions \ncdists= amp_train.groupby('CLASS').size() # groups the observation by the column of class, and counts all the observations including null values\nprint(cdists)\n\n#plots to visualize the class distribution\namp_train.groupby('CLASS').size().plot(kind=\"pie\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The observations from each class seem8 to be equal"},{"metadata":{},"cell_type":"markdown","source":"# Correlation between the different attributes\nBasically, we need to examine our attributes for correlation as highly correlated attributes present the same data to the algorithm. Removing one may speed learning of the algorithm (less dimensions more speed) and also prevent overfitting of the algorithm"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation between attributes \ncorrelations = amp_train.corr(method=\"pearson\") # calculates pairwaise correlation for the attributes \ncorrelations\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"FULL_AURR980107 and FULL_AcidicMolPerc have a correlation coefficent of 0.79, this might mean these two attributes may be some what correlated. Same goes for AS_DAYM780201 and FULL_DAYM780201 (correlation coefficient is 0.894191)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plots to visualize the correlations\nfrom matplotlib import rcParams\nsns.heatmap(correlations, annot=True)\nrcParams['figure.figsize'] = (11.7,8.27)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data skewness\n\nMost machine learning algorithms assume that data from the attributes is normally distributed, so identifying attributes with data that has a left or right skew, can be important as this can be easily corrected"},{"metadata":{"trusted":true},"cell_type":"code","source":"sk = amp_train.skew() # calculates the skew for each attribute\nsk","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Negative values like those of FULL_DAYM780201, FULL_OOBM850104,AS_DAYM780201, AS_FUKS010112, indicate that these attributes have values skewed more to the left\nValues closer to zero are indicative of a less or no skew, while positive values would mean that that particular attribute is skewed more to the right"},{"metadata":{},"cell_type":"markdown","source":" # Visualising data distributions with plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot one, histogram to show the distributions\namp_train.hist(layout=(4,3), figsize=(16,16))\nplt.subplots_adjust(wspace=0.4, hspace=0.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot two density plots can show the distributions better\namp_train.plot(kind=\"density\",subplots=True,layout=(4,3),sharex=False,sharey=False, figsize=(16,16))\n#amp_train.plot(kind=\"density\",subplots=False,layout=(4,3),sharex=True,sharey=True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Distributions for AS_MeanAmphiMoment,FULL_AcidicMolPerc and NT_EFC195 dont look so good"},{"metadata":{},"cell_type":"markdown","source":"# Data transformations\nUsing squaring to transform the attributes with negative values into postives"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nneg1=amp_train.iloc[:,0]\ntneg1=neg1**2\ntneg1.plot(kind=\"density\")\n\namp_train.iloc[:,0]=tneg1\n\nneg2=amp_train.iloc[:,5]\ntneg2=neg2**2\ntneg2.plot(kind=\"density\")\namp_train.iloc[:,5]=tneg2\n\n## test\nneg3=test_data.iloc[:,0]\ntneg3=neg3**2\ntneg3.plot(kind=\"density\")\ntest_data.iloc[:,0]=tneg3\n\n\n\nneg4=test_data.iloc[:,5]\ntneg4=neg4**2\ntneg4.plot(kind=\"density\")\ntest_data.iloc[:,5]=tneg4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":" #test one selecting out features with low variance\nfrom sklearn.feature_selection import VarianceThreshold\nsel = VarianceThreshold(threshold=(.8 * (1 - .8)))\nk=sel.fit_transform(amp_train)\nnames=amp_train.columns[sel.get_support(indices=True)]\nprint(k.shape)\namp_train2=pd.DataFrame(k,columns=names)\namp_train2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After selecting out features with low variance, only 8 attribute remained "},{"metadata":{"trusted":true},"cell_type":"code","source":"#test two using sklearn with a chi square test\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\ntest_array = amp_train2.values\n\ntest_atr = test_array[:,0:7]\nclass_atr = test_array[:,7]\n\n\ntest = SelectKBest(score_func=chi2, k=5)\nfit = test.fit(test_atr, class_atr)\n\n\nprint(fit.scores_)\nfeatures = fit.transform(test_atr)\nnames2=amp_train2.columns[fit.get_support(indices=True)]\namp_train3=pd.DataFrame(features,columns=names2)\namp_train3.iloc[:5,]\nprint(names2)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test three Recursive feature elimination\n\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import  RandomForestClassifier\n\nmodel1 = LogisticRegression()\nmodel2=RandomForestClassifier()\n\nrfe = RFE(model1, 5)\nfit2 = rfe.fit(test_atr, class_atr)\nfeatures2 = fit2.transform(test_atr)\n\nrfe2= RFE(model2, 5)\nfit3 = rfe2.fit(test_atr, class_atr)\n\n\n\n\nnames3= set(amp_train2.columns[fit2.get_support(indices=True)])\n\nnames4= set(amp_train2.columns[fit3.get_support(indices=True)])\n\nnames2=set(names2)\n\ncomn=names2&names3&names4 ### identifies features common to all the feature selection methods used\ncomn\n\nimport collections\n\ncomn=collections.deque(comn)\ncomn.appendleft(\"FULL_Charge\")\ncomn\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Getting the indices of the chosen attributes"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nindice=[]\n\nfor index,name in enumerate(amp_train.columns):\n    for sub_name in comn:\n        if name==sub_name:\n            indice.append(index)\nindice\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Subsetting the data for the chosen attributes "},{"metadata":{"trusted":true},"cell_type":"code","source":"amp_train = pd.read_csv(\"/kaggle/input/ace-class-assignment/AMP_TrainSet.csv\", header=0, sep=\",\")\n\n\ntest_amp =amp_train.iloc[:,[0,1,3,5,7,11]]\n\ntest_amp.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic regression using cross validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX=test_amp.iloc[:,0:5]\nY=test_amp.iloc[:,5]\nfolds=10\nkfold = KFold(n_splits=folds, random_state=7, shuffle=True,)\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=kfold)\n\nprint((\"Accuracy: %.3f%% (%.3f%%)\") % (results.mean()*100.0, results.std()*100.0))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model one\n ## Logistic regression with a test train split using 5 features\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_amp =amp_train.values[:,[0,1,3,5,7,11]]\nfrom sklearn.metrics import matthews_corrcoef\nX=test_amp[:,0:5]\nY=test_amp[:,5]\n\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel1 = LogisticRegression()\nmodel1.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model1.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult1 = model1.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result1*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model1.predict(X_test),Y_test))\nmcc1=matthews_corrcoef(model1.predict(X_test),Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Model two\n## Gausian/Naive Bayes using five features "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_amp =amp_train.values[:,[0,1,3,5,7,11]]\nfrom sklearn.metrics import matthews_corrcoef\nX=test_amp[:,0:5]\nY=test_amp[:,5]\n\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel2 = GaussianNB()\nmodel2.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model2.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult2 = model2.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result2*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model2.predict(X_test),Y_test))\nmcc2=matthews_corrcoef(model2.predict(X_test),Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model three\n## Linear Discriminant Analysis using five features "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_amp =amp_train.values[:,[0,1,3,5,7,11]]\nfrom sklearn.metrics import matthews_corrcoef\nX=test_amp[:,0:5]\nY=test_amp[:,5]\n\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel3=LinearDiscriminantAnalysis()\nmodel3.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model3.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult3 = model3.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result3*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model3.predict(X_test),Y_test))\n\nmcc3=matthews_corrcoef(model3.predict(X_test),Y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model four \n ## Support Vector Machines with five features"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_amp =amp_train.values[:,[0,1,3,5,7,11]]\nfrom sklearn.metrics import matthews_corrcoef\nX=test_amp[:,0:5]\nY=test_amp[:,5]\n\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel4=SVC()\nmodel4.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model4.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult4 = model4.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result4*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model4.predict(X_test),Y_test))\n\n\nmcc4=matthews_corrcoef(model4.predict(X_test),Y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model 5\n ## K-Nearest neighbours with five features\n "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodel5 = KNeighborsClassifier(n_neighbors=5)\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel5.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model5.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult5 = model5.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result5*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model5.predict(X_test),Y_test))\n\nmcc5=matthews_corrcoef(model5.predict(X_test),Y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model six\n ## Centroid clasifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nmodel6 = NearestCentroid()\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel6.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model6.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult6 = model6.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result6*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model6.predict(X_test),Y_test))\n\nmcc6=matthews_corrcoef(model6.predict(X_test),Y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model seven\n\n## Decision trees with five features \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel7=tree.DecisionTreeClassifier()\nmodel7.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model7.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult7 = model7.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result7*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model7.predict(X_test),Y_test))\nmcc7=matthews_corrcoef(model7.predict(X_test),Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model eight \n## Randomised tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nmodel8 =RandomForestClassifier()\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel8.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model8.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult8 = model8.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result8*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model8.predict(X_test),Y_test))\n\n\nmcc8=matthews_corrcoef(model8.predict(X_test),Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model nine \n ## Gradient tree boosting\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nmodel9 =GradientBoostingClassifier()\n\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel9.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model9.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult9 = model9.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result9*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model9.predict(X_test),Y_test))\n\nmcc9=matthews_corrcoef(model9.predict(X_test),Y_test)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model ten\n## Stochastic Gradient Descent "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nmodel10 = SGDClassifier()\n\n#Training data spliting \n\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed, shuffle=True)\n\n#model training \n\nmodel10.fit(X_train, Y_train)\n\n# predicting\n\npredicted = model10.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult10 = model10.score(X_test, Y_test)\n\n# Results accuracy \n\nprint(\"Accuracy: \",  (result10*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model10.predict(X_test),Y_test))\n\n\nmcc10=matthews_corrcoef(model10.predict(X_test),Y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare=[result1,result2,result3,result4,result5,result6,result7,result8,result9,result10]\n\ncompare=pd.DataFrame(compare).T\n\ncompare=compare.rename(columns={0:\"LGR\", 1:\"GNB\", 2:\"LDN\", 3:\"SVM\", 4:\"KNN\", 5:\"CCL\", 6:\"DCS\", 7:\"RDT\", 8:\"GBT\", 9:\"SGD\"})\n\ncompareMCC=[mcc1,mcc2,mcc3,mcc4,mcc5,mcc6,mcc7,mcc8,mcc9,mcc10]\ncompareMCC=pd.DataFrame(compareMCC).T\ncompareMCC=compareMCC.rename(columns={0:\"LGR\", 1:\"GNB\", 2:\"LDN\", 3:\"SVM\", 4:\"KNN\", 5:\"CCL\", 6:\"DCS\", 7:\"RDT\", 8:\"GBT\", 9:\"SGD\"})\n\ncompare=compare.append(compareMCC)\n#compare.plot(kind=\"box\")\n#plt.plot(\"Mean of MCC and Accuracy\",\"Different models\", data=compare)\n\n\ncompare=compare.values\n\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.boxplot(compare)\nplt.xticks([1, 2, 3,4,5,6,7,8,9,10], [\"LGR\",\"GNB\",\"LDN\",\"SVM\",\"KNN\",\"CCL\",\"DCS\",\"RDT\",\"GBT\",\"SGD\"])\n\n\n\nax.set_title('A comparison of the different Accuracies and MCC from the different Models')\nax.set_xlabel('The different Models')\nax.set_ylabel('Mean of Accuracy and MCC')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting from the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest_data = pd.read_csv(\"/kaggle/input/ace-class-assignment/Test.csv\", header=0, sep=\",\")\ntest_data2=test_data.values[:,[0,1,3,5,7]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions from logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.fit(X,Y) ## retrains the algorithm again on the entire train data set\nkj_results=model1.predict(test_data2)\n\ndf = pd.DataFrame(kj_results)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\ndf.to_csv(\"kjLGR.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score from the leader board using this prediction is 0.82503"},{"metadata":{},"cell_type":"markdown","source":"## Predicting using Gausssian"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.fit(X,Y) ## retrains the algorithm again on the entire train data set\nkj_results=model2.predict(test_data2)\n\ndf = pd.DataFrame(kj_results)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\ndf.to_csv(\"kjGNB.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score on leader board using this prediction was 0.84591"},{"metadata":{},"cell_type":"markdown","source":"# Predicting using Support Vector Machines  "},{"metadata":{"trusted":true},"cell_type":"code","source":"model4.fit(X,Y) ## retrains the algorithm again on the entire train data set\nkj_results=model4.predict(test_data2)\n\ndf = pd.DataFrame(kj_results)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\ndf.to_csv(\"kjSVM.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score on leader board using this prediction was 0.82136"},{"metadata":{},"cell_type":"markdown","source":"## Predicting using the randomised tree classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model8.fit(X,Y) ## retrains the algorithm again on the entire train data set\nkj_results=model8.predict(test_data2)\n\ndf = pd.DataFrame(kj_results)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\ndf.to_csv(\"kjRDT.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score on leader board using this prediction was 0.80561"},{"metadata":{},"cell_type":"markdown","source":"## Predicting using the Gradient tree boosting classifier "},{"metadata":{"trusted":true},"cell_type":"code","source":"model9.fit(X,Y) ## retrains the algorithm again on the entire train data set\nkj_results=model9.predict(test_data2)\n\ndf = pd.DataFrame(kj_results)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\ndf.to_csv(\"kjGBT.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score on leader board using this prediction was 0.79678"},{"metadata":{},"cell_type":"markdown","source":"Random forest and Gradient boosting classifiers had the highest accuracies during training but gave the least scores on the leader board\n\nGausian gave the highest score"},{"metadata":{},"cell_type":"markdown","source":"# More with the gausian "},{"metadata":{},"cell_type":"markdown","source":"## Using gausian with more features"},{"metadata":{},"cell_type":"markdown","source":"## Using gausian with eight features "},{"metadata":{"trusted":true},"cell_type":"code","source":"amp_train = pd.read_csv(\"/kaggle/input/ace-class-assignment/AMP_TrainSet.csv\", header=0, sep=\",\")\ntest_data = pd.read_csv(\"/kaggle/input/ace-class-assignment/Test.csv\", header=0, sep=\",\")\n\n#selecting out features with low variance\nfrom sklearn.feature_selection import VarianceThreshold\nsel = VarianceThreshold(threshold=(.8 * (1 - .8)))\nk=sel.fit_transform(amp_train)\nnames=amp_train.columns[sel.get_support(indices=True)]\nprint(k.shape)\namp_train2=pd.DataFrame(k,columns=names)\n#print(amp_train2)\n\nn=sel.fit_transform(test_data)\nnames2=test_data.columns[sel.get_support(indices=True)]\ntest_data=pd.DataFrame(n,columns=names2)\ntest_data2=test_data.values\n\n#print(test_data)\n\n### data \ntest_amp =amp_train2.values\nX=test_amp[:,0:7]\nY=test_amp[:,7]\n\n\n\n\n#model\nmodel=GaussianNB()\nfrom sklearn.metrics import matthews_corrcoef\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\nrandom_state=seed, shuffle=\"True\")\nmodel.fit(X_train, Y_train)\npredicted = model.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult = model.score(X_test, Y_test)\nprint(\"Accuracy: \",  (result*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model.predict(X_test),Y_test))  \nmodel.fit(X,Y)\nkj_resultsg8=model.predict(test_data)\n\n\n#### results \n\ndf = pd.DataFrame(kj_resultsg8)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\n\ndf.to_csv(\"kjGNB8.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MCC value for the Gaussian with 8 features and that with 5 features are almost the same, but the leaderboard score using the gausian with 8 features was 0.86379, which is an improvement over the 0.84 score from the five features"},{"metadata":{},"cell_type":"markdown","source":"## Using gaussian with all attributes "},{"metadata":{"trusted":true},"cell_type":"code","source":"amp_train = pd.read_csv(\"/kaggle/input/ace-class-assignment/AMP_TrainSet.csv\", header=0, sep=\",\")\ntest_data = pd.read_csv(\"/kaggle/input/ace-class-assignment/Test.csv\", header=0, sep=\",\")\n\n\n### data \ntest_amp =amp_train.values\nX=test_amp[:,0:11]\nY=test_amp[:,11]\n\n\n#model\nmodel=GaussianNB()\nfrom sklearn.metrics import matthews_corrcoef\ntest_size = 0.4\nseed = 42\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\nrandom_state=seed)\nmodel.fit(X_train, Y_train)\npredicted = model.predict(X_test)\nmatrix = confusion_matrix(Y_test, predicted)\nresult = model.score(X_test, Y_test)\nprint(\"Accuracy: \",  (result*100.0))\nprint(matrix)\nprint('MCC: ', matthews_corrcoef(model.predict(X_test),Y_test))  \nmodel.fit(X,Y)\n\nkj_resultsg12=model.predict(test_data)\n\n\n#### results \n\ndf = pd.DataFrame(kj_resultsg12)\ndf.columns = ['CLASS']\ndf.index.name = 'Index'\ndf['CLASS']=df['CLASS'].map({0.0:False,1.0:True})\n\ndf.to_csv(\"kjGNB11.csv\")\ndf[\"CLASS\"].unique()\nprint(df.groupby(\"CLASS\").size()[0].sum())\nprint(df.groupby(\"CLASS\").size()[1].sum())\ndf['CLASS'].value_counts()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score from the leaderboard using all features was 0.99559"},{"metadata":{},"cell_type":"markdown","source":"References\n\n\n1. https://realpython.com/logistic-regression-python/\n2. https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_extra_trees.htm\n3. https://stackabuse.com/gradient-boosting-classifiers-in-python-with-scikit-learn/\n4. https://machinelearningmastery.com/stochastic-gradient-boosting-xgboost-scikit-learn-python/\n5. https://machinelearningmastery.com/stochastic-gradient-boosting-xgboost-scikit-learn-python/\n6. https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n7. https://machinelearningmastery.com/master-machine-learning-algorithms/\n8. https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n9. https://github.com/search?q=data-analysis-and-visualization-with-python&type=Repositories\n10. https://stackabuse.com/applying-filter-methods-in-python-for-feature-selection/\n11. https://towardsdatascience.com/decision-tree-in-machine-learning-e380942a4c96\n12. https://machinelearningmastery.com/master-machine-learning-algorithms/\n13. https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}