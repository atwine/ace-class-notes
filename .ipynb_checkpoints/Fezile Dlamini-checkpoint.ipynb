{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "###Importing libraries\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading some libraries\n",
    "### These are some of the libraries I think I will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading My Dataset\n",
    "\n",
    "##### I am going to first use my training dataset, then the test dataset last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_csv('/kaggle/input/ace-class-assignment/AMP_TrainSet.csv')\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pandas.read_csv('/kaggle/input/ace-class-assignment/Test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting my train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()  ###this will show the number of null values in my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()  #returns number of non-null values in my data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It seems i have no missing values in my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()  #returns summary of the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info() #It returns range, column, number of non-null objects of each column, datatype and memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows that my dataset has 3038 rows (instances) and 12 columns (attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I will also take a look at how many instances i have for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('CLASS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('CLASS').size().plot(kind='bar')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have two groups of classes, each with 1519 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will start with univariate plots to see each indiviadual variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist(figsize=(16,16))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr(method='pearson')['CLASS'] #Here I tried to see the correlation of all attributes with the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = train.corr()\n",
    "# plot correlation matrix\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(train.columns)\n",
    "ax.set_yticklabels(train.columns)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i did this plot in order to see which features are highly correlated as this can be a problem in soome models if some features are used together whereas they are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATING ALGORITHMS\n",
    "#### I will now evaluate some algorithms and estimate their accuracy on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from here, NB is the best performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "#print('MCC', matthews_corrcoef(model.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with all features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "array = train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=train.CLASS\n",
    "X=train.drop(\"CLASS\",axis=1)\n",
    "OUTPUT=model.fit(X, Y).predict(test.values)\n",
    "OUTPUT_1=pd.DataFrame(OUTPUT)\n",
    "OUTPUT_1.columns=[\"CLASS\"]\n",
    "OUTPUT_1.index.name=\"Index\"\n",
    "OUTPUT_1[\"CLASS\"]=OUTPUT_1[\"CLASS\"].map({0.0:False,1.0:True})\n",
    "OUTPUT_1.to_csv(\"output\")\n",
    "print(OUTPUT_1[\"CLASS\"].unique())\n",
    "print(OUTPUT_1[\"CLASS\"].nunique())\n",
    "print(OUTPUT_1.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_1.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection using feature importance\n",
    "X = train.iloc[:,0:11]  #independent columns\n",
    "y = train.iloc[:,-1]    #target column\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain=train.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtest=test.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = newtrain.values\n",
    "X = array[:,0:5]\n",
    "Y = array[:,-1]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=23, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=newtrain.CLASS\n",
    "X=newtrain.drop(\"CLASS\",axis=1)\n",
    "OUTPUT=model.fit(X, Y).predict(newtest.values)\n",
    "OUTPUT_1=pd.DataFrame(OUTPUT)\n",
    "OUTPUT_1.columns=[\"CLASS\"]\n",
    "OUTPUT_1.index.name=\"Index\"\n",
    "OUTPUT_1[\"CLASS\"]=OUTPUT_1[\"CLASS\"].map({0.0:False,1.0:True})\n",
    "OUTPUT_1.to_csv(\"out1\")\n",
    "print(OUTPUT_1[\"CLASS\"].unique())\n",
    "print(OUTPUT_1[\"CLASS\"].nunique())\n",
    "print(OUTPUT_1.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_1.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy using data with selected features from feature importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = train.values\n",
    "X = array[:,[0,1,3,5,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "prediction=model.predict(X_test)\n",
    "matrix=matthews_corrcoef(Y_test,prediction)\n",
    "print(\"Accuracy: \",  (result*100.0))\n",
    "print(matrix)\n",
    "\n",
    "# making predictions on the test data\n",
    "\n",
    "#output=model.predict(test.values)\n",
    "#output1=pd.DataFrame(output)\n",
    "#output1.columns=['CLASS']\n",
    "#output1.index.name='Index'\n",
    "#output1['CLASS']=output1['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "#print(output1['CLASS'].unique())\n",
    "#print(output1['CLASS'].nunique())\n",
    "\n",
    "#print(output1.groupby('CLASS').size()[0].sum())\n",
    "#print(output1.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2 = np.array(test)\n",
    "X = array2[:,[0,1,3,5,7]]\n",
    "x_t=array[:,[0,1,3,5,7]]\n",
    "y_t=array[:,11]\n",
    "\n",
    "#array3 = train.values\n",
    "#X_t = array3[:,[0,1,3,5,7]]\n",
    "#Y_t=array3[:,10]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "#random_state=seed)\n",
    "test=array3[:,[0,1,3,5,7]]\n",
    "model = GaussianNB()\n",
    "\n",
    "#result = model.score(X_t, Y_t)\n",
    "model.fit(x_t, y_t)\n",
    "prediction=model.predict(X)\n",
    "\n",
    "#matrix=matthews_corrcoef(Y_t,prediction)\n",
    "#print(\"Accuracy: \",  (result*100.0))\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection using Logistic regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "array_1 = train.values\n",
    "X = array_1[:,0:11]\n",
    "Y = array_1[:,11]\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: \",  fit.n_features_)\n",
    "print(\"Selected Features:\",  fit.support_)\n",
    "print(\"Feature Ranking: \",  fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking accuracy using data with selected features from feature importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "array = train.values\n",
    "X = array[:,[0,2,3,5,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING ACCURACY WITH ALL FEATURES\n",
    "array = train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
