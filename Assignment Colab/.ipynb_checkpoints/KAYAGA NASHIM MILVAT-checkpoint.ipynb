{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "        \n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "#### https://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/\n",
    "#### https://www.dataquest.io/blog/top-10-machine-learning-algorithms-for-beginners/\n",
    "#### https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/\n",
    "#### https://towardsdatascience.com/understanding-random-forest-58381e0602d2\n",
    "\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "    Please put these at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FULL_Charge</th>\n",
       "      <th>FULL_AcidicMolPerc</th>\n",
       "      <th>FULL_AURR980107</th>\n",
       "      <th>FULL_DAYM780201</th>\n",
       "      <th>FULL_GEOR030101</th>\n",
       "      <th>FULL_OOBM850104</th>\n",
       "      <th>NT_EFC195</th>\n",
       "      <th>AS_MeanAmphiMoment</th>\n",
       "      <th>AS_DAYM780201</th>\n",
       "      <th>AS_FUKS010112</th>\n",
       "      <th>CT_RACS820104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.704</td>\n",
       "      <td>0.873</td>\n",
       "      <td>73.519</td>\n",
       "      <td>0.987</td>\n",
       "      <td>-4.833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.382</td>\n",
       "      <td>74.556</td>\n",
       "      <td>7.225</td>\n",
       "      <td>1.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.892</td>\n",
       "      <td>62.444</td>\n",
       "      <td>0.931</td>\n",
       "      <td>-0.584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320</td>\n",
       "      <td>56.056</td>\n",
       "      <td>4.942</td>\n",
       "      <td>1.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1.039</td>\n",
       "      <td>-5.664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.164</td>\n",
       "      <td>47.000</td>\n",
       "      <td>5.969</td>\n",
       "      <td>1.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.869</td>\n",
       "      <td>69.222</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-5.423</td>\n",
       "      <td>0</td>\n",
       "      <td>2.010</td>\n",
       "      <td>69.222</td>\n",
       "      <td>5.462</td>\n",
       "      <td>1.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>21.591</td>\n",
       "      <td>1.061</td>\n",
       "      <td>71.682</td>\n",
       "      <td>0.976</td>\n",
       "      <td>-2.002</td>\n",
       "      <td>0</td>\n",
       "      <td>2.758</td>\n",
       "      <td>66.000</td>\n",
       "      <td>5.582</td>\n",
       "      <td>1.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.5</td>\n",
       "      <td>6.977</td>\n",
       "      <td>0.895</td>\n",
       "      <td>68.512</td>\n",
       "      <td>0.950</td>\n",
       "      <td>-1.878</td>\n",
       "      <td>0</td>\n",
       "      <td>3.090</td>\n",
       "      <td>72.000</td>\n",
       "      <td>5.779</td>\n",
       "      <td>1.844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.0</td>\n",
       "      <td>3.175</td>\n",
       "      <td>1.022</td>\n",
       "      <td>74.460</td>\n",
       "      <td>1.010</td>\n",
       "      <td>-3.225</td>\n",
       "      <td>0</td>\n",
       "      <td>3.172</td>\n",
       "      <td>76.722</td>\n",
       "      <td>5.664</td>\n",
       "      <td>1.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3.704</td>\n",
       "      <td>0.932</td>\n",
       "      <td>69.519</td>\n",
       "      <td>0.977</td>\n",
       "      <td>-2.509</td>\n",
       "      <td>0</td>\n",
       "      <td>2.543</td>\n",
       "      <td>72.000</td>\n",
       "      <td>4.251</td>\n",
       "      <td>1.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>0.903</td>\n",
       "      <td>59.500</td>\n",
       "      <td>0.963</td>\n",
       "      <td>-1.682</td>\n",
       "      <td>0</td>\n",
       "      <td>2.990</td>\n",
       "      <td>66.000</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.873</td>\n",
       "      <td>72.792</td>\n",
       "      <td>0.998</td>\n",
       "      <td>-4.943</td>\n",
       "      <td>0</td>\n",
       "      <td>2.985</td>\n",
       "      <td>77.444</td>\n",
       "      <td>5.626</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.219</td>\n",
       "      <td>0.927</td>\n",
       "      <td>75.068</td>\n",
       "      <td>0.989</td>\n",
       "      <td>-3.118</td>\n",
       "      <td>0</td>\n",
       "      <td>3.493</td>\n",
       "      <td>76.389</td>\n",
       "      <td>6.047</td>\n",
       "      <td>1.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.703</td>\n",
       "      <td>0.966</td>\n",
       "      <td>69.757</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-3.896</td>\n",
       "      <td>1</td>\n",
       "      <td>3.714</td>\n",
       "      <td>76.444</td>\n",
       "      <td>5.492</td>\n",
       "      <td>1.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.538</td>\n",
       "      <td>1.027</td>\n",
       "      <td>77.923</td>\n",
       "      <td>0.981</td>\n",
       "      <td>-3.954</td>\n",
       "      <td>1</td>\n",
       "      <td>3.679</td>\n",
       "      <td>78.056</td>\n",
       "      <td>7.222</td>\n",
       "      <td>1.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.114</td>\n",
       "      <td>79.100</td>\n",
       "      <td>1.024</td>\n",
       "      <td>-2.437</td>\n",
       "      <td>0</td>\n",
       "      <td>3.988</td>\n",
       "      <td>75.556</td>\n",
       "      <td>6.667</td>\n",
       "      <td>1.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.005</td>\n",
       "      <td>78.971</td>\n",
       "      <td>1.102</td>\n",
       "      <td>1.544</td>\n",
       "      <td>0</td>\n",
       "      <td>4.143</td>\n",
       "      <td>78.556</td>\n",
       "      <td>4.472</td>\n",
       "      <td>1.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.061</td>\n",
       "      <td>0.897</td>\n",
       "      <td>76.455</td>\n",
       "      <td>0.955</td>\n",
       "      <td>-4.032</td>\n",
       "      <td>1</td>\n",
       "      <td>4.310</td>\n",
       "      <td>81.222</td>\n",
       "      <td>6.207</td>\n",
       "      <td>1.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.128</td>\n",
       "      <td>0.889</td>\n",
       "      <td>64.064</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0</td>\n",
       "      <td>4.097</td>\n",
       "      <td>74.667</td>\n",
       "      <td>5.097</td>\n",
       "      <td>1.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>55.647</td>\n",
       "      <td>0.955</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>0</td>\n",
       "      <td>3.816</td>\n",
       "      <td>61.667</td>\n",
       "      <td>4.829</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.5</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.948</td>\n",
       "      <td>70.720</td>\n",
       "      <td>0.956</td>\n",
       "      <td>-3.559</td>\n",
       "      <td>1</td>\n",
       "      <td>3.982</td>\n",
       "      <td>66.500</td>\n",
       "      <td>7.024</td>\n",
       "      <td>1.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.828</td>\n",
       "      <td>54.875</td>\n",
       "      <td>1.048</td>\n",
       "      <td>-2.853</td>\n",
       "      <td>0</td>\n",
       "      <td>4.293</td>\n",
       "      <td>54.875</td>\n",
       "      <td>5.229</td>\n",
       "      <td>1.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>0.901</td>\n",
       "      <td>69.594</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-1.677</td>\n",
       "      <td>0</td>\n",
       "      <td>3.876</td>\n",
       "      <td>58.500</td>\n",
       "      <td>5.278</td>\n",
       "      <td>1.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.872</td>\n",
       "      <td>67.200</td>\n",
       "      <td>0.972</td>\n",
       "      <td>-5.392</td>\n",
       "      <td>0</td>\n",
       "      <td>4.471</td>\n",
       "      <td>67.200</td>\n",
       "      <td>6.524</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>64.150</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-4.706</td>\n",
       "      <td>0</td>\n",
       "      <td>3.929</td>\n",
       "      <td>63.722</td>\n",
       "      <td>6.941</td>\n",
       "      <td>1.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.933</td>\n",
       "      <td>62.800</td>\n",
       "      <td>1.008</td>\n",
       "      <td>-4.170</td>\n",
       "      <td>0</td>\n",
       "      <td>4.104</td>\n",
       "      <td>62.667</td>\n",
       "      <td>4.870</td>\n",
       "      <td>1.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.811</td>\n",
       "      <td>1.086</td>\n",
       "      <td>77.108</td>\n",
       "      <td>1.010</td>\n",
       "      <td>-2.112</td>\n",
       "      <td>0</td>\n",
       "      <td>4.208</td>\n",
       "      <td>78.056</td>\n",
       "      <td>5.748</td>\n",
       "      <td>1.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.941</td>\n",
       "      <td>0.900</td>\n",
       "      <td>71.206</td>\n",
       "      <td>0.967</td>\n",
       "      <td>-3.963</td>\n",
       "      <td>0</td>\n",
       "      <td>4.126</td>\n",
       "      <td>72.611</td>\n",
       "      <td>6.828</td>\n",
       "      <td>1.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.845</td>\n",
       "      <td>69.511</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-2.049</td>\n",
       "      <td>0</td>\n",
       "      <td>3.977</td>\n",
       "      <td>70.722</td>\n",
       "      <td>4.891</td>\n",
       "      <td>1.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.946</td>\n",
       "      <td>71.667</td>\n",
       "      <td>1.023</td>\n",
       "      <td>-4.982</td>\n",
       "      <td>0</td>\n",
       "      <td>3.439</td>\n",
       "      <td>71.667</td>\n",
       "      <td>5.953</td>\n",
       "      <td>1.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.822</td>\n",
       "      <td>54.545</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-3.955</td>\n",
       "      <td>0</td>\n",
       "      <td>3.562</td>\n",
       "      <td>55.500</td>\n",
       "      <td>6.086</td>\n",
       "      <td>1.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>38.235</td>\n",
       "      <td>1.239</td>\n",
       "      <td>83.559</td>\n",
       "      <td>1.002</td>\n",
       "      <td>0.108</td>\n",
       "      <td>1</td>\n",
       "      <td>3.317</td>\n",
       "      <td>91.500</td>\n",
       "      <td>5.723</td>\n",
       "      <td>1.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.167</td>\n",
       "      <td>0.931</td>\n",
       "      <td>67.833</td>\n",
       "      <td>0.936</td>\n",
       "      <td>-0.775</td>\n",
       "      <td>0</td>\n",
       "      <td>14.993</td>\n",
       "      <td>68.667</td>\n",
       "      <td>6.047</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.407</td>\n",
       "      <td>0.930</td>\n",
       "      <td>81.259</td>\n",
       "      <td>0.985</td>\n",
       "      <td>-2.859</td>\n",
       "      <td>0</td>\n",
       "      <td>14.993</td>\n",
       "      <td>80.778</td>\n",
       "      <td>6.012</td>\n",
       "      <td>1.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1.119</td>\n",
       "      <td>79.667</td>\n",
       "      <td>1.023</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>0</td>\n",
       "      <td>14.986</td>\n",
       "      <td>77.667</td>\n",
       "      <td>6.042</td>\n",
       "      <td>1.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>17.500</td>\n",
       "      <td>1.068</td>\n",
       "      <td>84.100</td>\n",
       "      <td>0.995</td>\n",
       "      <td>-1.328</td>\n",
       "      <td>0</td>\n",
       "      <td>14.943</td>\n",
       "      <td>90.000</td>\n",
       "      <td>6.081</td>\n",
       "      <td>1.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.545</td>\n",
       "      <td>0.830</td>\n",
       "      <td>85.091</td>\n",
       "      <td>0.996</td>\n",
       "      <td>-3.729</td>\n",
       "      <td>0</td>\n",
       "      <td>14.982</td>\n",
       "      <td>85.833</td>\n",
       "      <td>5.612</td>\n",
       "      <td>1.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.538</td>\n",
       "      <td>1.050</td>\n",
       "      <td>70.885</td>\n",
       "      <td>1.015</td>\n",
       "      <td>-2.530</td>\n",
       "      <td>0</td>\n",
       "      <td>14.981</td>\n",
       "      <td>75.722</td>\n",
       "      <td>5.337</td>\n",
       "      <td>1.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.333</td>\n",
       "      <td>0.925</td>\n",
       "      <td>72.533</td>\n",
       "      <td>0.993</td>\n",
       "      <td>-2.093</td>\n",
       "      <td>0</td>\n",
       "      <td>18.279</td>\n",
       "      <td>72.533</td>\n",
       "      <td>5.525</td>\n",
       "      <td>1.147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.5</td>\n",
       "      <td>11.111</td>\n",
       "      <td>1.135</td>\n",
       "      <td>80.778</td>\n",
       "      <td>1.034</td>\n",
       "      <td>-1.448</td>\n",
       "      <td>0</td>\n",
       "      <td>14.951</td>\n",
       "      <td>80.778</td>\n",
       "      <td>5.411</td>\n",
       "      <td>1.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>13.333</td>\n",
       "      <td>0.957</td>\n",
       "      <td>75.200</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>0</td>\n",
       "      <td>17.799</td>\n",
       "      <td>75.200</td>\n",
       "      <td>5.939</td>\n",
       "      <td>1.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.204</td>\n",
       "      <td>0.947</td>\n",
       "      <td>78.184</td>\n",
       "      <td>0.986</td>\n",
       "      <td>-3.313</td>\n",
       "      <td>0</td>\n",
       "      <td>15.300</td>\n",
       "      <td>77.111</td>\n",
       "      <td>6.239</td>\n",
       "      <td>1.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.231</td>\n",
       "      <td>1.065</td>\n",
       "      <td>91.077</td>\n",
       "      <td>1.004</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0</td>\n",
       "      <td>15.214</td>\n",
       "      <td>95.611</td>\n",
       "      <td>5.369</td>\n",
       "      <td>1.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>17.647</td>\n",
       "      <td>1.119</td>\n",
       "      <td>82.147</td>\n",
       "      <td>1.005</td>\n",
       "      <td>-1.477</td>\n",
       "      <td>0</td>\n",
       "      <td>15.321</td>\n",
       "      <td>81.333</td>\n",
       "      <td>5.771</td>\n",
       "      <td>1.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.704</td>\n",
       "      <td>0.909</td>\n",
       "      <td>76.111</td>\n",
       "      <td>1.009</td>\n",
       "      <td>-2.840</td>\n",
       "      <td>0</td>\n",
       "      <td>15.666</td>\n",
       "      <td>79.222</td>\n",
       "      <td>6.023</td>\n",
       "      <td>1.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.836</td>\n",
       "      <td>80.097</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-2.795</td>\n",
       "      <td>0</td>\n",
       "      <td>15.110</td>\n",
       "      <td>82.611</td>\n",
       "      <td>5.923</td>\n",
       "      <td>1.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>13.333</td>\n",
       "      <td>1.115</td>\n",
       "      <td>75.289</td>\n",
       "      <td>1.027</td>\n",
       "      <td>-1.292</td>\n",
       "      <td>0</td>\n",
       "      <td>15.058</td>\n",
       "      <td>80.389</td>\n",
       "      <td>5.809</td>\n",
       "      <td>1.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.333</td>\n",
       "      <td>0.928</td>\n",
       "      <td>79.000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>-3.607</td>\n",
       "      <td>0</td>\n",
       "      <td>15.091</td>\n",
       "      <td>80.944</td>\n",
       "      <td>5.417</td>\n",
       "      <td>1.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>10.5</td>\n",
       "      <td>17.000</td>\n",
       "      <td>1.091</td>\n",
       "      <td>82.160</td>\n",
       "      <td>1.003</td>\n",
       "      <td>-2.414</td>\n",
       "      <td>0</td>\n",
       "      <td>15.270</td>\n",
       "      <td>74.944</td>\n",
       "      <td>5.601</td>\n",
       "      <td>1.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>5.5</td>\n",
       "      <td>12.821</td>\n",
       "      <td>0.996</td>\n",
       "      <td>67.513</td>\n",
       "      <td>0.991</td>\n",
       "      <td>-4.674</td>\n",
       "      <td>0</td>\n",
       "      <td>14.989</td>\n",
       "      <td>67.944</td>\n",
       "      <td>6.928</td>\n",
       "      <td>1.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>19.048</td>\n",
       "      <td>1.030</td>\n",
       "      <td>85.333</td>\n",
       "      <td>0.969</td>\n",
       "      <td>-1.162</td>\n",
       "      <td>0</td>\n",
       "      <td>15.458</td>\n",
       "      <td>86.500</td>\n",
       "      <td>6.284</td>\n",
       "      <td>1.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>20.513</td>\n",
       "      <td>1.099</td>\n",
       "      <td>82.795</td>\n",
       "      <td>1.014</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0</td>\n",
       "      <td>15.715</td>\n",
       "      <td>86.333</td>\n",
       "      <td>5.589</td>\n",
       "      <td>1.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>1.178</td>\n",
       "      <td>86.417</td>\n",
       "      <td>1.013</td>\n",
       "      <td>1.322</td>\n",
       "      <td>0</td>\n",
       "      <td>22.989</td>\n",
       "      <td>86.417</td>\n",
       "      <td>5.584</td>\n",
       "      <td>1.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>21.875</td>\n",
       "      <td>1.021</td>\n",
       "      <td>66.188</td>\n",
       "      <td>0.994</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>0</td>\n",
       "      <td>15.499</td>\n",
       "      <td>71.222</td>\n",
       "      <td>5.939</td>\n",
       "      <td>1.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.054</td>\n",
       "      <td>86.462</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.815</td>\n",
       "      <td>0</td>\n",
       "      <td>20.866</td>\n",
       "      <td>86.462</td>\n",
       "      <td>5.712</td>\n",
       "      <td>1.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>14.894</td>\n",
       "      <td>1.042</td>\n",
       "      <td>83.255</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-1.303</td>\n",
       "      <td>0</td>\n",
       "      <td>15.260</td>\n",
       "      <td>85.167</td>\n",
       "      <td>5.718</td>\n",
       "      <td>1.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>28.261</td>\n",
       "      <td>1.221</td>\n",
       "      <td>82.109</td>\n",
       "      <td>1.014</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>0</td>\n",
       "      <td>15.355</td>\n",
       "      <td>81.167</td>\n",
       "      <td>6.904</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>-1.5</td>\n",
       "      <td>16.000</td>\n",
       "      <td>1.100</td>\n",
       "      <td>82.820</td>\n",
       "      <td>0.991</td>\n",
       "      <td>-1.987</td>\n",
       "      <td>0</td>\n",
       "      <td>15.185</td>\n",
       "      <td>85.333</td>\n",
       "      <td>7.053</td>\n",
       "      <td>1.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.182</td>\n",
       "      <td>1.085</td>\n",
       "      <td>73.455</td>\n",
       "      <td>1.027</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>0</td>\n",
       "      <td>16.550</td>\n",
       "      <td>74.667</td>\n",
       "      <td>6.729</td>\n",
       "      <td>1.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.048</td>\n",
       "      <td>1.108</td>\n",
       "      <td>82.190</td>\n",
       "      <td>1.033</td>\n",
       "      <td>-1.789</td>\n",
       "      <td>0</td>\n",
       "      <td>16.112</td>\n",
       "      <td>79.667</td>\n",
       "      <td>6.036</td>\n",
       "      <td>1.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.143</td>\n",
       "      <td>0.955</td>\n",
       "      <td>76.786</td>\n",
       "      <td>1.023</td>\n",
       "      <td>1.141</td>\n",
       "      <td>0</td>\n",
       "      <td>20.630</td>\n",
       "      <td>76.786</td>\n",
       "      <td>5.669</td>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>17.143</td>\n",
       "      <td>1.078</td>\n",
       "      <td>84.186</td>\n",
       "      <td>1.009</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0</td>\n",
       "      <td>17.168</td>\n",
       "      <td>76.611</td>\n",
       "      <td>6.688</td>\n",
       "      <td>1.305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>758 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FULL_Charge  FULL_AcidicMolPerc  FULL_AURR980107  FULL_DAYM780201  \\\n",
       "0            4.0               3.704            0.873           73.519   \n",
       "1            4.0               4.444            0.892           62.444   \n",
       "2            2.0               0.000            0.901           47.000   \n",
       "3            4.5               0.000            0.869           69.222   \n",
       "4           -4.0              21.591            1.061           71.682   \n",
       "5            4.5               6.977            0.895           68.512   \n",
       "6           12.0               3.175            1.022           74.460   \n",
       "7            1.5               3.704            0.932           69.519   \n",
       "8            3.0               3.333            0.903           59.500   \n",
       "9            4.0               0.000            0.873           72.792   \n",
       "10          11.0               8.219            0.927           75.068   \n",
       "11           4.5               2.703            0.966           69.757   \n",
       "12           0.0              11.538            1.027           77.923   \n",
       "13           6.0               3.333            1.114           79.100   \n",
       "14           0.0               0.000            1.005           78.971   \n",
       "15           3.0               6.061            0.897           76.455   \n",
       "16           3.0               2.128            0.889           64.064   \n",
       "17           9.5               0.000            0.786           55.647   \n",
       "18           1.5              12.000            0.948           70.720   \n",
       "19           4.0               0.000            0.828           54.875   \n",
       "20           5.0               3.125            0.901           69.594   \n",
       "21           1.5               0.000            0.872           67.200   \n",
       "22           2.0               0.000            0.786           64.150   \n",
       "23           8.0               0.000            0.933           62.800   \n",
       "24           3.0              10.811            1.086           77.108   \n",
       "25           4.0               2.941            0.900           71.206   \n",
       "26          10.0               0.000            0.845           69.511   \n",
       "27           5.5               0.000            0.946           71.667   \n",
       "28           9.0               0.000            0.822           54.545   \n",
       "29          -6.0              38.235            1.239           83.559   \n",
       "..           ...                 ...              ...              ...   \n",
       "728          1.0               4.167            0.931           67.833   \n",
       "729          1.0               7.407            0.930           81.259   \n",
       "730          0.0              25.000            1.119           79.667   \n",
       "731         -2.0              17.500            1.068           84.100   \n",
       "732          1.0               4.545            0.830           85.091   \n",
       "733          1.0              11.538            1.050           70.885   \n",
       "734          0.0              13.333            0.925           72.533   \n",
       "735          0.5              11.111            1.135           80.778   \n",
       "736         -0.5              13.333            0.957           75.200   \n",
       "737          5.0              10.204            0.947           78.184   \n",
       "738         -1.0              19.231            1.065           91.077   \n",
       "739         -1.5              17.647            1.119           82.147   \n",
       "740          6.5               3.704            0.909           76.111   \n",
       "741          5.0               0.000            0.836           80.097   \n",
       "742         -3.5              13.333            1.115           75.289   \n",
       "743          4.0               8.333            0.928           79.000   \n",
       "744         10.5              17.000            1.091           82.160   \n",
       "745          5.5              12.821            0.996           67.513   \n",
       "746         -2.0              19.048            1.030           85.333   \n",
       "747         -2.5              20.513            1.099           82.795   \n",
       "748         -2.0              25.000            1.178           86.417   \n",
       "749         -4.0              21.875            1.021           66.188   \n",
       "750          2.0               0.000            1.054           86.462   \n",
       "751         -2.0              14.894            1.042           83.255   \n",
       "752         -8.0              28.261            1.221           82.109   \n",
       "753         -1.5              16.000            1.100           82.820   \n",
       "754         -1.0              18.182            1.085           73.455   \n",
       "755         -1.0              19.048            1.108           82.190   \n",
       "756         -1.0               7.143            0.955           76.786   \n",
       "757         -7.0              17.143            1.078           84.186   \n",
       "\n",
       "     FULL_GEOR030101  FULL_OOBM850104  NT_EFC195  AS_MeanAmphiMoment  \\\n",
       "0              0.987           -4.833          0               0.382   \n",
       "1              0.931           -0.584          0               0.320   \n",
       "2              1.039           -5.664          0               0.164   \n",
       "3              0.982           -5.423          0               2.010   \n",
       "4              0.976           -2.002          0               2.758   \n",
       "5              0.950           -1.878          0               3.090   \n",
       "6              1.010           -3.225          0               3.172   \n",
       "7              0.977           -2.509          0               2.543   \n",
       "8              0.963           -1.682          0               2.990   \n",
       "9              0.998           -4.943          0               2.985   \n",
       "10             0.989           -3.118          0               3.493   \n",
       "11             0.972           -3.896          1               3.714   \n",
       "12             0.981           -3.954          1               3.679   \n",
       "13             1.024           -2.437          0               3.988   \n",
       "14             1.102            1.544          0               4.143   \n",
       "15             0.955           -4.032          1               4.310   \n",
       "16             1.000            0.583          0               4.097   \n",
       "17             0.955           -0.577          0               3.816   \n",
       "18             0.956           -3.559          1               3.982   \n",
       "19             1.048           -2.853          0               4.293   \n",
       "20             0.995           -1.677          0               3.876   \n",
       "21             0.972           -5.392          0               4.471   \n",
       "22             0.969           -4.706          0               3.929   \n",
       "23             1.008           -4.170          0               4.104   \n",
       "24             1.010           -2.112          0               4.208   \n",
       "25             0.967           -3.963          0               4.126   \n",
       "26             0.975           -2.049          0               3.977   \n",
       "27             1.023           -4.982          0               3.439   \n",
       "28             0.993           -3.955          0               3.562   \n",
       "29             1.002            0.108          1               3.317   \n",
       "..               ...              ...        ...                 ...   \n",
       "728            0.936           -0.775          0              14.993   \n",
       "729            0.985           -2.859          0              14.993   \n",
       "730            1.023           -0.379          0              14.986   \n",
       "731            0.995           -1.328          0              14.943   \n",
       "732            0.996           -3.729          0              14.982   \n",
       "733            1.015           -2.530          0              14.981   \n",
       "734            0.993           -2.093          0              18.279   \n",
       "735            1.034           -1.448          0              14.951   \n",
       "736            0.969           -1.257          0              17.799   \n",
       "737            0.986           -3.313          0              15.300   \n",
       "738            1.004            0.520          0              15.214   \n",
       "739            1.005           -1.477          0              15.321   \n",
       "740            1.009           -2.840          0              15.666   \n",
       "741            0.973           -2.795          0              15.110   \n",
       "742            1.027           -1.292          0              15.058   \n",
       "743            0.960           -3.607          0              15.091   \n",
       "744            1.003           -2.414          0              15.270   \n",
       "745            0.991           -4.674          0              14.989   \n",
       "746            0.969           -1.162          0              15.458   \n",
       "747            1.014           -0.965          0              15.715   \n",
       "748            1.013            1.322          0              22.989   \n",
       "749            0.994           -0.523          0              15.499   \n",
       "750            1.051           -0.815          0              20.866   \n",
       "751            0.978           -1.303          0              15.260   \n",
       "752            1.014           -0.153          0              15.355   \n",
       "753            0.991           -1.987          0              15.185   \n",
       "754            1.027           -0.745          0              16.550   \n",
       "755            1.033           -1.789          0              16.112   \n",
       "756            1.023            1.141          0              20.630   \n",
       "757            1.009           -0.066          0              17.168   \n",
       "\n",
       "     AS_DAYM780201  AS_FUKS010112  CT_RACS820104  \n",
       "0           74.556          7.225          1.234  \n",
       "1           56.056          4.942          1.853  \n",
       "2           47.000          5.969          1.174  \n",
       "3           69.222          5.462          1.138  \n",
       "4           66.000          5.582          1.453  \n",
       "5           72.000          5.779          1.844  \n",
       "6           76.722          5.664          1.215  \n",
       "7           72.000          4.251          1.560  \n",
       "8           66.000          5.175          1.514  \n",
       "9           77.444          5.626          1.621  \n",
       "10          76.389          6.047          1.126  \n",
       "11          76.444          5.492          1.445  \n",
       "12          78.056          7.222          1.054  \n",
       "13          75.556          6.667          1.079  \n",
       "14          78.556          4.472          1.280  \n",
       "15          81.222          6.207          1.506  \n",
       "16          74.667          5.097          1.302  \n",
       "17          61.667          4.829          2.026  \n",
       "18          66.500          7.024          1.050  \n",
       "19          54.875          5.229          1.651  \n",
       "20          58.500          5.278          1.486  \n",
       "21          67.200          6.524          0.986  \n",
       "22          63.722          6.941          1.040  \n",
       "23          62.667          4.870          1.547  \n",
       "24          78.056          5.748          1.249  \n",
       "25          72.611          6.828          1.507  \n",
       "26          70.722          4.891          1.543  \n",
       "27          71.667          5.953          1.108  \n",
       "28          55.500          6.086          1.114  \n",
       "29          91.500          5.723          1.055  \n",
       "..             ...            ...            ...  \n",
       "728         68.667          6.047          1.125  \n",
       "729         80.778          6.012          1.051  \n",
       "730         77.667          6.042          1.137  \n",
       "731         90.000          6.081          1.484  \n",
       "732         85.833          5.612          1.165  \n",
       "733         75.722          5.337          1.327  \n",
       "734         72.533          5.525          1.147  \n",
       "735         80.778          5.411          1.079  \n",
       "736         75.200          5.939          1.150  \n",
       "737         77.111          6.239          1.050  \n",
       "738         95.611          5.369          1.276  \n",
       "739         81.333          5.771          1.016  \n",
       "740         79.222          6.023          1.242  \n",
       "741         82.611          5.923          1.245  \n",
       "742         80.389          5.809          1.300  \n",
       "743         80.944          5.417          1.316  \n",
       "744         74.944          5.601          1.053  \n",
       "745         67.944          6.928          1.166  \n",
       "746         86.500          6.284          1.156  \n",
       "747         86.333          5.589          1.127  \n",
       "748         86.417          5.584          1.228  \n",
       "749         71.222          5.939          1.080  \n",
       "750         86.462          5.712          1.298  \n",
       "751         85.167          5.718          1.164  \n",
       "752         81.167          6.904          0.933  \n",
       "753         85.333          7.053          1.325  \n",
       "754         74.667          6.729          1.132  \n",
       "755         79.667          6.036          1.219  \n",
       "756         76.786          5.669          1.111  \n",
       "757         76.611          6.688          1.305  \n",
       "\n",
       "[758 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../AMP Data Sets/Test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(758, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FULL_Charge</th>\n",
       "      <th>FULL_AcidicMolPerc</th>\n",
       "      <th>FULL_AURR980107</th>\n",
       "      <th>FULL_DAYM780201</th>\n",
       "      <th>FULL_GEOR030101</th>\n",
       "      <th>FULL_OOBM850104</th>\n",
       "      <th>NT_EFC195</th>\n",
       "      <th>AS_MeanAmphiMoment</th>\n",
       "      <th>AS_DAYM780201</th>\n",
       "      <th>AS_FUKS010112</th>\n",
       "      <th>CT_RACS820104</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.951</td>\n",
       "      <td>74.842</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-3.663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.282</td>\n",
       "      <td>73.444</td>\n",
       "      <td>5.661</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.405</td>\n",
       "      <td>0.931</td>\n",
       "      <td>71.595</td>\n",
       "      <td>0.957</td>\n",
       "      <td>-4.011</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600</td>\n",
       "      <td>68.222</td>\n",
       "      <td>6.537</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.405</td>\n",
       "      <td>0.873</td>\n",
       "      <td>73.595</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-2.512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.593</td>\n",
       "      <td>69.444</td>\n",
       "      <td>4.934</td>\n",
       "      <td>1.722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.167</td>\n",
       "      <td>0.895</td>\n",
       "      <td>66.250</td>\n",
       "      <td>0.999</td>\n",
       "      <td>-1.362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>67.222</td>\n",
       "      <td>4.316</td>\n",
       "      <td>1.382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.5</td>\n",
       "      <td>8.537</td>\n",
       "      <td>0.932</td>\n",
       "      <td>64.720</td>\n",
       "      <td>0.979</td>\n",
       "      <td>-2.091</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616</td>\n",
       "      <td>72.944</td>\n",
       "      <td>4.540</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FULL_Charge  FULL_AcidicMolPerc  FULL_AURR980107  FULL_DAYM780201  \\\n",
       "0          5.0               0.000            0.951           74.842   \n",
       "1          4.0               5.405            0.931           71.595   \n",
       "2          5.5               5.405            0.873           73.595   \n",
       "3          5.0               4.167            0.895           66.250   \n",
       "4          7.5               8.537            0.932           64.720   \n",
       "\n",
       "   FULL_GEOR030101  FULL_OOBM850104  NT_EFC195  AS_MeanAmphiMoment  \\\n",
       "0            0.975           -3.663          0               0.282   \n",
       "1            0.957           -4.011          1               0.600   \n",
       "2            0.961           -2.512          0               0.593   \n",
       "3            0.999           -1.362          0               0.614   \n",
       "4            0.979           -2.091          0               0.616   \n",
       "\n",
       "   AS_DAYM780201  AS_FUKS010112  CT_RACS820104  CLASS  \n",
       "0         73.444          5.661          1.041      1  \n",
       "1         68.222          6.537          1.453      1  \n",
       "2         69.444          4.934          1.722      1  \n",
       "3         67.222          4.316          1.382      1  \n",
       "4         72.944          4.540          1.539      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the data\n",
    "data = pd.read_csv(\"../AMP Data Sets/AMP_TrainSet.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze data by describing\n",
    "\n",
    "#### This step helped me know which features are in my dataset, are they categorical or numerical.\n",
    "#### How many rows and columns does the dataset have\n",
    "#### The data types for the various features\n",
    "#### Checked whether the dataset has null or missing values\n",
    "\n",
    "<div c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3038, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dimensions to the number of rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FULL_Charge', 'FULL_AcidicMolPerc', 'FULL_AURR980107',\n",
       "       'FULL_DAYM780201', 'FULL_GEOR030101', 'FULL_OOBM850104', 'NT_EFC195',\n",
       "       'AS_MeanAmphiMoment', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104',\n",
       "       'CLASS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FULL_Charge           float64\n",
       "FULL_AcidicMolPerc    float64\n",
       "FULL_AURR980107       float64\n",
       "FULL_DAYM780201       float64\n",
       "FULL_GEOR030101       float64\n",
       "FULL_OOBM850104       float64\n",
       "NT_EFC195               int64\n",
       "AS_MeanAmphiMoment    float64\n",
       "AS_DAYM780201         float64\n",
       "AS_FUKS010112         float64\n",
       "CT_RACS820104         float64\n",
       "CLASS                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FULL_Charge</th>\n",
       "      <th>FULL_AcidicMolPerc</th>\n",
       "      <th>FULL_AURR980107</th>\n",
       "      <th>FULL_DAYM780201</th>\n",
       "      <th>FULL_GEOR030101</th>\n",
       "      <th>FULL_OOBM850104</th>\n",
       "      <th>NT_EFC195</th>\n",
       "      <th>AS_MeanAmphiMoment</th>\n",
       "      <th>AS_DAYM780201</th>\n",
       "      <th>AS_FUKS010112</th>\n",
       "      <th>CT_RACS820104</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "      <td>3038.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.060237</td>\n",
       "      <td>8.521520</td>\n",
       "      <td>0.971410</td>\n",
       "      <td>73.668760</td>\n",
       "      <td>0.994007</td>\n",
       "      <td>-2.432927</td>\n",
       "      <td>0.088545</td>\n",
       "      <td>15.683233</td>\n",
       "      <td>73.650828</td>\n",
       "      <td>5.911361</td>\n",
       "      <td>1.235255</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.819929</td>\n",
       "      <td>7.586652</td>\n",
       "      <td>0.107413</td>\n",
       "      <td>8.527489</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>1.707223</td>\n",
       "      <td>0.284133</td>\n",
       "      <td>11.575665</td>\n",
       "      <td>9.166092</td>\n",
       "      <td>0.693689</td>\n",
       "      <td>0.210012</td>\n",
       "      <td>0.500082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>-10.432000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>42.778000</td>\n",
       "      <td>3.533000</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.516000</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>68.294000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>-3.606000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.587500</td>\n",
       "      <td>67.556000</td>\n",
       "      <td>5.459250</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.143000</td>\n",
       "      <td>0.963000</td>\n",
       "      <td>74.059500</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>-2.296500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.988500</td>\n",
       "      <td>73.697000</td>\n",
       "      <td>5.925500</td>\n",
       "      <td>1.184000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.158000</td>\n",
       "      <td>1.041000</td>\n",
       "      <td>79.343750</td>\n",
       "      <td>1.011000</td>\n",
       "      <td>-1.283250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.807750</td>\n",
       "      <td>79.778000</td>\n",
       "      <td>6.382000</td>\n",
       "      <td>1.351000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>46.667000</td>\n",
       "      <td>1.451000</td>\n",
       "      <td>101.682000</td>\n",
       "      <td>1.196000</td>\n",
       "      <td>3.576000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.280000</td>\n",
       "      <td>103.167000</td>\n",
       "      <td>8.662000</td>\n",
       "      <td>2.192000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FULL_Charge  FULL_AcidicMolPerc  FULL_AURR980107  FULL_DAYM780201  \\\n",
       "count  3038.000000         3038.000000      3038.000000      3038.000000   \n",
       "mean      2.060237            8.521520         0.971410        73.668760   \n",
       "std       3.819929            7.586652         0.107413         8.527489   \n",
       "min     -16.000000            0.000000         0.684000        42.750000   \n",
       "25%       0.000000            2.516000         0.895000        68.294000   \n",
       "50%       2.000000            7.143000         0.963000        74.059500   \n",
       "75%       4.000000           13.158000         1.041000        79.343750   \n",
       "max      30.000000           46.667000         1.451000       101.682000   \n",
       "\n",
       "       FULL_GEOR030101  FULL_OOBM850104    NT_EFC195  AS_MeanAmphiMoment  \\\n",
       "count      3038.000000      3038.000000  3038.000000         3038.000000   \n",
       "mean          0.994007        -2.432927     0.088545           15.683233   \n",
       "std           0.031333         1.707223     0.284133           11.575665   \n",
       "min           0.866000       -10.432000     0.000000            0.041000   \n",
       "25%           0.974000        -3.606000     0.000000            5.587500   \n",
       "50%           0.994000        -2.296500     0.000000           14.988500   \n",
       "75%           1.011000        -1.283250     0.000000           26.807750   \n",
       "max           1.196000         3.576000     1.000000           51.280000   \n",
       "\n",
       "       AS_DAYM780201  AS_FUKS010112  CT_RACS820104        CLASS  \n",
       "count    3038.000000    3038.000000    3038.000000  3038.000000  \n",
       "mean       73.650828       5.911361       1.235255     0.500000  \n",
       "std         9.166092       0.693689       0.210012     0.500082  \n",
       "min        42.778000       3.533000       0.785000     0.000000  \n",
       "25%        67.556000       5.459250       1.082000     0.000000  \n",
       "50%        73.697000       5.925500       1.184000     0.500000  \n",
       "75%        79.778000       6.382000       1.351000     1.000000  \n",
       "max       103.167000       8.662000       2.192000     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate descriptive statistics that summarize the central tendency, dispersion, and shape of a datasetâ€™s distribution, excluding NaN values\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FULL_Charge           0\n",
       "FULL_AcidicMolPerc    0\n",
       "FULL_AURR980107       0\n",
       "FULL_DAYM780201       0\n",
       "FULL_GEOR030101       0\n",
       "FULL_OOBM850104       0\n",
       "NT_EFC195             0\n",
       "AS_MeanAmphiMoment    0\n",
       "AS_DAYM780201         0\n",
       "AS_FUKS010112         0\n",
       "CT_RACS820104         0\n",
       "CLASS                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of null values in each column\n",
    "data.isnull().sum()\n",
    "#since my data has no null values then its good to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### needed to know how balanced the class values are\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    What did you learn from all the steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.groupby('CLASS').size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Its a good idea to review all the pairwise correlations of the attributes in the dataset because some machine learning algorithm like linear and logistic regression can suffer poor performance if there are highly correlated attributes in the dataset\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "    Good explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  heat map to show the correlation of the data; plots that show the interactions between multiple variables in the dataset\n",
    "#### Correlation gives an indication of how related the changes are between two variables. If two variables change in the same direction they are positively correlated. If they change in opposite directions together (one goes up, one goes down), then they are negatively correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(data.corr(method='pearson'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### also checked the corelation in regards to the class since am trying to build a ML agorithm for that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.corr(method='pearson')['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most of my variables are positively skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data.skew().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## understanding data with visualization\n",
    "#### Data can be visualised in many ways that is univariate plots and multivariate plots             #### Used the Histogram for univariate plot as shown below and the correlation matrix plot as the multivariate plot as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram\n",
    "#### This helps to understand each attribute of my dataset independently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "data.hist()\n",
    "plt.subplots_adjust(bottom=3, right=2, top=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize data\n",
    "#### Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "array = data.values\n",
    "#separate array into input and output components\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "#set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = test.values\n",
    "scaler = StandardScaler().fit(array)\n",
    "rescaledt = scaler.transform(array)\n",
    "# summarize transformed data\n",
    "#set_printoptions(precision=3)\n",
    "print(rescaledt[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  it's the process of selecting a subset of relevant features for use in model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose Recursive Feature Elimination\n",
    "#### This is an automatic feature selection technique\n",
    "#### Used logistic regression it is a good baseline as it is fast to train and predict and scales well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model,8)\n",
    "fit = rfe.fit(X,Y)\n",
    "print(\"Num Features:\", fit.n_features_)\n",
    "print(\"Selected Features:\", fit.support_)\n",
    "print(\"Feature Ranking:\", fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,fit.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop=data.drop(['FULL_AcidicMolPerc', 'FULL_DAYM780201', 'AS_DAYM780201'],axis=1)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_test = test.drop(['FULL_AcidicMolPerc', 'FULL_DAYM780201', 'AS_DAYM780201'],axis=1)\n",
    "drop_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. #### Decided to first use all the  first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Performance of Machine Learning Algorithms with ResamplingÂ¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This algorithm evaluation technique is very fast. It is ideal for large datasets where there is strong evidence that both splits of the data are representative of the underlying problem. Because of the speed, it is useful to use this approach when the algorithm you are investigating is slow to train.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report = pd.DataFrame(output)\n",
    "report.columns = ['CLASS']\n",
    "report.index.name = \"Index\"\n",
    "report['CLASS']=report['CLASS'].map({0.0:False, 1.0:True})\n",
    "report.to_csv(\"report.csv\")\n",
    "\n",
    "print(report['CLASS'].unique())\n",
    "print('False: ',report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is more accurate because the algorithm is trained and evaluated multiple times on different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "num_folds = 10 #number of folds to use\n",
    "seed = 7 #reproducibility\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(f\"Accuracy:\", (results.mean()*100.0, results.std()*100.0))\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_kf = pd.DataFrame(output)\n",
    "report_kf.columns = ['CLASS']\n",
    "report_kf.index.name = \"Index\"\n",
    "report_kf['CLASS']=report_kf['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_kf.to_csv(\"report_kf.csv\")\n",
    "\n",
    "print(report_kf['CLASS'].unique())\n",
    "print('False: ',report_kf.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_kf.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "num_folds = 10\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy:\",  (results.mean()*100.0, results.std()*100.0))\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_l = pd.DataFrame(output)\n",
    "report_l.columns = ['CLASS']\n",
    "report_l.index.name = \"Index\"\n",
    "report_l['CLASS']=report_l['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_l.to_csv(\"report_l.csv\")\n",
    "\n",
    "print(report_l['CLASS'].unique())\n",
    "print('False: ',report_l.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_l.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Random Test-Train Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creates a random split of the data like the train/test split , but repeats the process of splitting and evaluation of the algorithm multiple times, like cross validation. Repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size\n",
    "#### In this I prefered using Repeated Random Test_Train Splits because when you look at the dataset the zeros are one side and the ones on the otherside in the 'class' column. So I would prefer to first shuffle the data and then split it to reduce on the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: \" , (results.mean()*100.0, results.std()*100.0))\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_rrt = pd.DataFrame(output)\n",
    "report_rrt.columns = ['CLASS']\n",
    "report_rrt.index.name = \"Index\"\n",
    "report_rrt['CLASS']=report_rrt['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_rrt.to_csv(\"report_rrt.csv\")\n",
    "\n",
    "print(report_rrt['CLASS'].unique())\n",
    "print('False: ',report_rrt.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_rrt.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms Overview\n",
    "### linear machine learning algorithms:\n",
    "\n",
    "    Logistic Regression.\n",
    "    Linear Discriminant Analysis.\n",
    "### onlinear machine learning algorithms\n",
    "\n",
    "    k-Nearest Neighbors.\n",
    "    Naive Bayes.\n",
    "    Classication and Regression Trees.\n",
    "    Support Vector Machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression is best suited for binary classification: data sets where y = 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression on standardized data\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "model.fit(rescaledX,Y)\n",
    "output = model.predict(rescaledt)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_scaled = pd.DataFrame(output)\n",
    "report_scaled.columns = ['CLASS']\n",
    "report_scaled.index.name = \"Index\"\n",
    "report_scaled['CLASS']=report_scaled['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_scaled.to_csv(\"report_scaled.csv\")\n",
    "\n",
    "print(report_scaled['CLASS'].unique())\n",
    "print('False: ',report_scaled.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_scaled.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classification\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "my_report = pd.DataFrame(output)\n",
    "my_report.columns = ['CLASS']\n",
    "my_report.index.name = \"Index\"\n",
    "my_report['CLASS']=my_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "my_report.to_csv(\"report_XGB.csv\")\n",
    "\n",
    "print(my_report['CLASS'].unique())\n",
    "print('False: ',my_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',my_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant AnalysisÂ¶\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "lda_report = pd.DataFrame(output)\n",
    "lda_report.columns = ['CLASS']\n",
    "lda_report.index.name = \"Index\"\n",
    "lda_report['CLASS']=lda_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "lda_report.to_csv(\"ldareport.csv\")\n",
    "\n",
    "print(lda_report['CLASS'].unique())\n",
    "print('False: ',lda_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',lda_report.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_k = pd.DataFrame(output)\n",
    "report_k.columns = ['CLASS']\n",
    "report_k.index.name = \"Index\"\n",
    "report_k['CLASS']=report_k['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_k.to_csv(\"report_k.csv\")\n",
    "\n",
    "\n",
    "print(report_k['CLASS'].unique())\n",
    "print('False: ',report_k.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_k.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tried using Standardised data on Naive Bayes\n",
    "\n",
    "### When I predicted Naive Bayes on Standardised data gave me a score of 0.98235, after feature selection it gave 0.90 and on unstandardised data it gave a score of 0.9959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on standardised data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "model.fit(rescaledX,Y)\n",
    "output = model.predict(rescaledt)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_rebayes = pd.DataFrame(output)\n",
    "report_rebayes.columns = ['CLASS']\n",
    "report_rebayes.index.name = \"Index\"\n",
    "report_rebayes['CLASS']=report_rebayes['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_rebayes.to_csv(\"report_rebayes.csv\")\n",
    "\n",
    "\n",
    "print(report_rebayes['CLASS'].unique())\n",
    "print('False: ',report_rebayes.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_rebayes.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on selected features\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "selectedX = X[:,fit.support_]\n",
    "\n",
    "array2 =test.values\n",
    "selectedT = array2[:,fit.support_]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, selectedX, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "model.fit(selectedX,Y)\n",
    "output = model.predict(selectedT)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(selectedX),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_sel = pd.DataFrame(output)\n",
    "report_sel.columns = ['CLASS']\n",
    "report_sel.index.name = \"Index\"\n",
    "report_sel['CLASS']=report_sel['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_sel.to_csv(\"report_sel.csv\")\n",
    "\n",
    "\n",
    "print(report_sel['CLASS'].unique())\n",
    "print('False: ',report_sel.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_sel.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_bayes = pd.DataFrame(output)\n",
    "report_bayes.columns = ['CLASS']\n",
    "report_bayes.index.name = \"Index\"\n",
    "report_bayes['CLASS']=report_bayes['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_bayes.to_csv(\"report_bayes.csv\")\n",
    "\n",
    "\n",
    "print(report_bayes['CLASS'].unique())\n",
    "print('False: ',report_bayes.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_bayes.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classiffication and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### used for classification or regression predictive modeling problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_tree = pd.DataFrame(output)\n",
    "report_tree.columns = ['CLASS']\n",
    "report_tree.index.name = \"Index\"\n",
    "report_tree['CLASS']=report_tree['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_tree.to_csv(\"report_tree.csv\")\n",
    "\n",
    "\n",
    "print(report_tree['CLASS'].unique())\n",
    "print('False: ',report_tree.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_tree.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = SVC()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_svm = pd.DataFrame(output)\n",
    "report_svm.columns = ['CLASS']\n",
    "report_svm.index.name = \"Index\"\n",
    "report_svm['CLASS']=report_svm['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_svm.to_csv(\"report_svm.csv\")\n",
    "\n",
    "\n",
    "print(report_svm['CLASS'].unique())\n",
    "print('False: ',report_svm.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_svm.groupby('CLASS').size()[1].sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Models Into Ensemble Predictions\n",
    "\n",
    "The three most popular methods for combining the predictions from different models are:\n",
    "   \n",
    "   Bagging\n",
    "   Boosting\n",
    "   Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # BoostingAlgorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  These seek to improve the prediction power by training a sequence of weak models, each compensating the weaknesses of its predecessors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is specifically designed for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "num_trees = 39\n",
    "seed=10\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_ada = pd.DataFrame(output)\n",
    "report_ada.columns = ['CLASS']\n",
    "report_ada.index.name = \"Index\"\n",
    "report_ada['CLASS']=report_ada['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_ada.to_csv(\"report_ada.csv\")\n",
    "\n",
    "\n",
    "print(report_ada['CLASS'].unique())\n",
    "print('False: ',report_ada.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_ada.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging is used with decision trees where it significantly raises the stability of models in the reduction of variance and improving accuracy, which eliminates the challenge of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Trees for Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#split the data in portions\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "seed = 7 #duplication\n",
    "\n",
    "#split according to cross validation\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "#initialize the model\n",
    "cart = DecisionTreeClassifier()\n",
    "\n",
    "#bagging\n",
    "num_trees = 250\n",
    "\n",
    "#model\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_bag = pd.DataFrame(output)\n",
    "report_bag.columns = ['CLASS']\n",
    "report_bag.index.name = \"Index\"\n",
    "report_bag['CLASS']=report_bag['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_bag.to_csv(\"report_bag.csv\")\n",
    "\n",
    "\n",
    "print(report_bag['CLASS'].unique())\n",
    "print('False: ',report_bag.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_bag.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "num_trees = 1000\n",
    "\n",
    "max_features = 3\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_rf = pd.DataFrame(output)\n",
    "report_rf.columns = ['CLASS']\n",
    "report_rf.index.name = \"Index\"\n",
    "report_rf['CLASS']=report_rf['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_rf.to_csv(\"report_rf.csv\")\n",
    "\n",
    "\n",
    "print(report_rf['CLASS'].unique())\n",
    "print('False: ',report_rf.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_rf.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "num_trees = 100\n",
    "max_features = 7\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble for Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "model4 = XGBClassifier()\n",
    "estimators.append(('xgb', model4))\n",
    "\n",
    "model5 = RandomForestClassifier()\n",
    "estimators.append(('rfc', model5))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "output = model.predict(test.values)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "mcc = matthews_corrcoef(model.predict(X),Y)\n",
    "print('MCC:',mcc)\n",
    "                       \n",
    "report_v = pd.DataFrame(output)\n",
    "report_v.columns = ['CLASS']\n",
    "report_v.index.name = \"Index\"\n",
    "report_v['CLASS']=report_v['CLASS'].map({0.0:False, 1.0:True})\n",
    "report_v.to_csv(\"report_v.csv\")\n",
    "\n",
    "\n",
    "print(report_v['CLASS'].unique())\n",
    "print('False: ',report_v.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',report_v.groupby('CLASS').size()[1].sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparing the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare models and add them to a list\n",
    "from matplotlib import pyplot\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('ETC', ExtraTreesClassifier()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# '''''''''''''''''''''''''''''''END''''''''''''''''''''''''''''''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
