{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use this link to learn Markdown\n",
    "\n",
    "[Link](https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-text-files/format-text-with-markdown-jupyter-notebook/)\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "  Please use it to write your report.\n",
    "  \n",
    "  So far its easy to follow your thought which is good.\n",
    "  \n",
    "  It would be better to explain more on the concepts, you have done it well in some parts ,others neglected.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "#import seaborn as sb\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "###Importing libraries\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading some libraries\n",
    "### These are some of the libraries I think I will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv #for reading in csv files\n",
    "from pandas.plotting import scatter_matrix \n",
    "from matplotlib import pyplot \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief description of the codes above:\n",
    "#### 1.**read_csv**:   for reading in csv files\n",
    "#### 2.**scatter matrix**: for showing how one variable is affected by another\n",
    "#### 3.**pyplot** : for plotting graphs\n",
    "#### 4.**train_test_split**: for splitting my data into train and test\n",
    "#### 5.**cross_val_score**: to estimate the skill of a machine learning model on unseen data\n",
    "#### 6.**StratifiedKFold**: the folds are selected so that the mean response value is approximately equal in all the folds. In the case of a dichotomous classification, this means that each fold contains roughly the same proportions of the two types of class labels\n",
    "#### 7.**classification_report**: Visual classification reports are used to compare classification models to select models that are “redder”, e.g. have stronger classification metrics or that are more balanced.\n",
    "#### 8.**confusion_matrix**: A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.\n",
    "#### 9.**accuracy_score**: It is the ratio of number of correct predictions to the total number of input samples\n",
    "#### 10.**LogisticRegression**: an algorithm for classification\n",
    "#### 11.**DecisionTreeClassifier**: create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "#### 12.**KNeighborsClassifier**: for classification\n",
    "#### 13.**LinearDiscriminantAnalysis**: used for modeling differences in groups i.e. separating two or more classes\n",
    "#### 14.**GaussianNB**: an algorithm that estimates the mean and the standard deviation from your training data,\n",
    "#### 15.**SVC**: an algorithm that creates a line or a hyperplane which separates the data into classes\n",
    "#### 16.**RandomForestClassifier**: Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting\n",
    "#### 17.**SGDClassifier**: Stochastic Gradient Descent Classifier (SGDC) is an incremental Gradient Descent method falling under the broad classification of Supervised Learning Model that helps converge faster and is thus very fast as compared to other iterative models capable of delivering similar performance\n",
    "#### 18.**NearestCentroid**: assigns to observations the label of the class of training samples whose mean (centroid) is closest to the observation\n",
    "#### 19.**MLPClassifier**:  It can distinguish data that is not linearly separable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this suprreses unnecesary warnings from my output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading My Dataset\n",
    "\n",
    "##### I am going to first use my training dataset, then the test dataset last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas.read_csv('/kaggle/input/ace-class-assignment/AMP_TrainSet.csv')#reading in my train dataset\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pandas.read_csv('/kaggle/input/ace-class-assignment/Test.csv') #reading in my test dataset\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting my train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape #a tuple that gives you an indication of the number of dimensions in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()  ###this will show the number of null values in my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.count()  #returns number of non-null values in my data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It seems i have no missing values in my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()  #returns summary of the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info() #It returns range, column, number of non-null objects of each column, datatype and memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This shows that my dataset has 3038 rows (instances) and 12 columns (attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I will also take a look at how many instances i have for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('CLASS').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('CLASS').size().plot(kind='bar') #i can also show this in a graph form\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have two groups of classes, each with 1519 instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will start with univariate plots to see each individual variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing using histograms\n",
    "train.hist(figsize=(16,16))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These histograms show that FullAcidicMolPerc is exponentially distributed while the rest are have a Gaussian distribution except for NT_EFC195 and CLASS. Histograms also help us identify outliers. From this output, I can say there are no outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr(method='pearson')['CLASS'] #Here I tried to see the correlation of all attributes with the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### According to literature,Pearson’s correlation coefficient is the test statistics that measures the statistical relationship, or association, between two continuous variables.  It is known as the best method of measuring the association between variables of interest because it is based on the method of covariance.  It gives information about the magnitude of the association, or correlation, as well as the direction of the relationship.\n",
    "\n",
    "### So from the above results, i can see that most attributes have a negative correlation with the class. Only two have a high degree of correlation as they are between +o.5 and +1.0. AS_FUKS010112 has moderate corrlation as the range is between 0.30-0.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a heatmap to show correlation of data\n",
    "pyplot.figure(figsize=(10,10))\n",
    "sns.heatmap(train.corr(method='pearson'))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i did this plot in order to see which features are highly correlated as this can be a problem in soome models if some features are used together whereas they are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A scatter plot shows the relationship between two variables as dots in two dimensions. So from this output, i can be able to see the relationship between variables. If they show a good correlation, then they ccan be removed in feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATING ALGORITHMS\n",
    "#### I will now evaluate some algorithms and estimate their accuracy on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will first split my train data into test and train, so that I test the effectiveness of my model using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train.values #first create a variable for extracting the values from the train dataset to be used\n",
    "X = array[:,0:11]  #selecting which columns to use, in this case all of them\n",
    "Y = array[:,11] #selecting the label for our data, which is the last column\n",
    "test_size = 0.32 #this is the size of my test data, meaning my train data is 68%\n",
    "seed = 3 #this is to initialize the random generator, to ensure i get the same numbers each time.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING MODELS\n",
    "\n",
    "#### I will now use the models I imported in the beginning from sklearn to use for my algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RTC', RandomForestClassifier()))\n",
    "models.append(('SGD',SGDClassifier()))\n",
    "models.append(('NC', NearestCentroid()))\n",
    "models.append(('MLPC',MLPClassifier()))\n",
    "models.append(('GBC', GradientBoostingClassifier()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from here, RTC is the best performing, followed by gradient boosting then NB.\n",
    "\n",
    "### Irecently added Gradient boosting. It relies on the intuition that the best possible next model, when combined with previous models, minimizes the overall prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset, using my selected model from above(NB)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print('MCC', matthews_corrcoef(model.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset, using my selected model from above(RTC)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print('MCC', matthews_corrcoef(model.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The MCC gives a score close to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset, using my selected model from above(GBC)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "print('MCC', matthews_corrcoef(model.predict(X_test), Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will now test the performance of my model first using all the features, then with some selected ones to see if my performance increases or decreases with either the addition of or dropping of some features.\n",
    "#### I started with all features because my features are not that much for me to consider dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with all features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "array = train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This gives me a good score of 93.6%. I will now try selecting some features based on feature importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This will be my first submission. It gave me a score of 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=train.CLASS\n",
    "X=train.drop(\"CLASS\",axis=1)\n",
    "OUTPUT=model.fit(X, Y).predict(test.values)\n",
    "OUTPUT_1=pandas.DataFrame(OUTPUT)\n",
    "OUTPUT_1.columns=[\"CLASS\"]\n",
    "OUTPUT_1.index.name=\"Index\"\n",
    "OUTPUT_1[\"CLASS\"]=OUTPUT_1[\"CLASS\"].map({0.0:False,1.0:True})  #changing 0 values to False, 1 to True\n",
    "OUTPUT_1.to_csv(\"output\") #converting my output file into a csv\n",
    "print(OUTPUT_1[\"CLASS\"].unique()) #printing out the unique values, i expect to get 2\n",
    "print(OUTPUT_1[\"CLASS\"].nunique()) #the sum of unique values\n",
    "print(OUTPUT_1.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_1.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection using feature importance\n",
    "X = train.iloc[:,0:11]  #independent columns\n",
    "y = train.iloc[:,-1]    #target column\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will select the features with the highest bars. The number of features selected will depend on the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "newtrain=train.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)\n",
    "newtest=test.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)\n",
    "array = newtrain.values\n",
    "X = array[:,0:5]\n",
    "Y = array[:,-1]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new=newtrain.CLASS\n",
    "X_new=newtrain.drop(\"CLASS\",axis=1)\n",
    "OUTPUT=model.fit(X_new, Y_new).predict(newtest.values)\n",
    "OUTPUT_new=pd.DataFrame(OUTPUT)\n",
    "OUTPUT_new.columns=[\"CLASS\"]\n",
    "OUTPUT_new.index.name=\"Index\"\n",
    "OUTPUT_new[\"CLASS\"]=OUTPUT_new[\"CLASS\"].map({0.0:False,1.0:True})\n",
    "OUTPUT_new.to_csv(\"out1\")\n",
    "print(OUTPUT_new[\"CLASS\"].unique())\n",
    "print(OUTPUT_new[\"CLASS\"].nunique())\n",
    "print(OUTPUT_new.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_new.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This gave me a score of 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how i checked the accuracy from the features selected\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "array = train.values\n",
    "X = array[:,[0,2,3,5,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i will now select 6 features to see if my score improves\n",
    "\n",
    "array = train.values\n",
    "X = array[:,[0,1,2,3,5,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the accuracy deacreases. let me try 4 features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = train.values\n",
    "X = array[:,[1,2,3,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy deacreases even further. so if i weere to feature select, I would use 5 features because they give me the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let me try the RTC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with all features\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "array = train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this actually gives me a better score than the one from GaussianNB. Let me submit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new2=train.CLASS\n",
    "X_new2=train.drop(\"CLASS\",axis=1)\n",
    "OUTPUT2=model.fit(X_new2, Y_new2).predict(test.values)\n",
    "OUTPUT_new1=pd.DataFrame(OUTPUT2)\n",
    "OUTPUT_new1.columns=[\"CLASS\"]\n",
    "OUTPUT_new1.index.name=\"Index\"\n",
    "OUTPUT_new1[\"CLASS\"]=OUTPUT_new1[\"CLASS\"].map({0.0:False,1.0:True})  #changing 0 values to False, 1 to True\n",
    "OUTPUT_new1.to_csv(\"outputRTC\") #converting my output file into a csv\n",
    "print(OUTPUT_new1[\"CLASS\"].unique()) #printing out the unique values, i expect to get 2\n",
    "print(OUTPUT_new1[\"CLASS\"].nunique()) #the sum of unique values\n",
    "print(OUTPUT_new1.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_new1.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This gave me a score of 83%. let me feature select the 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "array = train.values\n",
    "X = array[:,[0,2,3,5,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### this gives me a lower score than when all features are selected. So i will stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with all features\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "array = train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission with all features\n",
    "Y_new4=train.CLASS\n",
    "X_new4=train.drop(\"CLASS\",axis=1)\n",
    "OUTPUT4=model.fit(X_new4, Y_new4).predict(test.values)\n",
    "OUTPUT_new4=pd.DataFrame(OUTPUT4)\n",
    "OUTPUT_new4.columns=[\"CLASS\"]\n",
    "OUTPUT_new4.index.name=\"Index\"\n",
    "OUTPUT_new4[\"CLASS\"]=OUTPUT_new4[\"CLASS\"].map({0.0:False,1.0:True})  #changing 0 values to False, 1 to True\n",
    "OUTPUT_new4.to_csv(\"outputGBC\") #converting my output file into a csv\n",
    "print(OUTPUT_new4[\"CLASS\"].unique()) #printing out the unique values, i expect to get 2\n",
    "print(OUTPUT_new4[\"CLASS\"].nunique()) #the sum of unique values\n",
    "print(OUTPUT_new4.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_new4.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This gave me a score of 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "array = train.values\n",
    "X = array[:,[0,2,3,5,7]]\n",
    "Y = array[:,11]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i get accuracy of 92,4 if i choose 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission with dropped\n",
    "train.columns\n",
    "newtrain2=train.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)\n",
    "newtest2=test.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)\n",
    "array2 = newtrain2.values\n",
    "X2 = array2[:,0:5]\n",
    "Y2 = array2[:,-1]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X2, Y2, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns\n",
    "newtrain=train.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)\n",
    "newtest=test.drop([  'FULL_AURR980107', 'FULL_OOBM850104', 'NT_EFC195', 'AS_DAYM780201', 'AS_FUKS010112', 'CT_RACS820104'], axis=1)\n",
    "array = newtrain.values\n",
    "X = array[:,0:5]\n",
    "Y = array[:,-1]\n",
    "test_size = 0.32\n",
    "seed = 3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_new=newtrain.CLASS\n",
    "X_new=newtrain.drop(\"CLASS\",axis=1)\n",
    "OUTPUT=model.fit(X_new, Y_new).predict(newtest.values)\n",
    "OUTPUT_new=pd.DataFrame(OUTPUT)\n",
    "OUTPUT_new.columns=[\"CLASS\"]\n",
    "OUTPUT_new.index.name=\"Index\"\n",
    "OUTPUT_new[\"CLASS\"]=OUTPUT_new[\"CLASS\"].map({0.0:False,1.0:True})\n",
    "OUTPUT_new.to_csv(\"RTC_DROP\")\n",
    "print(OUTPUT_new[\"CLASS\"].unique())\n",
    "print(OUTPUT_new[\"CLASS\"].nunique())\n",
    "print(OUTPUT_new.groupby(\"CLASS\").size()[0].sum())\n",
    "print(OUTPUT_new.groupby(\"CLASS\").size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBC gave me a score of 81%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
