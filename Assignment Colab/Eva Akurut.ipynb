{"cells":[{"metadata":{},"cell_type":"markdown","source":"### ACE_COMPETITION\n#### Exploration Data Analysis assignment\n1)Import the datasets into the notebook\n2)Find out the Dimensions of the data imported\n3)Descibe the data using statistics(Descriptive statistics)\n4)Looking at how the variables correlate with each other\n5)Data Visualisation\n6)Preparation of data for Machine Learning\n7)Evaluate the Performance of Machine Learning Algorithms with Resampling\n8)Spot-Checking Classiffication Algorithms"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing the tools to use for the assignment\nimport numpy as np # linear algebra\nimport pandas as pd # data structure analysis\nimport matplotlib.pyplot as plt # for visualisation\nimport seaborn as sns#\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1)Loading the data to be used into my notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"###Importing the data sets into the notebook using read.csv\nTrain=pd.read_csv(\"../input/ace-class-assignment/AMP_TrainSet.csv\")\nTest=pd.read_csv(\"../input/ace-class-assignment/Test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2)Checking the dimensions of my data\nThis sumarries the data type,Number of columns and rows,if the data has missing values "},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.head(5)\n# To check the first 5 rows on my dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the datatype of of my data to determine the class of my data\nTrain.dtypes ,Test.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding out the rows and columns present in my data set \nTrain.shape , Test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing the summary of the data frame\n# Summary includes list of all columns with their data types and the number of non-null values in each column. \n#we also have the value of rangeindex provided for the index axis.\nTrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Printing the column names to get to know the names of the columns\nTrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In general, both the train and Test datasets have float and intenger data types\n#The Train Data set has 3038 rows and 12 columns\n# The Test Data set has 758 rows plus 11 columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3)Descriptive statistics\nDescriptive statistics can give you great insight into the shape of each attribute.\n\nOften you can create more summaries than you have time to review. The describe() function on the Pandas DataFrame lists 8 statistical properties of each attribute:\nCount,Mean,Standard Devaition,Minimum Value,25th Percentile,50th Percentile (Median),75th Percentile,Maximum Value.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Getting the spread of my data\nTrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting my data into by classfication to find out how balanced the v\n#A groupby operation involves a combination of splitting the object, \n#Then application of a function, and combining the results.\nTrain.groupby(\"CLASS\").size().plot(kind=\"bar\")                             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x = 'FULL_Charge', data = Train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4)Checking how my data correlates with each other \nIn statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data.\nHere the intension was to find out if there is a relationship**** between the variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr=Train.corr(method='pearson')\ncorr\n# The correllation 1 is a positive relationship, -1 a negative relationship and 0 no relationship","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(Train.corr(method='pearson'),annot=True,cmap=\"YlGnBu\")\n#Heatmap is a way of representing the data in a 2-dimensional form. The data values are represented as colors in the graph. \n#It's goal is to provide a colored visual summary of information\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For more depth of understanding the data the clustermap method is used \n#The .clustermap() method uses a hierarchical clusters to order data by similarity.\n#This reorganizes the data for the rows and columns and displays similar content next to one another \n\nsns.clustermap(Train.corr(method='pearson'),annot=True, cmap=\"Paired_r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Showing how each variable correlates with the CLASS variable\nTrain.corr(method='pearson')['CLASS']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5)Data Visualisation\n*Data visualizations in python can be done via many packages.\n*Using matplot enables one to have a visual figures for the data\n*Every Axes has an x-axis and y-axis for plotting. \n*Contained within the axes are titles, ticks, labels associated with each axis\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#1)To check for skewness in my dataset\n#Skew refers to a distribution that is assumed Gaussian (normal or bell curve) that is shifted in one direction or another\nTrain.skew().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2) Use of the box plot\n#Boxplots summarize the distribution of each attribute\n#A line for the median (middle value) is drawn while and a box put around the 25th and 75th percentiles.\n#The whiskers give an idea of the spread of the data and dots outside of the whiskers show candidate outlier values \n# Box plots\nTrain.plot(kind='box', subplots=True, layout=(4,3), sharex=True,sharey=True)\nplt.subplots_adjust(bottom=1, right=2, top=3)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#3) Scatter plot: This is to relationship between two variables as dots in two dimension.\n#This is done so we could spot if there is a structured relationship within the two variables\nsns.pairplot(data=Train[['FULL_Charge','FULL_DAYM780201','FULL_OOBM850104', 'NT_EFC195',\n       'AS_MeanAmphiMoment','CLASS']])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Histograms\nplt.figure(figsize=(15,15))\nTrain.hist(color='red')\n\nplt.subplots_adjust(bottom=1, right=2, top=3)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6)Preparation of data for Machine Learning\nPre-processing of Data is carried out in this section\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#1) I will need to preapre my data for prepossessing \n# My preffered method for Data transformation is \"The Fit and Multiple Transform\" method form the scikit-learn library.\n#Split the dataset into the input and output variables for machine learning.\n#Apply a pre-processing transform to the input variables.\n#Summarize the data to show the change.\n#Rescaling the Data:Since the attributes have varying scales\n\nfrom numpy import set_printoptions\nfrom sklearn.preprocessing import MinMaxScaler\n\narray = Train.values\n# separate array into input and output components\nX= array[:,0:11]\nY= array[:,11]\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = scaler.fit_transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(rescaledX[0:5,:])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looking at when my data is binarized instead\nfrom sklearn.preprocessing import Binarizer\n\narray2 = Train.values\n# separate array into input and output components\nX = array2[:,0:11]\nY = array2[:,11]\nbinarizer = Binarizer(threshold=0.0).fit(X)\nbinaryX = binarizer.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(binaryX[0:5,:])\n\n#NB:This binarised data was not used ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#b) Feature Selection\n#Select an anttribute will will give the most to the prediction variable \n#a)Selection is by The Recursive Feature Elimination (or RFE) \n# This works by recursively removing attributes and building a model on those attributes that remain.\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\n# feature extraction\n# feature extraction\nmodel = LogisticRegression()\nrfe = RFE(model, 6)\nfit = rfe.fit(X, Y)\nprint(\"Num Features: \",  fit.n_features_)\nprint(\"Selected Features:\",  fit.support_)\nprint(\"Feature Ranking: \",  fit.ranking_)\nprint(\"Num Features: \",  fit.n_features_)\nprint(\"Selected Features:\",  fit.support_)\nprint(\"Feature Ranking: \",  fit.ranking_)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\narray = Train.values\nX = array[:,0:11]\nY = array[:,11]\n# feature extraction\npca = PCA(n_components=3)\nfit = pca.fit(X)\n# summarize components\nprint(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\nprint(fit.components_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature importance\nfrom sklearn.ensemble import ExtraTreesClassifier\n\narray = Train.values\nA = array[:,0:11]\nB = array[:,11]\n# feature extraction\nmodel = ExtraTreesClassifier()\nmodel.fit(A, B)\nprint(model.feature_importances_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## According to feature importance all the features in the data set were useful hence could not be lost and therefore i kept them all","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7)Evaluate the Performance of Machine Learning Algorithms with Resampling\n##There is need to know how well the algorithms will perform on unseen data\n##The best way to evaluate the performance of an algorithm is to make predictions for new data to which  answers are known\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Split the  Data into Test and Train\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\ntest_size = 0.35\nseed = 7\n\nX_train,X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\nrandom_state=seed)\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\nresult = model.score(X_test, Y_test)\nprint(\"Accuracy: \",  (result*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# On rescaled Data\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\narray = Train.values\nX = array[:,0:11]\nY = array[:,11]\ntest_size = 0.35\nseed = 7\n\nrescaledX_train,rescaledX_test, Y_train, Y_test = train_test_split(rescaledX, Y, test_size=test_size,\nrandom_state=seed)\nmodel = LogisticRegression()\nmodel.fit(rescaledX_train, Y_train)\nresult = model.score(rescaledX_test, Y_test)\nprint(\"Accuracy: \",  (result*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber1_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Despite having a similar accuracy of 91.82,the rescaled data was giving imbalanced false a.nd true values and therefore i would not use it further","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification accuracy:is the number of correct predictions made as a ratio of all predictions made.\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\n\narray = Train.values\n\nnum_folds = 20#number of folds to use\nseed = 7#reproducibility\n\nkfold = KFold(n_splits=num_folds, random_state=None)\nmodel = LogisticRegression()\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\nrandom_state=seed)\nmodel.fit(X_train, Y_train)\nresults = cross_val_score(model, X, Y, cv=kfold)\n\nprint(f\"Accuracy:\", (results.mean()*100.0, results.std()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber2_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#To check out the classification report \nfrom sklearn.metrics import classification_report\n\narray = Train.values\nX = array[:,0:11]\nY = array[:,11]\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledA = scaler.fit_transform(A)\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledA = scaler.fit_transform(A)\ntest_size = 0.35\nseed = 7\nrescaledX_train,rescaledX_test, Y_train, Y_test = train_test_split(rescaledX, Y, test_size=test_size,\nrandom_state=seed)\nmodel = LogisticRegression()\nmodel.fit(rescaledX_train, Y_train)\npredicted = model.predict(rescaledX_test)\nreport = classification_report(Y_test, predicted)\nprint(report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we then look at the regression M\n# The Mean Absolute Error(MAE) is the sum of the absolute differences between predictions and actual values.\n# Its aim is to give an idea of how wrong the predictions were. \nfrom pandas import read_csv\nfrom sklearn.linear_model import LinearRegression\narray = Train.values\nX = array[:,0:11]\nY = array[:,11]\nkfold = KFold(n_splits=10, random_state=None)\nmodel = LinearRegression()\nscoring = 'neg_mean_absolute_error'\nresults = cross_val_score(model, rescaledX, Y, cv=kfold, scoring=scoring)\nprint(\"MAE:\",(results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The R2 metric provides an indication of the goodness of fit of a set of predictions to the actual values\n#Cross Validation Regression R^2\narray = Train.values\nX = array[:,0:11]\nY = array[:,11]\n\nkfold = KFold(n_splits=10, random_state=None)\nmodel = LinearRegression()\nscoring = 'r2'\nresults = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\nprint(\"R^2:\",(results.mean(), results.std()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8)Spot-Checking Classiffication Algorithms\n##Algorithms Overview\n##looking at six classication algorithms that will help spot-check on your dataset. Starting with two ##linear machine learning algorithms:\n\n8.1.1)Logistic Regression.\n8.1.2)Linear Discriminant Analysis.\nThen looking at four nonlinear machine learning algorithms:\n\n8.2.1)k-Nearest Neighbors.\n8.2.2)Naive Bayes.\n8.2.3)Classication and Regression Trees.\n8.2.4)Support Vector Machines.\n8.2.5)Random Forest\n8.2.6)Gradient Boosting for classification\n8.2.7)An extra-trees classifier.\n8.2.8)Neural Network-MLPC"},{"metadata":{},"cell_type":"markdown","source":" ## 8.1)Linear Machine Language Alogarithms\n### 8.1.1)Logistic Regression\nLogistic regression assumes a Gaussian distribution for the numeric input variables and can model binary classiffication problems.\n****This is done using the Logisticregression class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Classification\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.metrics import plot_confusion_matrix\n\n#for model set up\nmodel = LogisticRegression()\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the LogisticRegression predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber3_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The difference between Accuracy and MCC model is slight but giving the same output pf 383 True values and 375 false values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.1.2)Linear Discriminant Analysis or LDA \n-This a statistical technique for binary and multiclass classiffication. \n-It too assumes a Gaussian distribution for the numerical input variables. \n-You can construct an LDA model using the LinearDiscriminantAnalysis class"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n#Model set up\nmodel = LinearDiscriminantAnalysis()\n# For cross validation of data\nnum_folds = 10\nseed=9\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the  LinearDiscriminantAnalysis predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber4_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8.2 Nonlinear machine learning algorithms.\n\n### 8.2.1)k-Nearest Neighbors\n##The k-Nearest Neighbors algorithm (or KNN) uses a distance metric to find the k most similar instances ##In the training data for a new instance and takes the mean outcome of the neighbors as the prediction. #You can construct a KNN model using the KNeighborsClassifier class."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n#Model set up\nmodel = KNeighborsClassifier()\n# For cross validation of data\nnum_folds = 5\nseed=8\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the  LinearDiscriminantAnalysis predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber5_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.2.2) Naive Bayes\n-Naive Bayes calculates the probability of each class and the conditional probability of each class given each input value. \n-These probabilities are estimated for new data and multiplied together\n-The Assumption is that they are all independent (a simple or naive assumption).\n-When working with real-valued data, a Gaussian distribution is assumed to easily estimate the probabilities for input variables using the Gaussian Probability Density Function. \n##You can construct a Naive Bayes model using the GaussianNB class4"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = GaussianNB()\n\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the  Naive Bayes predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber5_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8.2.3)Classiffication and Regression Trees\nClassiffication and Regression Trees (CART or just decision trees) construct a binary tree from the training data. Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index). You can construct a CART model using the DecisionTreeClassifier class"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = DecisionTreeClassifier()\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the DecisionTreeClassifier  predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber6_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8.2.4)Support Vector Machines\nSupport Vector Machines (or SVM) seek a line that best separates two classes. \nThe data instances closest to the line that best separates the classes are called support vectors and \ninfluence where the line is placed. \nSVM supports multiple classes and that of particular importance is the use of dierent kernel functions via the kernel parameter."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = SVC()\n\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the SVC predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber7_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.2.5)Random Forest\nRandom forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\nRandom decision forests correct for decision treesâ€™ habit of over fitting to their training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = RandomForestClassifier(bootstrap = True,\n                              max_features = None)\n\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the Randomforest predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber8_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.2.6)Gradient Boosting for classification.\nGB builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. \nIn each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function.\nBinary classification is a special case where only a single regression tree is induced."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = GradientBoostingClassifier(learning_rate = 1.0,\n                              max_depth = 1)\n\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the GradientBoostingClassifier predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber9_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.2.7)An extra-trees classifier.\nThis class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset.\nIt uses averaging to improve the predictive accuracy and control over-fitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = ExtraTreesClassifier()                              \n\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the ExtratreeClassifier predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber10_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8.2.8)Multi-layer Perceptron classifier.\nThis model optimizes the log-loss function using LBFGS or stochastic gradient descent."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n# For cross validation of data\nnum_folds = 10\nseed=7\nkfold = KFold(n_splits=num_folds, random_state=seed,shuffle=True)\nmodel = MLPClassifier()                              \n\n#For accuracy of model\nscoring='accuracy'\nresults = cross_val_score(model, X, Y, cv=kfold,scoring=scoring)\nprint('accuracy',results.mean()*100)\n#Training the model to make a prediction\nmodel.fit(X,Y)\nkmodel=model.predict(Test)\n#With Mathews correlation cofficient on the model\nkmcc=matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',kmcc)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting the MLPClassifier predicted model first to data frame then a CSV file\nout= model.predict(Test.values)\n\nEva = pd.DataFrame(out) #Converting to data frame\nEva.columns=[\"CLASS\"] #Naming the column\nEva.index.name=\"Index\" #Creating a column index\nEva[\"CLASS\"]=Eva[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\nEva.to_csv(\"Amber11_csv\") ## Writing a csv file\nprint(Eva['CLASS'].unique())\nprint(Eva['CLASS'].nunique())\n\n#printing the numbers of False and True\nprint(Eva.groupby('CLASS').size()[0].sum()) #\nprint(Eva.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 9)Compare Machine Learning Algorithms\nIt is important to compare the performance of multiple different machine learning algorithms consistently.  The test harness as a template on your own machine learning problems and add more and different algorithms to compare."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare Algorithms\nfrom matplotlib import pyplot\n# prepare models and add them to a list\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))\nmodels.append(('MLPC', MLPClassifier()))\nmodels.append(('EXTC', ExtraTreesClassifier()))\nmodels.append(('GBC', GradientBoostingClassifier()))\nmodels.append(('RDF', RandomForestClassifier()))\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# boxplot algorithm comparison\nfig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From the alogarithms above the best was the Gausian Naive Bayes with the highest mean value pf 0.88 followed by LDA with 0.85\n# The least fit alogarith was DecisionTreeClassifier(0.72)followed by GradientBoostingClassifier at (0.79)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}