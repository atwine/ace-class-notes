{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#First importing the necessary libraries helpful in building and/or testing the model\n#Three main libraries for a start: numpy, pandas, matplotlib.pyplot\n#numpy is for linear algebra, pandas for data processing\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Kintu Christopher\n## This is my assignment.\n## I am in to win the competition\n\n```import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))```\n        \n \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Input data files necessary for this assignment were obtained from \"../input/\" directory.\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ignoring warnings: It is necessary to import while ignoring warnings\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The data sets are loaded and read as below in form of csv files\nTrain = pd.read_csv(\"../input/ace-class-assignment/AMP_TrainSet.csv\")\nTest = pd.read_csv(\"../input/ace-class-assignment/Test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data visualization\n## The data is loaded for viewing directly from the ACE_class_Assignment folder. This displays, in tabular format, the real values we are to work with."},{"metadata":{"trusted":true},"cell_type":"code","source":"#There is need to know how many dimensions our data has\n# This helps me to know how many rows or columns are in each data set and also how large the data set is.\n#Too many rows and columns require a longer time to train the model.\n\nTrain.shape, Test.shape\n\n# The Train data set has 12 columns and 3038 rows. \n# The Test data set has 758 rows and 11 columns\n#This means our Train data is large enough to train the algorithm without over training or under training","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking the column variables for the Train data set\n#This gives me an idea of the variables I am dealing with and how they are labelled.\n\nTrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Similarly, checking for column variables for the Test data set\n\nTest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It is good to also take a look at they data types for each data set. \n#Just incase there are strings that need to be converted into floats \n\n#First, the train data set\nTrain.dtypes\n\n#The data type of the train set is an object\n#The column variables are all floats and integers as shown below","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Similarly, for the Test data set\n\nTest.dtypes\n\n#It is an object, with floats and integers only. \n#This is good, we dont need to change anything.\n#We are good to go.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking for quick statistical comparisons\n## This will quickly give me a view of the relationship between variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"#We check out quick summary statistics for both data sets\n\nTrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#summary statistics for the Test data set too\n\nTest.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Attribute Correlations\n## It is important to check whether different attributes have a positive or negative correlation or none."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Assuming a Gaussian distribution for both data stes; we shall use the pearson correlation\n\nTrain.corr(method = 'pearson')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Correlation on the Test data set\n\nTest.corr(method = 'pearson')\n\n#A quci eyeball shows all variables have some form of correlation to each other. \n#There is no variable with zero correlation to another","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting the data\n## Upon noticing some correlation, it is good to cisualize it in a heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualizing correlations between attributes using heatmaps\n#import the necessary library; seaborn\n\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot a heat map for the Test data set\nplt.figure(figsize=(6,6))\nsns.heatmap(Test.corr(method='pearson'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heat map for the Train data set\nplt.figure(figsize=(6,6))\nsns.heatmap(Train.corr(method='pearson'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing for skewness of variables\n# This will be important incase some variables are skewed either positively or negatively since we are assuming a Gaussian distribution. Correcting for this skewness improves on the accuracy of the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Skewness of distributions on the Train data set\nTrain.skew().plot(kind= 'bar')\n\n#The NT_EFC195 show a high right skew (above 1).\n#We shall have to correct for this to improve the model accuracy\n#This we shall do by finding the square root, cube root or a logarithmic transformation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Testing for skewness on the Train Data set\n\nTest.skew().plot(kind= 'bar')\n\n# This data set also has a high positive skew for the NT_EFC195 variable as well","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding my data\n# Different plots will give me a good insight into what to do next with the data I have.Plots like histograms, scatter plots are good to give a genearl view"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting a histogram for the Train Data\n\nplt.figure(figsize=(15,15))\nTrain.hist()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Plotting a histogram for the Test Data\n\nplt.figure(figsize=(15,15))\nTest.hist()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rug plots\n#The rugplots are like histograms except they show every single data point on the x-axis, allowing us to visualize all of the actual values\n#Both the Train and Test rugplots indicate some kind of left skew. This we need to take into account when designing the model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(Train, hist = False, kde = True, rug = True, color = 'darkblue', kde_kws={'linewidth': 3}, rug_kws={'color': 'black'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(Test, hist = False, kde = True, rug = True, color = 'darkblue', kde_kws={'linewidth': 3}, rug_kws={'color': 'black'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plots","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train\nTrain.plot(kind='box', subplots=True, layout=(12,12), sharex=False, sharey=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test\nTest.plot(kind='box', subplots=True, layout=(12,12), sharex=False, sharey=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scatter Plot matrix\n#scatter plot matrix shows the relationship between two variables as dots in two dimensions all at once","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sns.pairplot(Train)\n#The scatter plot for the train dataset indicates a mixture of correlations for different variables. \n#Some have a positive strong correlation, others a negative correlation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test data scatter plot\n#sns.pairplot(Test)\n#Similarly, some have aa positive correlation and negative correlation between different paired variables","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Data for machine learning"},{"metadata":{},"cell_type":"markdown","source":"# Rescaling Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rescaling\n#Since I might use features like regression and neural networks and algorithms that use distance measures like k-Nearest Neighbors. \n#I need to rescale my data using scikit-learn using the MinMaxScaler class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We rescale to make sure all our data values lie in a scale from 0 to 1\n#from numpy import set_printoptions\n#from sklearn.preprocessing import MinMaxScaler\n\n#array = Train.values\n# separate array into input and output components\n#X = array[:,0:11]\n#Y = array[:,11]\n#scaler = MinMaxScaler(feature_range=(0, 1))\n#rescaledX = scaler.fit_transform(X)\n# summarize transformed data\n#set_printoptions(precision=3)\n#print(rescaledX[0:5,:])\n\n#Indeed all our data values have been rescaled","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# standardization of data\n```from sklearn.preprocessing import StandardScaler\n\narray2 = data.values\n#separate array into input and output components\nX = array2[:,0:8]\nY = array2[:,8]\nscaler = StandardScaler().fit(X)\nrescaledX = scaler.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(rescaledX[0:5,:])\n```\n\n# Normalization of data\n``from sklearn.preprocessing import Normalizer\n\narray3 = data.values\n#separate array into input and output components\nX = array3[:,0:8]\nY = array3[:,8]\nscaler = Normalizer().fit(X)\nnormalizedX = scaler.transform(X)\n#summarize transformed data\nset_printoptions(precision=3)\nprint(normalizedX[0:5,:])\nprint(type(normalizedX))#print the data type so we can know what we are \n#working with in the dataset.\n```\n\n```# Binarizing data\nfrom sklearn.preprocessing import Binarizer\n\narray4 = data.values\n#separate array into input and output components\nX = array4[:,0:11]\nY = array4[:,11]\nbinarizer = Binarizer(threshold=0.0).fit(X)\nbinaryX = binarizer.transform(X)\n#summarize transformed data\nset_printoptions(precision=3)\nprint(binaryX[0:5,:])\n```\n\n"},{"metadata":{},"cell_type":"markdown","source":"# using Standardized generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#standardizing data\n#from sklearn.preprocessing import StandardScaler\n\n#array2 = Train.values\n# separating array into input and output components\n#X = array2[:,0:11]\n#Y = array2[:,11]\n#scaler = StandardScaler().fit(X)\n#rescaledX = scaler.transform(X)\n\n# summarizing transformed data\n#set_printoptions(precision=3)\n#print(rescaledX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Binarizing data\n## This will help incase there are probabilities in the data that need to be turned into crisp values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# binarization\n# It will turn data into 0s and 1s\nfrom numpy import set_printoptions\nfrom sklearn.preprocessing import Binarizer\n\narray4 = Train.values\n# separate array into input and output components\nX = array4[:,0:11]\nY = array4[:,11]\nbinarizer = Binarizer(threshold=0.0).fit(X)\nbinaryX = binarizer.transform(X)\n# summarize transformed data\nset_printoptions(precision=3)\nprint(binaryX[0:7,:]) #I am selecting the 7 best attributes out of the 11 to cover atleast 50% of the selected attributes\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Using the Recursive elimination\n#from sklearn.feature_selection import RFE\n#from sklearn.linear_model import LogisticRegression\n\n#array_1 = Train.values\n#X = array_1[:,0:11]\n#Y = array_1[:,11]\n\n# Extracting features\n#model = LogisticRegression()\n#rfe = RFE(model, 3)\n#fit = rfe.fit(X, Y)\n#print(\"Num Features: \",  fit.n_features_)\n#print(\"Selected Features:\",  fit.support_)\n#print(\"Feature Ranking: \",  fit.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#evaluating perfomance\n#from sklearn.model_selection import train_test_split\n#from sklearn.linear_model import LogisticRegression\n\n#array = Train.values\n#X = array[:,0:11]\n#Y = array[:,11]\n#test_size = 0.33\n#seed = 10\n#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n#model = LogisticRegression()\n#model.fit(X_train, Y_train)\n#result = model.score(X_test, Y_test)\n#print(\"Accuracy: \",  (result*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#out = model.predict(Test.values)\n\n#KC = pd.DataFrame(out) #Converting to data frame\n#KC.columns=[\"CLASS\"] #Naming the column\n#KC.index.name=\"Index\" #Creating a column index\n#KC[\"CLASS\"]=KC[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\n#KC.to_csv(\"KC_csv\") ## Writing a csv file\n#print(KC['CLASS'].unique())\n#print(KC['CLASS'].nunique())\n\n#printing the numbers of False and True\n#print(KC.groupby('CLASS').size()[0].sum()) #\n#print(KC.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.preprocessing import StandardScaler\n\n#array2 = Train.values\n# separating array into input and output components\n#X = array2[:,0:11]\n#Y = array2[:,11]\n#scaler = StandardScaler().fit(X)\n#rescaledX = scaler.transform(X)\n# transformed data should be summarized using the code below\n#set_printoptions(precision=3)\n#print(rescaledX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Principal Component analysis feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training the model using PCA as the feature of choice\n#from sklearn.decomposition import PCA\n\n#array = Train.values\n#X = array[:,0:11]\n#Y = array[:,11]\n\n# feature extraction\n#pca = PCA(n_components=3)\n#fit = pca.fit(X)\n# summarize components\n#print(\"Explained Variance: \" , fit.explained_variance_ratio_)\n#print(fit.components_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Output model using PCA as the feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"#out = model.predict(Test.values)\n\n#KC2 = pd.DataFrame(out) #Converting the data to data frame\n#KC2.columns=[\"CLASS\"] #Naming the column\n#KC2.index.name=\"Index\" #Creating a column index\n#KC2[\"CLASS\"]=KC2[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\n#KC2.to_csv(\"KC2_csv\") # obtaininng a csv file\n#print(KC2['CLASS'].unique())\n#print(KC2['CLASS'].nunique())\n\n#printing the numbers of False and True\n#print(KC2.groupby('CLASS').size()[0].sum()) #\n#print(KC2.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(\"Hello\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# sklearn.feature_selection.SelectFromModel\n## Parameters for the model\n\n### estimator: object\n```The base estimator from which the transformer is built. This can be both a fitted (if prefit is set to True) or a non-fitted estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting.\nFeatures whose importance is greater or equal are kept while the others are discarded. If “median” (resp. “mean”), then the threshold value is the median (resp. the mean) of the feature importances. A scaling factor (e.g., “1.25*mean”) may also be used. If None and if the estimator has a parameter penalty set to l1, either explicitly or implicitly (e.g, Lasso), the threshold used is 1e-5. Otherwise, “mean” is used by default.\nWhether a prefit model is expected to be passed into the constructor directly or not. If True, transform must be called directly and SelectFromModel cannot be used with cross_val_score, GridSearchCV and similar utilities that clone the estimator. Otherwise train the model using fit and then transform to do feature selection.```"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\n\narray6 = Train.values\nX = array6[:,0:11]\nY = array6[:,11]\n\n#fitting to the model\nselector = SelectFromModel(estimator=LogisticRegression()).fit(X, Y)\nselector.estimator_.coef_\narray6\nselector.threshold_\n\nselector.get_support()\narray6\nselector.transform(X)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Logistic model output"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model2 = model.predict(Test.values)\n\n#KC3 = pd.DataFrame(model2) #Converting the data to data frame\n#KC3.columns=[\"CLASS\"] #Naming the column\n#KC3.index.name=\"Index\" #Creating a column index\n#KC3[\"CLASS\"]=KC3[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\n#KC3.to_csv(\"KC3_csv\") # obtaininng a csv file\n#print(KC3['CLASS'].unique())\n#print(KC3['CLASS'].nunique())\n\n#printing the numbers of False and True\n#print(KC3.groupby('CLASS').size()[0].sum()) \n#print(KC3.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recursive feature model elimination"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import numpy as np\n#from sklearn.feature_selection import RFE\n#from sklearn.svm import SVR\n#array8 = Train.values\n#array8 = Train.values\n#X = array8[:,0:11]\n#Y = array8[:,11]\n#estimator = SVR(kernel=\"linear\")\n#selector = RFE(estimator, 5, step=1)\n#selector = selector.fit(X, Y)\n#set_printoptions(precision=3)\n#print(estimator[0:7,:]) #To print out the chosen 7 attributes that best fit the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.linear_model import ElasticNet\n#from sklearn.datasets import make_regression\n#X, Y = Train(n_features=2, random_state=0)\n#regr = ElasticNet(random_state=0)\n#regr.fit(X, Y)\n#ElasticNet(random_state=0)\n#print(regr.coef_)\n#print(regr.intercept_)\n#print(regr.predict([[0, 0]]))\n\n#model2 = model.predict(Test.values)\n\n#KC3 = pd.DataFrame(model2) #Converting the data to data frame\n#KC3.columns=[\"CLASS\"] #Naming the column\n#KC3.index.name=\"Index\" #Creating a column index\n#KC3[\"CLASS\"]=KC3[\"CLASS\"].map({0.0:False,1.0:True}) # Chaninging 0 to \"False\" 1 to \"True\"\n\n#KC3.to_csv(\"KC3_csv\") # obtaininng a csv file\n#print(KC3['CLASS'].unique())\n#print(KC3['CLASS'].nunique())\n\n#printing the numbers of False and True\n#print(KC3.groupby('CLASS').size()[0].sum()) \n#print(KC3.groupby('CLASS').size()[1].sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nreg = linear_model.Lasso(alpha=0.1)\nreg.fit([[0, 0], [1, 1]], [0, 1])\nLasso(alpha=0.1)\nreg.predict([[1, 1]])\narray([0.8])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparison of different models\n## To select which model works best\n```A comparison of all models will enable me select out which models best suit the data.\nFrom these, I can pick out which one gives best accuracy and perfom an MCM statistics.```\n"},{"metadata":{},"cell_type":"markdown","source":"# Linear regression\n```Linear regression fits a linear model with coefficients to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation. Linear regression will enable me fit the best line on the distributions in the data. There are more advanced ways to fit a line to data, but in general, I want the line to go through the \"middle\" of the points.```\n\n# Histogram-based Gradient Boosting Classification Tree\n```Although Gradient boosting is a greedy algorithm and can overfit a training dataset quickly, It can benefit from regularization methods that penalize various parts of the algorithm and generally improve the performance of the algorithm by reducing overfitting. I want to use this model to checkfo overfitting .```\n\n# K-fold\n```When we split the dataset into training and test set, we use only a subset of data and we know when we train on fewer observations the model will not perform well and overestimate the test error rate for the model to fit on the entire dataset. We correct for this by using a K-fold cross-validation with a specified number of kfolds. Cross-validation will give me a more accurate estimate of a model’s performance```\n\n# XGBClassifier\n```XGBoost is an efficient and easy to use an algorithm which delivers high performance and accuracy as compared to other algorithms. I added XGBClassifier because it has in-built L1 (Lasso Regression) and L2 (Ridge Regression) regularization which prevents the model from overfitting.```\n\n# RandomForestClassifier \n``` I added Random forest classifier because it is one of the most accurate learning algorithms available. For many data sets, it produces a highly accurate classifier. It runs efficiently on large databases. It can handle thousands of input variables without variable deletion. It will be a good basis to compare other models```\n\n# SGDClassifier\n``` Stochastic Gradient Descent (SGD) is a simple yet very efficient approach to discriminative learning of linear classifiers under convex loss functions such as (linear) Support Vector Machines and Logistic Regression. I chose to add it as one of the models has been successfully applied to large-scale and sparse machine learning problems often encountered in text classification and natural language processing. This classifier supports multi-class classification by combining multiple binary classifiers in a “one versus all” (OVA) scheme.```\n\n# DecisionTreeClassifier\n```Thi algorithm is simpler to understand, interpret and visualize. Effort required for Data preparation is minimal. Additionally, decision trees combined into an ensemble create some of the best binary classifiers.```\n\n# BaggingClassifier \n```Bagging takes the advantage of ensemble learning wherein multiple weak learner outperform a single strong learner. It helps reduce variance and thus helps us avoid overfitting. There is loss of interpretability of the model. There can possibly be a problem of high bias if not modeled properly.```\n\n# Coss validation score\n```Using cross validation can give me a hint of how well my model is doing, and it has the advantage of being very robust (as opposed to simple train-test split). It can be also used in hyper-tuning of parameters: for a given parameters, using the CV score to optimize its value in a robust way.```\n\n# LogisticRegression \n```I chose Logistic Regression because performs well when the dataset is linearly separable.Logistic regression is less prone to over-fitting but it can overfit in high dimensional datasets. Logistic Regression not only gives a measure of how relevant a predictor (coefficient size) is, but also its direction of association (positive or negative). Logistic regression is easier to implement, interpret and very efficient to train. It would work well in prediciting my model.```\n\n# KNeighborsClassifier\n```I chose this algorithm because it is simple and easy to implement. There's no need to build a model, tune several parameters, or make additional assumptions. The algorithm is versatile. It can be used for classification, regression, and search.```\n\n# LinearDiscriminantAnalysis\n```LDA in the binary-class case has been shown to be equivalent to linear regression with the class label as the output. This implies that LDA for binary-class classiﬁcations can be formulated as a least squares problem. It will give me a good comparison with the linear regression model already included.```\n\n# GaussianNB \n```I chose the naive Bayesian classifier because they are extremely fast for both training and prediction. They provide straightforward probabilistic prediction. This classifier needs less training data, highly scalable. It scales linearly with the number of predictors and data points. Can be used for both binary and mult-iclass classification problems. Can make probabilistic predictions. Handles continuous and discrete data. Not sensitive to irrelevant features. It would therefore be a good model to include in the testing algorithms```\n\n# SVC\n``I added this model beause SVM Classifiers offer good accuracy and perform faster prediction compared to Naïve Bayes algorithm.They willhelp me audit the naive bayes classifier. They also use less memory because they use a subset of training points in the decision phase. SVM works well with a clear margin of separation and with high dimensional space. Evenwhen my dimentional space is not that big, its worth a try.```\n\n# HistGradientBoostingClassifier\n```This is one of the ensemble methods. The goal of ensemble methods is to combine the predictions of several base estimators built with a given learning algorithm in order to improve generalizability / robustness over a single estimator. It will give me a good comparison with the model.```\n\n\n\n\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Models comparison\nfrom sklearn import linear_model\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import HistGradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining all models\nmodels = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('RFC',RandomForestClassifier()))\nmodels.append(('BAG',BaggingClassifier()))\nmodels.append(('XGB',XGBClassifier()))\nmodels.append(('SGD',SGDClassifier()))\nmodels.append(('HGB',HistGradientBoostingClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EStimating accuracy of the models\n## Model accuracy\n```The accuracy of the models is determined to inform the next step over which is the most \naccurate model to follow.```"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The comparative accuracies of the models is determined\n\nresults = []\nnames = []\nscoring = 'accuracy'\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    kc4 = (name, cv_results.mean(), cv_results.std())\n    print(kc4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model chosen\n## NB', GaussianNB() \n```GaussianNB shows the highest accuracy, at 88%.\nI chose to test this further. Furtherstill, I choose this particular model because of the boxplot comparison\nIt has a small error from the mean. Thus its accuracy can be trusted to a better extent compared to other models```"},{"metadata":{},"cell_type":"markdown","source":"# Graph to show comparisons"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.suptitle('Comparison of models')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing the model on Matthew's Correlation Coefficient\n``` To futher test for a better metric than accuracy, I will test the GaussianNB modle on Matthew's correlation```"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef\n\narray= Train.values\nX = array[:,0:11]\nY = array[:,11]\ntest_size = 0.33\nseed = 7\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\nrandom_state=seed)\n\nkintu_model2 = LogisticRegression()\nkintu_model2.fit(X_train, Y_train)\n\npredicted3= kintu_model2.predict(X_test)\ncomp_mat = matthews_corrcoef(Y_test, predicted3)\nprint(comp_mat)\n\n#Mathews correlation coefficient gives a moderate","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generating the csv file\n``` I generate a csv file to enable me judge the accuracy of this model and submit to the competition.```"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generating a csv file\nkintu_df=pd.DataFrame(predicted3)\nkintu_df.columns=['CLASS']\nkintu_df.index.names=[\"Index\"]\nkintu_df['CLASS']=kintu_df['CLASS'].map({0.0:False, 1.0:True})\nkintu_df\nkintu_df.to_csv('KC_model2_csv')\nprint(kintu_df['CLASS'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Re-testingLinear Regression\n```Running each model seperately to allow me change certain parameters \nthat are not possible tochange when doing an overall comparison```"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\narray2 = Train.values\nreg = LinearRegression().fit(X, Y)\nreg.score(X, Y)\nscoring = ('Accuracy')\nreg.coef_\nreg.intercept_\nxp = reg.predict(X)\nxp\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}