{"cells":[{"metadata":{},"cell_type":"markdown","source":"## ACE_Uganda Kaggle competition 1\n### by Ibra Lujumba"},{"metadata":{},"cell_type":"markdown","source":"#### Exploratory Data Analysis "},{"metadata":{},"cell_type":"markdown","source":"This is done to try to understand the properties of the data before any machine learning algorithm id used to make predictions about the data."},{"metadata":{},"cell_type":"markdown","source":"##### Importing python modules for data analysis and visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # manipulation of arrays\nimport pandas as pd # manipulating dataframes\nimport matplotlib.pyplot as plt # data visualisation\nimport seaborn as sb # data visualisation,it is based on plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ignoring warnings that may arise\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### Importing the datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/ace-class-assignment/\n\n# reading in the data\ndata = pd.read_csv('../input/ace-class-assignment/AMP_TrainSet.csv')\nnew = pd.read_csv('../input/ace-class-assignment/Test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Checking the dimensions of the data as well as the datatype of each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking dimensions of the datasets\ndata.shape, new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the datatypes of the variables\ndata.dtypes, new.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All the values in all the variables exists as either floats or integers.\n\nProceeding to work with the training dataset to build the classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the descriptive statistics of the train dataset such as arithmetic mean, \n# standard deviation, quartiles and number of non-NA values in each column \ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"From the count, all values for all cells in the dataset exist. i.e, there are no missing values for any of the variables\nAS_DAYM780201 and FULL_DAYM780201 have the highest mean and highest maximum. FULL_OOBM850104 has a negative mean\nFor all the variables, the data points are not widely spread"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the proprotions of classses\ndata.groupby('CLASS').size()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Both classes have an equal number of entries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# obtaining pairwise correlation values for the variables in the train dataset\n# use this resource to understand the output https://realpython.com/numpy-scipy-pandas-correlation-python/#pearson-correlation-coefficient\npearsoncorr = data.corr(method='pearson')\n\n# visualizing the correlation matrix as a heatmap to make interpretation easier\nplt.figure(figsize=(10,10))\ntop_corr = pearsoncorr.index\nsb.heatmap(pearsoncorr, \n            xticklabels=pearsoncorr.columns,\n            yticklabels=pearsoncorr.columns,\n            cmap='RdYlGn',\n            annot=True,\n            linewidth=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the last row, FULL_Charge and AS_MeanAmphiMoment have the highest positive correlation values with CLASS whereas second,third and fourth variables have the most negative correlation values."},{"metadata":{},"cell_type":"markdown","source":"You can get the p-values associated with the correlation values using the code below.\n\n`from scipy.stats import pearsonr`\n\n`data.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(len(train.columns))`\n\nIn this example, all values were too low to be informative"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using a scatter plot matrix to visualise correlations\n# plt.figure(figsize=(60,60))\n# sb.pairplot(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some variables are significantly correlated with each other which raises the problem of multicollinearity (variables are correlated with each other as well as with the response variable).\nThese variables are Full_Charge, FULL_AcidicMolPer, FULL_AURR980107,...\n\nVariables that require further investigation - NT_EFC195, AS_MeanAmphiMoment"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data['AS_MeanAmphiMoment'].unique()), data['NT_EFC195'].unique()\n\n#this confirms that NT_EFC195 is a categorical variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['CLASS','NT_EFC195']].head() #NT_EFC195 assumes both values irrespective of class\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the associated p-values. The value of 1 at the bottom should be ignored \nfrom scipy.stats import pearsonr\ndata.corr(method=lambda x, y: pearsonr(x, y)[1])['CLASS']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the distribution and skewness of variables\nplt.figure(figsize=(10,6))\ndata.skew().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of the variables are minimally skewed except NT_EFC195. Further checks will be done to try to understand the properties of this variable.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby('NT_EFC195').size() # majority of the instances are of Class 0.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The skewedness in this variable can be understood by having most of its values at zeros\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.plot(kind='density', subplots=True, layout=(4,3), figsize=(10,10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Values for AS_FUK010112, CT_RACS820104,FULL_GEOR030101 and FULL_AURR980107 lie close to zero compared to the rest of the variables.\n\nTranformation possibilities\n* using the minimum and maximum scaler\n* standardisation"},{"metadata":{},"cell_type":"markdown","source":"#### Data transformation"},{"metadata":{},"cell_type":"markdown","source":"Better performance of algorithms can be obtained if the data is transformed.\nSome algorithms are may take features with large values as the most important features in the predictions"},{"metadata":{},"cell_type":"markdown","source":"Seperating the predictor variables from the target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"# converting Pandas dataframe to ndArray\ndataArray = data.to_numpy()\n\n# seperating the predictor and response variables\ntarget = dataArray[:,11]\npredictors = dataArray[:,0:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using minMaxScaler to set all values between 0 and 1\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0,1))\nrescaledPredictors = scaler.fit_transform(predictors)\n                        \n\n# using StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nscaler1 = StandardScaler().fit(predictors)\nstandardizedPredictors = scaler1.transform(predictors)\n                        \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"# using univariate statistics F-test as an alternative to chi-squared test (some values are zero and chi2 returns an error)\n\n# untransformed data\nfrom sklearn.feature_selection import SelectKBest, f_classif\nbestFeatures = SelectKBest(score_func=f_classif, k=7)\nfit = bestFeatures.fit(predictors, target)\n\nscores = pd.DataFrame(fit.scores_) \npvalues = pd.DataFrame(fit.pvalues_)\ncolumns = pd.DataFrame(data.columns[0:11])\n\nfeatureValues = pd.concat([columns,scores, pvalues,], axis=1) # concatenating dataframes\nfeatureValues.columns = ['predictor', 'score', 'pvalue'] # naming the columns\n\nprint(featureValues.nlargest(7, 'score'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the transformed data\n\n# rescaledPredictors\nreBestFeatures = SelectKBest(score_func=f_classif, k=7)\nreFit = reBestFeatures.fit(rescaledPredictors, target)\n\nreScores = pd.DataFrame(reFit.scores_) \nrePvalues = pd.DataFrame(reFit.pvalues_)\nreColumns = pd.DataFrame(data.columns[0:11])\n\nreFeatureValues = pd.concat([reColumns,reScores, rePvalues,], axis=1) # concatenating dataframes\nreFeatureValues.columns = ['re_predictor', 're_score', 're_pvalue'] # naming the columns\n\n\n\n# standardizedPredictors\nstBestFeatures = SelectKBest(score_func=f_classif, k=7)\nstFit = stBestFeatures.fit(standardizedPredictors, target)\n\nstScores = pd.DataFrame(stFit.scores_) \nstPvalues = pd.DataFrame(stFit.pvalues_)\nstColumns = pd.DataFrame(data.columns[0:11])\n\nstFeatureValues = pd.concat([stColumns,stScores, stPvalues,], axis=1) # concatenating dataframes\nstFeatureValues.columns = ['st_predictor', 'st_score', 'st_pvalue'] # naming the columns\n\nprint(reFeatureValues.nlargest(7, 're_score')), print(stFeatureValues.nlargest(7, 'st_score'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using feature importance\nfrom sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier()\nmodel.fit(predictors, target)\nprint(model.feature_importances_)\n\n# visualising feature importance\nimportances = pd.Series(model.feature_importances_, index=data.columns[0:11])\nimportances.nlargest(10).plot(kind='barh')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### Building the classification model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the data_one dataset into training and test datasets and using a logit function to classify instances\nfrom sklearn.model_selection import train_test_split # random split\nfrom sklearn.linear_model import LogisticRegression # all machine learning models in Python are implemented as classes\np_train, p_test, t_train, t_test = train_test_split(predictors, target, \n                                                    test_size=0.30,random_state=42)\n\nlogit = LogisticRegression() # making instance of model\n\n# fitting the model on untransformed data\nlogit.fit(p_train, t_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Measuring model performance\n\nWe can measure the performance of a classification problem using precison, F1 Score, ROC curve\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict on test data\npredictions = logit.predict(p_test) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the confusion matrix\nfrom sklearn import metrics\ncm = metrics.confusion_matrix(t_test, predictions)\ncm\nsb.heatmap(cm, annot=True, fmt='.3f', linewidths=.5,\n          square=True, cmap='Blues') \nplt.ylabel('Actual label'); plt.xlabel('Predicted label')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance metrics\nprint(\"Accuracy: \",metrics.accuracy_score(t_test, predictions)*100)\nprint(\"Precision: \",metrics.precision_score(t_test, predictions)*100)\nprint(\"Recall: \",metrics.recall_score(t_test, predictions)*100)\n\nfrom sklearn.metrics import matthews_corrcoef\nprint('MCC: ',matthews_corrcoef(t_test, predictions)) # takes into account true and false positives and negatives, \n                                                      # higher values are better\n# not affected by unbalanced classes\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ROC curve of true positive rate against false positive rate\n# shows tradeoff between sensitivy and specificity\n\npred_probs = logit.predict_proba(p_test)[::,1] # start=0, stop=size of dimension, step=1\nfpr, tpr,_ = metrics.roc_curve(t_test, pred_probs)\nauc = metrics.roc_auc_score(t_test, pred_probs)\nplt.plot(fpr, tpr, label = 'Untransformed+all Var, auc='+ str(auc))\nplt.legend(loc=4)\nplt.ylabel('tpr'), plt.xlabel('fpr')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance on new data\nnew_pred = logit.predict(new.values)\n\npred_df = pd.DataFrame(new_pred) \npred_df.columns=[\"CLASS\"]\npred_df.index.name=\"Index\" \npred_df[\"CLASS\"] = pred_df[\"CLASS\"].map({0:'False',1.0:'True'})\n\n#csv file output\npred_df.to_csv(\"ilujumba.csv\") \nprint(pred_df['CLASS'].unique())\n\n#printing the numbers of False and True\nprint(pred_df.groupby('CLASS').size()[0].sum())\nprint(pred_df.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic regression on rescaled data"},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_train, p1_test, t1_train, t1_test = train_test_split(rescaledPredictors, target, \n                                                        test_size=0.30,random_state=42)\n\nlogit1 = LogisticRegression() # making instance of model\n\n# fitting the model on rescaled data\nlogit1.fit(p1_train, t1_train)\n\n# predict on test data\npredictions1 = logit1.predict(p1_test)\n\n# performance metrics\nprint(\"Accuracy: \",metrics.accuracy_score(t1_test, predictions1)*100)\nprint(\"Precision: \",metrics.precision_score(t1_test, predictions1)*100)\nprint(\"Recall: \",metrics.recall_score(t1_test, predictions1)*100)\n\nfrom sklearn.metrics import matthews_corrcoef\nprint('MCC: ',matthews_corrcoef(t1_test, predictions1))\n\n# rescaling new data\nnewArray = new.to_numpy()\nrescaledNew = scaler.fit_transform(newArray)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# performance on new data (rescaled)\nnew_pred1 = logit1.predict(rescaledNew)\n\npred_df1 = pd.DataFrame(new_pred1) \npred_df1.columns=[\"CLASS\"]\npred_df1.index.name=\"Index\" \npred_df1[\"CLASS\"] = pred_df1[\"CLASS\"].map({0:'False',1.0:'True'})\n\n#csv file output\npred_df1.to_csv(\"ilujumba1.csv\") \nprint(pred_df1['CLASS'].unique())\n\n#printing the numbers of False and True\nprint(pred_df1.groupby('CLASS').size()[0].sum())\nprint(pred_df1.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Logistic regression on standardized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"p2_train, p2_test, t2_train, t2_test = train_test_split(standardizedPredictors, target, \n                                                        test_size=0.30,random_state=42)\n\nlogit2 = LogisticRegression() # making instance of model\n\n# fitting the model on rescaled data\nlogit2.fit(p2_train, t2_train)\n\n# predict on test data\npredictions2 = logit2.predict(p2_test)\n\n# performance metrics\nprint(\"Accuracy: \",metrics.accuracy_score(t2_test, predictions2)*100)\nprint(\"Precision: \",metrics.precision_score(t2_test, predictions2)*100)\nprint(\"Recall: \",metrics.recall_score(t2_test, predictions2)*100)\nprint('MCC: ',matthews_corrcoef(t2_test, predictions2))\n\n# standardizing new data\nstandardizedNew = scaler1.transform(newArray)\n\n# performance on new data (standaridized)\nnew_pred2 = logit2.predict(standardizedNew)\n\npred_df2 = pd.DataFrame(new_pred2) \npred_df2.columns=[\"CLASS\"]\npred_df2.index.name=\"Index\" \npred_df2[\"CLASS\"] = pred_df2[\"CLASS\"].map({0:'False',1.0:'True'})\n\n#csv file output\npred_df2.to_csv(\"ilujumba2.csv\") \nprint(pred_df2['CLASS'].unique())\n\n#printing the numbers of False and True\nprint(pred_df2.groupby('CLASS').size()[0].sum())\nprint(pred_df2.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using selected features, rescaled data and Logistic regression\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"p3_train, p3_test, t3_train, t3_test = train_test_split(rescaledPredictors[:,(0,1,2,3,7)], target, \n                                                        test_size=0.30,random_state=42)\n\nlogit3 = LogisticRegression() # making instance of model\n\n# fitting the model on rescaled data\nlogit3.fit(p3_train, t3_train)\n\n# predict on test data\npredictions3 = logit3.predict(p3_test)\n\n# performance metrics\nprint(\"Accuracy: \",metrics.accuracy_score(t3_test, predictions3)*100)\nprint(\"Precision: \",metrics.precision_score(t3_test, predictions3)*100)\nprint(\"Recall: \",metrics.recall_score(t3_test, predictions3)*100)\n\nfrom sklearn.metrics import matthews_corrcoef\nprint('MCC: ',matthews_corrcoef(t3_test, predictions3))\n\n# rescaling new data\n# newArray = new.to_numpy()\n# rescaledNew = scaler.fit_transform(newArray)\n\n# performance on new data (rescaled)\nnew_pred3 = logit3.predict(rescaledNew[:,(0,1,2,3,7)])\n\npred_df3 = pd.DataFrame(new_pred3) \npred_df3.columns=[\"CLASS\"]\npred_df3.index.name=\"Index\" \npred_df3[\"CLASS\"] = pred_df3[\"CLASS\"].map({0:'False',1.0:'True'})\n\n#csv file output\npred_df3.to_csv(\"ilujumba3.csv\") \nprint(pred_df3['CLASS'].unique())\n\n\n#printing the numbers of False and True\nprint(pred_df3.groupby('CLASS').size()[0].sum())\nprint(pred_df3.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Using cross-validation and Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nkfold = KFold(n_splits=10, random_state=42)\nmodel6 = LogisticRegression()\nmodel6.fit(predictors, target)\n\nresults = cross_val_score(model6, predictors, target)\nprint(results.mean())\n\nmodel6_pred = model6.predict(rescaledNew)\ndf6 = pd.DataFrame(model6_pred)\ndf6.columns = ['CLASS']\ndf6.index.name = 'Index'\ndf6['CLASS'] = df6['CLASS'].map({0.0:False, 1.0:True})\n\ndf6.to_csv('ilujumba7.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Naive Bayes classifier with kfold cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nkfold = KFold(n_splits=10, random_state=42, shuffle=True)\nmodel7 = GaussianNB()\nmodel7.fit(predictors, target)\n\nresults = cross_val_score(model7, predictors, target)\nprint(results.mean())\n\nmodel7_pred = model7.predict(newArray)\ndf7 = pd.DataFrame(model7_pred)\ndf7.columns = ['CLASS']\ndf7.index.name = 'Index'\ndf7['CLASS'] = df7['CLASS'].map({0.0:'False', 1.0:'True'})\n\ndf7.to_csv('ilujumba7.csv')\nprint(df7['CLASS'].unique())\n\n#printing the numbers of False and True\nprint(df7.groupby('CLASS').size()[0].sum())\nprint(df7.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Naive Bayes classifier on rescaled features\n\nAssumes that all features are independent of each other and each feature contributes equally to the resulting class"},{"metadata":{"trusted":true},"cell_type":"code","source":"kfold = KFold(n_splits=10, random_state=42, shuffle=True)\nmodel8 = GaussianNB()\nmodel8.fit(rescaledPredictors, target)\n\nresults1 = cross_val_score(model8, rescaledPredictors, target)\nprint(results1.mean())\n\nmodel8_pred = model8.predict(rescaledNew)\ndf8 = pd.DataFrame(model8_pred)\ndf8.columns = ['CLASS']\ndf8.index.name = 'Index'\ndf8['CLASS'] = df8['CLASS'].map({0.0:'False', 1.0:'True'})\n\ndf8.to_csv('ilujumba8.csv')\nprint(df8['CLASS'].unique())\n\n#printing the numbers of False and True\nprint(df8.groupby('CLASS').size()[0].sum())\nprint(df8.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Naive Bayes and kfold validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.naive_bayes import GaussianNB\n\nkfold = KFold(n_splits=10, random_state=42, shuffle=True)\nmodel9 = GaussianNB()\nmodel9.fit(predictors, target)\n\nresults = cross_val_score(model9, predictors, target, cv =10) # ten-fold cross validation\nprint('mean for results', results.mean())\n\npredic = cross_val_predict(model9, predictors, target, cv =10)\naccuracy = metrics.r2_score(target, predic)\nprint('cross-predicted accuracy ', accuracy)\n\nmodel9_pred = model9.predict(newArray)\ndf9 = pd.DataFrame(model9_pred)\ndf9.columns = ['CLASS']\ndf9.index.name = 'Index'\ndf9['CLASS'] = df9['CLASS'].map({0.0:'False', 1.0:'True'})\n\ndf9.to_csv('ilujumba9.csv')\nprint(df9['CLASS'].unique())\n\n#printing the numbers of False and True\nprint(df9.groupby('CLASS').size()[0].sum())\nprint(df9.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Comparing several algorithms to look at the nature of the decision boundaries created"},{"metadata":{},"cell_type":"markdown","source":"https://medium.com/cascade-bio-blog/creating-visualizations-to-better-understand-your-data-and-models-part-2-28d5c46e956"},{"metadata":{},"cell_type":"markdown","source":"Algorithms define a st of hyperplanes that divide the datapoints to their respective classes and span the feature space trained on. Visualising enables one to understand the limitations of a given algorithm on a dataset given to it.\nThus decision boundaries enable one to understand to how the training data selected affects performance of the algorithm."},{"metadata":{},"cell_type":"markdown","source":"Ten sklearn classifier algorithms were compared"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing classifiers from the sklearn library\n\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier #1\nfrom sklearn.neighbors import KNeighborsClassifier #2\nfrom sklearn.svm import SVC #3\nfrom sklearn.gaussian_process import GaussianProcessClassifier #4\nfrom sklearn.gaussian_process.kernels import RBF #5\nfrom sklearn.tree import DecisionTreeClassifier #6\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier #7,8\nfrom sklearn.naive_bayes import GaussianNB #9\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis #10\nfrom sklearn.linear_model import LogisticRegression #11\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\", \"Logistic Regression\"]\n\nclassifiers = [\n    KNeighborsClassifier(3), # holds no assumption on data distribution (non-parametric)\n    SVC(kernel=\"linear\", C=0.025), # using a linear kernel\n    SVC(gamma=2, C=1), # using radial basis function  kernel,C is low to enable a large decision margin\n    GaussianProcessClassifier(1.0 * RBF(1.0)), # based on Laplace approximation\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=100), # 100 trees in the forest\n    MLPClassifier(max_iter=1000), #iterations until converge\n    AdaBoostClassifier(), # fits multiple classifiers on the same dataset\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dimensionality reduction\nhttps://stackabuse.com/dimensionality-reduction-in-python-with-scikit-learn/"},{"metadata":{},"cell_type":"markdown","source":"Since the data is multi-dimensional, it was reduced using Principal Component Analysis (PCA) to reduce it to two components.\nTrial runs were done to check how much of the variation in the data is explained by the principal components.\n\nAnother thing to keep in mind is that PCA works best on standardised/normalised data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocessing the dataset\ndataArray = data.to_numpy()\nX, y = dataArray[:,0:11], dataArray[0:,11]\nX = StandardScaler().fit_transform(X)\n\n# reducing dimensions of the dataset using PCA  https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\nfrom sklearn.decomposition import PCA\npca = PCA()\npca.fit_transform(X)\npca_variance = pca.explained_variance_\nplt.figure(figsize=(8, 6))\nplt.bar(range(11), pca_variance, alpha=0.5, align='center', label='individual variance')\nplt.legend()\nplt.ylabel('Variance ratio')\nplt.xlabel('Principal components')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca2 = PCA(0.95) # keeping principal components that explain 95% of the variance\nninety_five = pca2.fit_transform(X)\nninety_five.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Explained variance: \", sum(pca2.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Eight features explain 95% of the variance in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca2 = PCA(3) # keeping features three principal components\nprincipalComponents = pca2.fit_transform(X)\n\nfrom mpl_toolkits.mplot3d import Axes3D\nplt.figure(figsize=(10,6))\nax = plt.axes(projection='3d')\nax.scatter(principalComponents[:,0], principalComponents[:,1], principalComponents[:,2], \n           linewidths=1, alpha=.5,\n           edgecolor='k', s= 200,\n           c=data['CLASS'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The three pincipal components wete visualised using a 3D plot. The figure above shows clustering of the three components. Each component is not exactly independent of the others so the clusters overlap to some extent"},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting principal component ndarrays to DataFrame format\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2','PC3'])\nfinalDf = pd.concat([principalDf, data['CLASS']], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalDf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Variance explained by three PCs: ',sum(pca2.explained_variance_ratio_)*100,'%')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualising the top 2 principal components"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (6,6))\nax = fig.add_subplot(111) \nax.set(xlim=(-10,10), ylim=(-10,10))\nax.set_xlabel('Principal Component 1', fontsize = 15)\nax.set_ylabel('Principal Component 2', fontsize = 15)\nax.set_title('top 2 components', fontsize = 20)\n\ntargets = [0, 1]\ncolors = ['r', 'g']\n\nfor target, color in zip(targets,colors):\n    indices = finalDf['CLASS'] == target\n    ax.scatter(finalDf.loc[indices, 'PC1']\n               , finalDf.loc[indices, 'PC2']\n               , c = color\n               , s = 50)\nax.legend(targets)\nax.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the into training and test part\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A mesh grid is required. This can be thought of as a matrix of coordinates upon which the model will make decisions.\nThese are then visualised to reveal decision boundaries.\nThe mesh grip was created based on the data and a step size of 0.02"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating mesh for the contour plot\n\nh = .02  # step size in the mesh\nx_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\ny_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two principal components were used to enable visualisation on a scatter plot.\n\nThe parameters for the PCA were generated on the training data and these were applied on both the training and training sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"pca4 = PCA(n_components=2)\n\n# applying PCA on training set\npca4.fit(X_train)\n\n#applying transform on training and testing sets\ntrain_ = pca4.transform(X_train)\ntest_ = pca4.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Explained variance: \", sum(pca4.explained_variance_ratio_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_.shape, test_.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After transforming the data and the creating the meshgrid, decision boundaries for the algorithms were created by iterating over the classifiers."},{"metadata":{"trusted":true},"cell_type":"code","source":"figure = plt.figure(figsize=(27, 15))\ni = 1\n\ndatasets=[data]\nfor ds_cnt, ds in enumerate(datasets):\n    # just plot the dataset first\n    cm = plt.cm.RdBu\n    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n\n    if ds_cnt == 0:\n        ax.set_title(\"Input data\")\n        # Plot the top 2 principal components for training data\n        ax.scatter(train_[:, 0], train_[:, 1], c=y_train, cmap=cm_bright,\n                    edgecolors='k')\n        # Plot the top 2 principal components for the testing data\n        ax.scatter(test_[:, 0], test_[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n                    edgecolors='k')\n        ax.set_xlim(xx.min(), xx.max())\n        ax.set_ylim(yy.min(), yy.max())\n        ax.set_xticks(())\n        ax.set_yticks(())\n        i += 1\n\n        # iterate over classifiers\n\n    for name, clf in zip(names, classifiers):\n        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n        clf.fit(train_, y_train)\n        score = clf.score(test_, y_test)\n\n        # Plot the decision boundary. For that, we will assign a color to each\n        # point in the mesh [x_min, x_max]x[y_min, y_max].\n\n        if hasattr(clf, \"decision_function\"):\n            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) # confidence scores\n        else:\n            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1] # probability estimates\n\n        # Put the result into a color plot\n        Z = Z.reshape(xx.shape)\n        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n\n        # Plot the training points\n        ax.scatter(train_[:, 0], train_[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n        # Plot the testing points\n        ax.scatter(test_[:, 0], test_[:, 1], c=y_test, cmap=cm_bright, edgecolors='k', alpha=0.4)\n\n        ax.set_xlim(xx.min(), xx.max())\n        ax.set_ylim(yy.min(), yy.max())\n        ax.set_xticks(())\n        ax.set_yticks(())\n        if ds_cnt == 0:\n            ax.set_title(name)\n            ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'), size=15, horizontalalignment='right')\n            i += 1\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Accuracies of the different algorithms are indicated on the lower right corner.\n\nThe plots show training points in solid colors and testing points semi-transparent. Contour decision boundaries were used which seperate points based on shared characteritics.\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}