{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # KAKOOZA TREVOR\n",
    "## Kaggle assignment\n",
    "### started on the 28th /feb/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Problem\n",
    "### a) Load libraries\n",
    "### b) Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary tools required to work on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries you are going to use\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -----> Put your code here below:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# This first session is about loading the give dataset and viewing them.  \n",
    "\n",
    "* The two data set provided are\n",
    "1. test.csv\n",
    "2. AMP_TrainSet.csv \n",
    "\n",
    "### Now load the data set using.\n",
    "```\n",
    "Train = pd.read_csv(\"../input/amp-data-set/AMP_TrainSet.csv\")\n",
    "Test = pd.read_csv(\"../input/amp-data-set/Test.csv\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /kaggle/input/amp-data-set/Test.csv does not exist: '/kaggle/input/amp-data-set/Test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1848a25d9e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#using pandas we call the data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/amp-data-set/Test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/amp-data-set/AMP_TrainSet.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /kaggle/input/amp-data-set/Test.csv does not exist: '/kaggle/input/amp-data-set/Test.csv'"
     ]
    }
   ],
   "source": [
    "#using pandas we call the data set\n",
    "Test = pd.read_csv('/kaggle/input/amp-data-set/Test.csv')\n",
    "Train = pd.read_csv(\"../input/amp-data-set/AMP_TrainSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Summarize Data\n",
    "\n",
    "## View the first five raws of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#head.() is ued to view the first five raws of the data set.\n",
    "Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4f599e897758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
     ]
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape function\n",
    "* This function helps to view the total raws and columns (dimension) of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dimensions of your data\n",
    "\n",
    "Train.shape, Test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data type\n",
    "* This returns a Series with the data type of each column.\n",
    "* The result’s index is the original DataFrame’s columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isnull().sum\n",
    "* This function helps to see if the dataset has any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.isnull().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When we look at the data ,it shows that both the test and train dataset does not have any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then in column of class we check and find out,\n",
    "* How is the data divied into.\n",
    "* Here the unique function does that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['CLASS'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Descriptive statistics\n",
    "## Descriptive statistics of the data\n",
    "* Generate descriptive statistics that summarize the central tendency,\n",
    "dispersion and shape of a dataset's distribution, excluding\n",
    "``NaN`` values.\n",
    "\n",
    "Analyzes both numeric and object series, as well\n",
    "as ``DataFrame`` column sets of mixed data types. The output\n",
    "will vary depending on what is provided.\n",
    "\n",
    "### For example this function will provide the following summary\n",
    "* Count.\n",
    "* Mean.\n",
    "* Standard Deviation.\n",
    "* Minimum Value.\n",
    "* 25th Percentile.\n",
    "* 75th Percentile(Median).\n",
    "* Maximum Value.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "This is good,\n",
    "    can you keep all the explanations like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c)Check the dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Data visualizations\n",
    "## Class Distribution\n",
    "\n",
    "A groupby operation involves some combination of splitting the\n",
    "object, applying a function, and combining the results. This can be\n",
    "used to group large amounts of data and compute operations on these\n",
    "groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.groupby('CLASS').size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations Between Attributes\n",
    "Is the a mutual relationship or connection between two or more things.\n",
    "\n",
    "Note: Correlation refers to the relationship between two variables and how they may or may notchange together. The most common method for calculating correlation is Pearson's Correlation Coefficient, that assumes a normal distribution of the attributes involved.\n",
    "\n",
    "A correlation of -1 or 1 shows a full negative or positive correlation respectively. Whereas a value of 0 shows no correlation at all. \n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "What did you learn from this?\n",
    "    \n",
    "    Please explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-35f49c0f9d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pearson'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Train' is not defined"
     ]
    }
   ],
   "source": [
    "Train.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting to show the correlation\n",
    "\n",
    "plot a heat map to show us the correlation of the data.\n",
    "\n",
    "With the help of ; seaborn\n",
    "the we can use spearman or pearson method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first step is to choose the figure size then use the heatmap to plot.\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(Train.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we can also check the correlation in regards to the CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.corr(method='pearson')['CLASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skew of Univariate Distributions\n",
    "### Definition of skew.\n",
    "* Is the suddenly change direction or position.\n",
    "* or Skew refers to a distribution that is assumed Gaussian (normal or bell curve) that is shifted or squashed in one direction or another. \n",
    "\n",
    "\n",
    "You can calculate the skew of each attribute using the skew() function on the Pandas DataFrame.\n",
    "\n",
    "#### NOTE: If skewness value lies above +1 or below -1, data is highly skewed. If it lies between +0.5 to -0.5, it is moderately skewed. If the value is 0, then the data is symmetric\n",
    "\n",
    "### Positively skewed data:\n",
    "If tail is on the right as that of the second image in the figure, it is right skewed data. It is also called positive skewed data. Common transformations of this data include square root, cube root, and log.\n",
    "\n",
    "### Cube root transformation:\n",
    "The cube root transformation involves converting x to  𝑥(1/3) . This is a fairly strong transformation with a substantial effect on distribution shape: but is weaker than the logarithm. It can be applied to negative and zero values too. Negatively skewed data.\n",
    "\n",
    "### Square root transformation:\n",
    "Applied to positive values only. Hence, observe the values of column before applying.\n",
    "\n",
    "### Logarithm transformation:\n",
    "The logarithm, x to log base 10 of x, or x to log base e of x (ln x), or x to log base 2 of x, is a strong transformation and can be used to reduce right skewness.\n",
    "\n",
    "### Negatively skewed data:\n",
    "If the tail is to the left of data, then it is called left skewed data. It is also called negatively skewed data. Common transformations include square , cube root and logarithmic. We will discuss what square transformation is as others are already discussed.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "What did you learn from this and how did you apply it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.skew().plot(kind='bar')\n",
    "#When we look to the data its highly positively skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization\n",
    "## Understand Your Data With Visualization\n",
    "You must understand your data in order to get the best results from machine learning algorithms. The fastest way to learn more about your data is to use data visualization.\n",
    "\n",
    "### Univariate Plots\n",
    "In this section we will look at three techniques that you can use to understand each attribute of your dataset independently.\n",
    "\n",
    "Histograms.\n",
    "Density Plots.\n",
    "Box and Whisker Plots.\n",
    "\n",
    "\n",
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "Train.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density Plots\n",
    "Density plots are another way of getting a quick idea of the distribution of each attribute. The plots look like an abstracted histogram with a smooth curve drawn through the top of each bin, much like your eye tried to do with the histograms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.plot(kind='density', subplots=True, layout=(3,4), sharex=False)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box and Whisker Plots\n",
    "Another useful way to review the distribution of each attribute is to use Box and Whisker Plots or boxplots for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots help to represent outlies\n",
    "Train.plot(kind='box', subplots=True, layout=(3,4), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Plots\n",
    "This section provides examples of two plots that show the interactions between multiple variables in your dataset.\n",
    "\n",
    "* Correlation Matrix Plot.\n",
    "* Scatter Plot Matrix.\n",
    "* Correlation Matrix Plot\n",
    "\n",
    "Correlation gives an indication of how related the changes are between two variables. If two variables change in the same direction they are positively correlated. If they change in opposite directions together (one goes up, one goes down), then they are negatively correlated. You can calculate the correlation between each pair of attributes. This is called a correlation matrix. You can then plot the correlation matrix and get an idea of which variables have a high correlation with each other. This is useful to know, because some machine learning algorithms like linear and logistic regression can have poor performance if there are highly correlated input variables in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = Train.corr()\n",
    "# plot correlation matrix\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,9,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(Train.columns)\n",
    "ax.set_yticklabels(Train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatter Plot Matrix\n",
    "\n",
    "A scatter plot shows the relationship between two variables as dots in two dimensions, one axis for each attribute. You can create a scatter plot for each pair of attributes in your data. Drawing all these scatter plots together is called a scatter plot matrix. Scatter plots are useful for spotting structured relationships between variables, like whether you could summarize the relationship between two variables with a line. Attributes with structured relationships may also be correlated and good candidates for removal from your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can use vars to compare two variable and hue to put colours\n",
    "sns.pairplot(Train,hue='CLASS',vars=['FULL_Charge','FULL_AcidicMolPerc'])\n",
    "#check on the seaborn(seaborn.pydata.org-dev/generated/seaborn.boxplot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mo = pd.DataFrame(out_model)\n",
    "mo.to_csv(\"xyz.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare Data\n",
    "\n",
    "# Prepare Your Data For Machine Learning\n",
    "Many machine learning algorithms make assumptions about your data. It is often a very good idea to prepare your data in such way to best expose the structure of the problem to the machine learning algorithms that you intend to use. In this chapter you will discover how to prepare your data for machine learning in Python using scikit-learn. After completing this lesson you will know how to:\n",
    "\n",
    "1. Rescale data.\n",
    "2. Standardize data.\n",
    "3. Normalize data.\n",
    "4. Binarize data.\n",
    "### Need For Data Pre-processing\n",
    "You almost always need to pre-process your data. It is a required step. A difficulty is that different algorithms make different assumptions about your data and may require different transforms. Further, when you follow all of the rules and prepare your data, sometimes algorithms can deliver better results without pre-processing. Generally, I would recommend creating many different views and transforms of your data, then exercise a handful of algorithms on each view of your dataset. This will help you to ush out which data transforms might be better at exposing the structure of your problem in general.\n",
    "\n",
    "### The steps involved are as below:\n",
    "\n",
    "Split the dataset into the input and output variables for machine learning.\n",
    "Apply a pre-processing transform to the input variables.\n",
    "Summarize the data to show the change.\n",
    "The scikit-learn library provides two standard idioms for transforming data. Each are useful in di\u000b",
    "erent circumstances. The transforms are calculated in such a way that they can be applied to your training data and any samples of data you may have in the future. The scikit-learn documentation has some information on how to use various di\u000b",
    "erent pre-processing methods:\n",
    "\n",
    "The Fit and Multiple Transform method is the preferred approach. You call the fit() function to prepare the parameters of the transform once on your data. Then later you can use the transform() function on the same data to prepare it for modeling and again on the test or validation dataset or new data that you may see in the future. The Combined Fit-And-Transform is a convenience that you can use for one o\u000b",
    " tasks. This might be useful if you are interested in plotting or summarizing the transformed data.\n",
    "\n",
    "### Rescale Data\n",
    "When your data is comprised of attributes with varying scales, many machine learning algorithms can bene\f",
    "t from rescaling the attributes to all have the same scale. Often this is referred to as normalization and attributes are often rescaled into the range between 0 and 1. This is useful for optimization algorithms used in the core of machine learning algorithms like gradient descent. It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like k-Nearest Neighbors. You can rescale your data using scikit-learn using the MinMaxScaler class\n",
    "\n",
    "### NOTE: Since my graph and summary data shows varying means and Gaussian distribution. i would use Standardize data method\n",
    "\n",
    "\n",
    "\n",
    "### Standardize of Data\n",
    "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression, logistic regression and linear discriminate analysis. You can standardize data using scikit-learn with the StandardScaler class3.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "Good work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "array2 = Train.values\n",
    "# separate array into input and output components\n",
    "X = array2[:,0:11]\n",
    "Y = array2[:,11]\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "# summarize transformed data\n",
    "#set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Data Cleaning(not done)\n",
    "# b) Feature Selection\n",
    "\n",
    "## Feature Selection For Machine\n",
    "Learning The data features that you use to train your machine learning models have a huge in uence on the performance you can achieve. Irrelevant or partially relevant features can negatively impact model performance. In this chapter you will discover automatic feature selection techniques that you can use to prepare your machine learning data in Python with scikit-learn. After completing this lesson you will know how to use:\n",
    "\n",
    "## Univariate Selection.\n",
    "Recursive Feature Elimination.\n",
    "Principle Component Analysis.\n",
    "Feature Importance.\n",
    "Feature Selection\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested. Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression. Three benets of performing feature selection before modeling your data are:\n",
    "\n",
    "Reduces Overffitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "Reduces Training Time: Less data means that algorithms train faster.\n",
    "Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable. The scikit-learn library provides the SelectKBest class2 that can be used with a suite of different statistical tests to select a specific number of features. The example below uses the chi-squared  (𝑐ℎ𝑖2)  statistical test for non-negative features to select 4 of the best features from the Pima Indians onset of diabetes dataset.\n",
    "\n",
    "You can see the scores for each attribute and the 4 attributes chosen (those with the highest scores): plas, test, mass and age. I got the names for the chosen attributes by manually mapping the index of the 4 highest scores to the index of the attribute names.\n",
    "\n",
    "# Recursive Feature Elimination method.\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute. You can learn more about the RFE class3 in the scikit-learn documentation. The example below uses RFE with the logistic regression algorithm to select the top 3 features. The choice of algorithm does not matter too much as long as it is skillful and consistent.\n",
    "\n",
    "### NOTE: Since i dont have much information about the interpretetion of my varaibles, Recursive Feature Elimination method would be the best. \n",
    "\n",
    "# c) Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "array_1 = Train.values\n",
    "X = array_1[:,0:11]\n",
    "Y = array_1[:,11]\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 10)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features: \",  fit.n_features_)\n",
    "print(\"Selected Features:\",  fit.support_)\n",
    "print(\"Feature Ranking: \",  fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n",
    "of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate Algorithms\n",
    "\n",
    "\n",
    "## Evaluate the Performance of Machine Learning Algorithms with Resampling\n",
    "You need to know how well your algorithms perform on unseen data. The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answers. The second best way is to use clever techniques from statistics called resampling methods that allow you to make accurate estimates for how well your algorithm will perform on new data. In this chapter you will discover how you can estimate the accuracy of your machine learning algorithms using resampling methods in Python and scikit-learn on the Pima Indians dataset. Let's get started.\n",
    "\n",
    "## Evaluate Machine Learning Algorithms\n",
    "Why can't you train your machine learning algorithm on your dataset and use predictions from this same dataset to evaluate machine learning algorithms? The simple answer is overffitting. Imagine an algorithm that remembers every observation it is shown during training. If you evaluated your machine learning algorithm on the same dataset used to train the algorithm, then an algorithm like this would have a perfect score on the training dataset. But the predictions it made on new data would be terrible. We must evaluate our machine learning algorithms on data that is not used to train the algorithm. The evaluation is an estimate that we can use to talk about how well we think the algorithm may actually do in practice. It is not a guarantee of performance. Once we estimate the performance of our algorithm, we can then re-train the final algorithm on the entire training dataset and get it ready for operational use. Next up we are going to look at four different techniques that we can use to split up our training dataset and create useful estimates of performance for our machine learning algorithms:\n",
    "\n",
    "* Train and Test Sets.\n",
    "* k-fold Cross Validation.\n",
    "* Leave One Out Cross Validation.\n",
    "* Repeated Random Test-Train Splits.\n",
    "\n",
    "# a) Split-out validation dataset\n",
    "\n",
    "### Split into Train and Test Sets\n",
    "The simplest method that we can use to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. We can take our original dataset and split it into two parts. Train the algorithm on the train part, make predictions on the second part and evaluate the predictions against the expected results. The size of the split can depend on the size and species of your dataset, although it is common to use 67% of the data for training and the remaining 33% for testing. This algorithm evaluation technique is very fast. It is ideal for large datasets (millions of records) where there is strong evidence that both splits of the data are representative of the underlying problem. Because of the speed, it is useful to use this approach when the algorithm you are investigating is slow to train. A downside of this technique is that it can have a high variance. This means that di\u000b",
    "erences in the training and test dataset can result in meaningful diferences in the estimate of accuracy. In the example below we split the Pima Indians dataset into 70%/30% splits for training and test and evaluate the accuracy of a Logistic Regression model.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "Good explanation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "print(\"Accuracy: \",  (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Test options and evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation\n",
    "Cross validation is an approach that you can use to estimate the performance of a machine learning algorithm with less variance than a single train-test set split. It works by splitting the dataset into k-parts (e.g. k = 5 or k = 10). Each split of the data is called a fold. The algorithm is trained on k 1 folds with one held back and tested on the held back fold. This is repeated so that each fold of the dataset is given a chance to be the held back test set. After running cross validation you end up with k diferent performance scores that you can summarize using a mean and a standard deviation. The result is a more reliable estimate of the performance of the algorithm on new data. It is more accurate because the algorithm is trained and evaluated multiple times on different data. The choice of k must allow the size of each test partition to be large enough to be a reasonable sample of the problem, whilst allowing enough repetitions of the train-test evaluation of the algorithm to provide a fair estimate of the algorithms performance on unseen data. For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5 and 10 are common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "num_folds = 10 #number of folds to use are 10\n",
    "seed = 7 #reproducibility\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(f\"Accuracy:\", (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave One Out Cross Validation\n",
    "You can configure cross validation so that the size of the fold is 1 (k is set to the number of observations in your dataset). This variation of cross validation is called leave-one-out cross validation. The result is a large number of performance measures that can be summarized in an effort to give a more reasonable estimate of the accuracy of your model on unseen data. A downside is that it can be a computationally more expensive procedure than k-fold cross validation. In the example below we use leave-one-out cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "num_folds = 10\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=loocv)\n",
    "print(\"Accuracy:\",  (results.mean()*100.0, results.std()*100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated Random Test-Train Splits\n",
    "Another variation on k-fold cross validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation. This has the speed of using a train/test split and the reduction in variance in the estimated performance of k-fold cross validation. You can also repeat the process many more times as needed to improve the accuracy. A down side is that repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation. The example below splits the data into a 70%/30% train/test split and repeats the process 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "n_splits = 10\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Accuracy: \" , (results.mean()*100.0, results.std()*100.0))\n",
    "\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "cross_validation_report = pd.DataFrame(output)\n",
    "cross_validation_report.columns = ['CLASS']\n",
    "cross_validation_report.index.name = 'Index'\n",
    "cross_validation_report['CLASS'] = cross_validation_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "cross_validation_report.to_csv('cross_validation_report.csv')\n",
    "\n",
    "print(cross_validation_report['CLASS'].unique())\n",
    "print('False: ',cross_validation_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',cross_validation_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: What Techniques to Use When\n",
    "This section lists some tips to consider what resampling technique to use in diferent circum- stances.\n",
    "\n",
    "Generally k-fold cross validation is the gold standard for evaluating the performance of amachine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
    "Using a train/test split is good for speed when using a slow algorithm and producesperformance estimates with lower bias when using large datasets.\n",
    "Techniques like leave-one-out cross validation and repeated random splits can be usefulintermediates when trying to balance variance in the estimated performance, modeltraining speed and dataset size.\n",
    "The best advice is to experiment and find a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross validation.\n",
    "# Machine Learning Algorithm Performance Metrics\n",
    "\n",
    "The metrics that you choose to evaluate your machine learning algorithms are very important.\n",
    "Choice of metrics in\n",
    "uences how the performance of machine learning algorithms is measured\n",
    "and compared. They in\n",
    "uence how you weight the importance of different characteristics in\n",
    "the results and your ultimate choice of which algorithm to choose.\n",
    "\n",
    "## Algorithm Evaluation Metrics\n",
    "In this lesson, various different algorithm evaluation metrics are demonstrated for both classification and regression type machine learning problems. In each recipe, the dataset is downloaded\n",
    "directly from the Machine Learning repository.\n",
    "\n",
    "## Classiffication Metrics\n",
    "Classiffication problems are perhaps the most common type of machine learning problem and as such there are a myriad of metrics that can be used to evaluate predictions for these problems. In this section we will review how to use the following metrics:\n",
    "\n",
    "* Classiffication Accuracy.\n",
    "* Logarithmic Loss.\n",
    "* Area Under ROC Curve.\n",
    "* Confusion Matrix.\n",
    "* Classiffication Report.\n",
    "\n",
    "## Classiffication Accuracy\n",
    "Classiffication accuracy is the number of correct predictions made as a ratio of all predictions made. This is the most common evaluation metric for classi\f",
    "cation problems, it is also the most misused. It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case. Below is an example of calculating classiffication accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy:\", (results.mean(), results.std()))\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "classification_accuracy_report = pd.DataFrame(output)\n",
    "classification_accuracy_report.columns = ['CLASS']\n",
    "classification_accuracy_report.index.name = 'Index'\n",
    "classification_accuracy_report['CLASS'] = classification_accuracy_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "classification_accuracy_report.to_csv('classification_accuracy_report.cp.csv')\n",
    "\n",
    "print(classification_accuracy_report['CLASS'].unique())\n",
    "print('False: ',classification_accuracy_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',classification_accuracy_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "The confusion matrix is a handy presentation of the accuracy of a model with two or more classes. The table presents predictions on the x-axis and accuracy outcomes on the y-axis. The cells of the table are the number of predictions made by a machine learning algorithm. For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. Predictions for 0 that were actually 0 appear in the cell for prediction = 0 and actual = 0, whereas predictions for 0 that were actually 1 appear in the cell for prediction = 0 and actual = 1. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "confusion_matrix_report = pd.DataFrame(output)\n",
    "confusion_matrix_report.columns = ['CLASS']\n",
    "confusion_matrix_report.index.name = 'Index'\n",
    "confusion_matrix_report['CLASS'] = confusion_matrix_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "confusion_matrix_report.to_csv('confusion_matrix_report.csv')\n",
    "\n",
    "print(confusion_matrix_report['CLASS'].unique())\n",
    "print('False: ',confusion_matrix_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',confusion_matrix_report.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classiffication Report\n",
    "The scikit-learn library provides a convenience report when working on classiffication problems to give you a quick idea of the accuracy of a model using a number of measures. The classification report() function displays the precision, recall, F1-score and support for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "test_size = 0.30\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
    "random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "Classification_report = pd.DataFrame(output)\n",
    "Classification_report.columns = ['CLASS']\n",
    "Classification_report.index.name = 'Index'\n",
    "Classification_report['CLASS'] = Classification_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "Classification_report.to_csv('Classification_report.csv')\n",
    "\n",
    "print(Classification_report['CLASS'].unique())\n",
    "print('False: ',Classification_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',Classification_report.groupby('CLASS').size()[1].sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-Check Classiffication Algorithms.\n",
    "Spot-checking is a way of discovering which algorithms perform well on your machine learning problem. You cannot know which algorithms are best suited to your problem beforehand. You must trial a number of \n",
    "methods and focus attention on those that prove themselves the most promising.\n",
    "\n",
    "1. How to spot-check machine learning algorithms on a classification problem.\n",
    "2. How to spot-check two linear classification algorithms.\n",
    "3. How to spot-check four nonlinear classification algorithms.\n",
    "\n",
    "## Algorithm Spot-Checking\n",
    "You cannot know which algorithm will work best on your dataset beforehand. You must use trial and error to discover a shortlist of algorithms that do well on your problem that you can then double down on and tune further. I call this process spot-checking. The question is not: What algorithm should I use on my dataset? Instead it is: What algorithms should I spot-check on my dataset? You can guess at what algorithms might do well on your dataset, and this can be a good starting point. I recommend trying a mixture of algorithms and see what is good at picking out the structure in your data. Below are some suggestions when spot-checking algorithms on your dataset:\n",
    "\n",
    "Try a mixture of algorithm representations (e.g. instances and trees).\n",
    "\n",
    "Try a mixture of learning algorithms (e.g. di\u000b",
    "erent algorithms for learning the same type of representation).\n",
    "\n",
    "Try a mixture of modeling types (e.g. linear and nonlinear functions or parametric and nonparametric).\n",
    "\n",
    "Algorithms Overview\n",
    "We are going to take a look at six classi\f",
    "cation algorithms that you can spot-check on your dataset. Starting with two linear machine learning algorithms:\n",
    "\n",
    "Logistic Regression.\n",
    "Linear Discriminant Analysis.\n",
    "Then looking at four nonlinear machine learning algorithms:\n",
    "\n",
    "k-Nearest Neighbors.\n",
    "Naive Bayes.\n",
    "Classiffication and Regression Trees.\n",
    "Support Vector Machines.\n",
    "Linear Machine Learning Algorithms\n",
    "This section demonstrates minimal recipes for how to use two linear machine learning algorithms: logistic regression and linear discriminant analysis.\n",
    "\n",
    "Logistic Regression\n",
    "Logistic regression assumes a Gaussian distribution for the numeric input variables and can model binary classiffication problems. You can construct a logistic regression model using the LogisticRegression class.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "Great information there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "LogisticRegression = pd.DataFrame(output)\n",
    "LogisticRegression.columns = ['CLASS']\n",
    "LogisticRegression.index.name = 'Index'\n",
    "LogisticRegression['CLASS'] = LogisticRegression['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "LogisticRegression.to_csv('LogisticRegression.csv')\n",
    "\n",
    "print(LogisticRegression['CLASS'].unique())\n",
    "print('False: ',LogisticRegression.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',LogisticRegression.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis\n",
    "Linear Discriminant Analysis or LDA is a statistical technique for binary and multiclass classiffication. It too assumes a Gaussian distribution for the numerical input variables. You can construct an LDA model using the LinearDiscriminantAnalysis class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "LinearDiscriminantAnalysis = pd.DataFrame(output)\n",
    "LinearDiscriminantAnalysis.columns = ['CLASS']\n",
    "LinearDiscriminantAnalysis.index.name = 'Index'\n",
    "LinearDiscriminantAnalysis['CLASS'] = LinearDiscriminantAnalysis['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "LinearDiscriminantAnalysis.to_csv('LinearDiscriminantAnalysis.csv')\n",
    "\n",
    "print(LinearDiscriminantAnalysis['CLASS'].unique())\n",
    "print('False: ',LinearDiscriminantAnalysis.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',LinearDiscriminantAnalysis.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Machine Learning Algorithms\n",
    "This section demonstrates minimal recipes for how to use 4 nonlinear machine learning algorithms.\n",
    "\n",
    "## k-Nearest Neighbors\n",
    "The k-Nearest Neighbors algorithm (or KNN) uses a distance metric to find the k most similar instances in the training data for a new instance and takes the mean outcome of the neighbors as the prediction. You can construct a KNN model using the KNeighborsClassifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = KNeighborsClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "k_nearest = pd.DataFrame(output)\n",
    "k_nearest.columns = ['CLASS']\n",
    "k_nearest.index.name = 'Index'\n",
    "k_nearest['CLASS'] = k_nearest['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "k_nearest.to_csv('k_nearest.csv')\n",
    "\n",
    "print(k_nearest['CLASS'].unique())\n",
    "print('False: ',k_nearest.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',k_nearest.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Naive Bayes calculates the probability of each class and the conditional probability of each class given each input value. These probabilities are estimated for new data and multiplied together, assuming that they are all independent (a simple or naive assumption). When working with real-valued data, a Gaussian distribution is assumed to easily estimate the probabilities for input variables using the Gaussian Probability Density Function. You can construct a Naive Bayes model using the GaussianNB class4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = GaussianNB()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "naive_bayes = pd.DataFrame(output)\n",
    "naive_bayes.columns = ['CLASS']\n",
    "naive_bayes.index.name = 'Index'\n",
    "naive_bayes['CLASS'] = naive_bayes['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "naive_bayes.to_csv('naive_bayes_nb.csv')\n",
    "\n",
    "print(naive_bayes['CLASS'].unique())\n",
    "print('False: ',naive_bayes.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',naive_bayes.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classiffication and Regression Trees\n",
    "Classiffication and Regression Trees (CART or just decision trees) construct a binary tree from the training data. Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index). You can construct a CART model using the DecisionTreeClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "DecisionTree_report = pd.DataFrame(output)\n",
    "DecisionTree_report.columns = ['CLASS']\n",
    "DecisionTree_report.index.name = 'Index'\n",
    "DecisionTree_report['CLASS'] = DecisionTree_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "DecisionTree_report.to_csv('DecisionTree_report_dt.csv')\n",
    "\n",
    "print(DecisionTree_report['CLASS'].unique())\n",
    "print('False: ',DecisionTree_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',DecisionTree_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "Support Vector Machines (or SVM) seek a line that best separates two classes. Those data instances that are closest to the line that best separates the classes are called support vectors and in uence where the line is placed. SVM has been extended to support multiple classes. Of particular importance is the use of di\u000b",
    "erent kernel functions via the kernel parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10)\n",
    "model = SVC()\n",
    "scoring = 'acuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "finalreport1 = pd.DataFrame(output)\n",
    "finalreport1.columns = ['CLASS']\n",
    "finalreport1.index.name = 'Index'\n",
    "finalreport1['CLASS'] = finalreport1['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "finalreport1.to_csv('finalreport1_sv.csv')\n",
    "\n",
    "print(finalreport1['CLASS'].unique())\n",
    "print('False: ',finalreport1.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',finalreport1.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics\n",
    "In this section will review 3 of the most common metrics for evaluating predictions on regression\n",
    "machine learning problems:\n",
    "- Mean Absolute Error.\n",
    "- Mean Squared Error.\n",
    "- R2.\n",
    "\n",
    "## Mean Absolute Error\n",
    "The Mean Absolute Error (or MAE) is the sum of the absolute di\u000b",
    "erences between predictions\n",
    "and actual values. It gives an idea of how wrong the predictions were. The measure gives an\n",
    "idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n",
    "The example below demonstrates calculating mean absolute error on the Boston house price\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE:\",(results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error\n",
    "The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the magnitude of error. Taking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation. This is called the Root Mean Squared Error (or RMSE). The example below provides a demonstration of calculating mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Regression MSE\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "num_folds = 10\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE:\",(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric too is inverted so that the results are increasing. Remember to take the absolute value before taking the square root if you are interested in calculating the RMSE.\n",
    "\n",
    "## R2 Metric\n",
    "The R2 (or R Squared) metric provides an indication of the goodness of fit of a set of predictions to the actual values. In statistical literature this measure is called the coefficient of determination. This is a value between 0 and 1 for no-fit and perfect fit respectively. The example below provides a demonstration of calculating the mean R2 for a set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Regression R^2\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2:\",(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classiffication and Regression Trees\n",
    "Classiffication and Regression Trees (CART or just decision trees) construct a binary tree from the training data. Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index). You can construct a CART model using the DecisionTreeClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = DecisionTreeClassifier()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Compare Algorithms\n",
    "## Compare Machine Learning Algorithms\n",
    "It is important to compare the performance of multiple di\u000b",
    "erent machine learning algorithms\n",
    "consistently. In this chapter you will discover how you can create a test harness to compare\n",
    "multiple different machine learning algorithms in Python with scikit-learn. You can use this\n",
    "test harness as a template on your own machine learning problems and add more and different\n",
    "algorithms to compare. After completing this lesson you will know:\n",
    "\n",
    "1. How to formulate an experiment to directly compare machine learning algorithms.\n",
    "2. A reusable template for evaluating the performance of multiple algorithms on one dataset.\n",
    "3. How to report and visualize the results when comparing algorithm performance.\n",
    "\n",
    "\n",
    "### Choose The Best Machine Learning Model\n",
    "When you work on a machine learning project, you often end up with multiple good models\n",
    "to choose from. Each model will have different performance characteristics. Using resampling\n",
    "methods like cross validation, you can get an estimate for how accurate each model may be on\n",
    "unseen data. You need to be able to use these estimates to choose one or two best models from\n",
    "the suite of models that you have created.\n",
    "When you have a new dataset, it is a good idea to visualize the data using different techniques\n",
    "in order to look at the data from di\u000b",
    "erent perspectives. The same idea applies to model selection.\n",
    "You should use a number of di\u000b",
    "erent ways of looking at the estimated accuracy of your machine\n",
    "learning algorithms in order to choose the one or two algorithm to finalize. A way to do this is\n",
    "to use visualization methods to show the average accuracy, variance and other properties of the\n",
    "distribution of model accuracies. In the next section you will discover exactly how you can do\n",
    "that in Python with scikit-learn.\n",
    "\n",
    "\n",
    "### Compare Machine Learning Algorithms Consistently\n",
    "The key to a fair comparison of machine learning algorithms is ensuring that each algorithm is\n",
    "evaluated in the same way on the same data. You can achieve this by forcing each algorithm to be evaluated on a consistent test harness. In the example below six different classiffication\n",
    "algorithms are compared on a single dataset:\n",
    "\n",
    "- Logistic Regression.\n",
    "- Linear Discriminant Analysis.\n",
    "- k-Nearest Neighbors.\n",
    "- Classiffication and Regression Trees.\n",
    "- Naive Bayes.\n",
    "- Support Vector Machines.\n",
    "\n",
    "The dataset is the Pima Indians onset of diabetes problem. The problem has two classes and\n",
    "eight numeric input variables of varying scales. The 10-fold cross validation procedure is used to\n",
    "evaluate each algorithm, importantly con\f",
    "gured with the same random seed to ensure that the\n",
    "same splits to the training data are performed and that each algorithm is evaluated in precisely\n",
    "the same way. Each algorithm is given a short name, useful for summarizing results afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# load dataset\n",
    "array = Train.values\n",
    "\n",
    "#split the dataset \n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "# prepare models and add them to a list\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "compare_testmethods_report = pd.DataFrame(output)\n",
    "compare_testmethods_report.columns = ['CLASS']\n",
    "compare_testmethods_report.index.name = 'Index'\n",
    "compare_testmethods_report['CLASS'] = compare_testmethods_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "compare_testmethods_report.to_csv('compare_testmethods_report.csv')\n",
    "\n",
    "print(compare_testmethods_report['CLASS'].unique())\n",
    "print('False: ',compare_testmethods_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',compare_testmethods_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate Machine Learning Workflows with Pipelines\n",
    "\n",
    "There are standard work\n",
    "ows in a machine learning project that can be automated. In Python\n",
    "scikit-learn, Pipelines help to clearly define and automate these work\n",
    "ows. In this chapter you\n",
    "will discover Pipelines in scikit-learn and how you can automate common machine learning\n",
    "work\n",
    "ows. After completing this lesson you will know:\n",
    "\n",
    "1. How to use pipelines to minimize data leakage.\n",
    "2. How to construct a data preparation and modeling pipeline.\n",
    "3. How to construct a feature extraction and modeling pipeline.\n",
    "\n",
    "### Automating Machine Learning Workflows\n",
    "There are standard work\n",
    "ows in applied machine learning. Standard because they overcome\n",
    "common problems like data leakage in your test harness. Python scikit-learn provides a Pipeline\n",
    "utility to help automate machine learning work\n",
    "ows. Pipelines work by allowing for a linear\n",
    "sequence of data transforms to be chained together culminating in a modeling process that can\n",
    "be evaluated.\n",
    "\n",
    "The goal is to ensure that all of the steps in the pipeline are constrained to the data available\n",
    "for the evaluation, such as the training dataset or each fold of the cross validation procedure.\n",
    "You can learn more about Pipelines in scikit-learn by reading the Pipeline section1 of the user\n",
    "guide. You can also review the API documentation for the Pipeline and FeatureUnion classes\n",
    "and the pipeline module2.\n",
    "\n",
    "### Data Preparation and Modeling Pipeline\n",
    "An easy trap to fall into in applied machine learning is leaking data from your training dataset\n",
    "to your test dataset. To avoid this trap you need a robust test harness with strong separation of training and testing. This includes data preparation. Data preparation is one easy way to leak\n",
    "knowledge of the whole training dataset to the algorithm. For example, preparing your data\n",
    "using normalization or standardization on the entire training dataset before learning would not\n",
    "be a valid test because the training dataset would have been in\n",
    "uenced by the scale of the data\n",
    "in the test set.\n",
    "\n",
    "\n",
    "Pipelines help you prevent data leakage in your test harness by ensuring that data preparation\n",
    "like standardization is constrained to each fold of your cross validation procedure. The example\n",
    "below demonstrates this important data preparation and model evaluation work\n",
    "ow on the\n",
    "Pima Indians onset of diabetes dataset. The pipeline is de\f",
    "ned with two steps:\n",
    "\n",
    "1. Standardize the data.\n",
    "2. Learn a Linear Discriminant Analysis model.\n",
    "\n",
    "The pipeline is then evaluated using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that standardizes the data then creates a model\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# load data\n",
    "\n",
    "#dataframe = read_csv('diabetes.csv')\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "standarzied_pipeline_report = pd.DataFrame(output)\n",
    "standarzied_pipeline_report.columns = ['CLASS']\n",
    "standarzied_pipeline_report.index.name = 'Index'\n",
    "standarzied_pipeline_report['CLASS'] = standarzied_pipeline_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "standarzied_pipeline_report.to_csv('standarzied_pipeline_report.csv')\n",
    "\n",
    "print(standarzied_pipeline_report['CLASS'].unique())\n",
    "print('False: ',standarzied_pipeline_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',standarzied_pipeline_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Improve Accuracy\n",
    "# a) Algorithm Tuning\n",
    "# b) Ensembles\n",
    "\n",
    "# Improve Performance with Ensembles\n",
    "\n",
    "Ensembles can give you a boost in accuracy on your dataset. In this chapter you will discover\n",
    "how you can create some of the most powerful types of ensembles in Python using scikit-learn.\n",
    "This lesson will step you through Boosting, Bagging and Majority Voting and show you how you\n",
    "can continue to ratchet up the accuracy of the models on your own datasets. After completing\n",
    "this lesson you will know:\n",
    "\n",
    "1. How to use bagging ensemble methods such as bagged decision trees, random forest and extra trees.\n",
    "2. How to use boosting ensemble methods such as AdaBoost and stochastic gradient boosting.\n",
    "3. How to use voting ensemble methods to combine the predictions from multiple algorithms.\n",
    "\n",
    "### Combine Models Into Ensemble Predictions\n",
    "The three most popular methods for combining the predictions from different models are:\n",
    "\n",
    "- Bagging. Building multiple models (typically of the same type) from different subsamples of the training dataset.\n",
    "- Boosting. Building multiple models (typically of the same type) each of which learns to fix the prediction errors of a prior model in the sequence of models.\n",
    "- Voting. Building multiple models (typically of di\u000b",
    "ering types) and simple statistics (like calculating the mean) are used to combine predictions.\n",
    "\n",
    "This assumes you are generally familiar with machine learning algorithms and ensemble\n",
    "methods and will not go into the details of how the algorithms work or their parameters.\n",
    "The Pima Indians onset of Diabetes dataset is used to demonstrate each algorithm. Each\n",
    "ensemble algorithm is demonstrated using 10-fold cross validation and the classiffication accuracy\n",
    "performance metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Algorithms\n",
    "Boosting ensemble algorithms creates a sequence of models that attempt to correct the mistakes\n",
    "of the models before them in the sequence. Once created, the models make predictions which\n",
    "may be weighted by their demonstrated accuracy and the results are combined to create a final\n",
    "output prediction. The two most common boosting ensemble machine learning algorithms are:\n",
    "\n",
    "- AdaBoost.\n",
    "- Stochastic Gradient Boosting.\n",
    "\n",
    "\n",
    "### AdaBoost\n",
    "AdaBoost was perhaps the \f",
    "rst successful boosting ensemble algorithm. It generally works\n",
    "by weighting instances in the dataset by how easy or di\u000ecult they are to classify, allowing\n",
    "the algorithm to pay or less attention to them in the construction of subsequent models. You\n",
    "can construct an AdaBoost model for classi\f",
    "cation using the AdaBoostClassifier class4. The\n",
    "example below demonstrates the construction of 30 decision trees in sequence using the AdaBoost\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "array = Train.values\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "num_trees = 30\n",
    "seed=7\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "AdaBoost_report = pd.DataFrame(output)\n",
    "AdaBoost_report.columns = ['CLASS']\n",
    "AdaBoost_report.index.name = 'Index'\n",
    "AdaBoost_report['CLASS'] = AdaBoost_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "AdaBoost_report.to_csv('AdaBoost_report.csv')\n",
    "\n",
    "print(AdaBoost_report['CLASS'].unique())\n",
    "print('False: ',AdaBoost_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',AdaBoost_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting\n",
    "Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most\n",
    "sophisticated ensemble techniques. It is also a technique that is proving to be perhaps one of\n",
    "the best techniques available for improving performance via ensembles. You can construct a\n",
    "Gradient Boosting model for classiffication using the GradientBoostingClassifier class5. The\n",
    "example below demonstrates Stochastic Gradient Boosting for classification with 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Boosting Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "array = Train.values\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic X Gradient Boosting Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "array = Train.values\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "model = XGBClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Ensemble\n",
    "Voting is one of the simplest ways of combining the predictions from multiple machine learning\n",
    "algorithms. It works by first creating two or more standalone models from your training dataset.\n",
    "A Voting Classiffier can then be used to wrap your models and average the predictions of the\n",
    "sub-models when asked to make predictions for new data. The predictions of the sub-models can\n",
    "be weighted, but specifying the weights for classiffiers manually or even heuristically is difficult.\n",
    "More advanced methods can learn how to best weight the predictions from sub-models, but this\n",
    "is called stacking (stacked aggregation) and is currently not provided in scikit-learn.\n",
    "You can create a voting ensemble model for classiffication using the VotingClassifier\n",
    "class6. The code below provides an example of combining the predictions of logistic regression,\n",
    "classiffication and regression trees and support vector machines together for a classiffication\n",
    "problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Ensemble for Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "\n",
    "array = Train.values\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "model4 = XGBClassifier()\n",
    "estimators.append(('xgb', model4))\n",
    "\n",
    "model5 = RandomForestClassifier()\n",
    "estimators.append(('rfc', model5))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "Voting_Ensemble_report = pd.DataFrame(output)\n",
    "Voting_Ensemble_report.columns = ['CLASS']\n",
    "Voting_Ensemble_report.index.name = 'Index'\n",
    "Voting_Ensemble_report['CLASS'] = Voting_Ensemble_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "Voting_Ensemble_report.to_csv('Voting_Ensemble_report.csv')\n",
    "\n",
    "print(Voting_Ensemble_report['CLASS'].unique())\n",
    "print('False: ',Voting_Ensemble_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',Voting_Ensemble_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees\n",
    "Extra Trees are another modi\f",
    "cation of bagging where random trees are constructed from\n",
    "samples of the training dataset. You can construct an Extra Trees model for classiffication using\n",
    "the ExtraTreesClassifier class3. The example below provides a demonstration of extra trees\n",
    "with the number of trees set to 100 and splits chosen from 7 random features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#let's read the data\n",
    "\n",
    "array = Train.values\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "num_trees = 100\n",
    "max_features = 7\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "Extra_tree_report = pd.DataFrame(output)\n",
    "Extra_tree_report.columns = ['CLASS']\n",
    "Extra_tree_report.index.name = 'Index'\n",
    "Extra_tree_report['CLASS'] = Extra_tree_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "Extra_tree_report.to_csv('Extra_tree_report.csv')\n",
    "\n",
    "print(Extra_tree_report.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting\n",
    "Stochastic Gradient Boosting (also called Gradient Boosting Machines) are one of the most\n",
    "sophisticated ensemble techniques. It is also a technique that is proving to be perhaps one of\n",
    "the best techniques available for improving performance via ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Boosting Classification\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "array = Train.values\n",
    "\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "Stochastic_report = pd.DataFrame(output)\n",
    "Stochastic_report.columns = ['CLASS']\n",
    "Stochastic_report.index.name = 'Index'\n",
    "Stochastic_report['CLASS'] = Stochastic_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "Stochastic_report.to_csv('Stochastic_report.csv')\n",
    "\n",
    "print(Stochastic_report.groupby('CLASS').size()[1].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Your Model with pickle\n",
    "Pickle is the standard way of serializing objects in Python. You can use the pickle1 operation\n",
    "to serialize your machine learning algorithms and save the serialized format to a file. Later you\n",
    "can load this file to deserialize your model and use it to make new predictions. The example\n",
    "below demonstrates how you can train a logistic regression model on data set and save the model to file and load it to make predictions on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using Pickle\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=7)\n",
    "# Fit the model on 30%\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model2.sav'\n",
    "dump(model, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "pickle_report = pd.DataFrame(output)\n",
    "pickle_report.columns = ['CLASS']\n",
    "pickle_report.index.name = 'Index'\n",
    "pickle_report['CLASS'] = pickle_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "pickle_report.to_csv('pickle.csv')\n",
    "\n",
    "print(pickle_report['CLASS'].unique())\n",
    "print('False: ',pickle_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',pickle_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize Your Model with Joblib\n",
    "The Joblib2 library is part of the SciPy ecosystem and provides utilities for pipelining Python\n",
    "jobs. It provides utilities for saving and loading Python objects that make use of NumPy data\n",
    "structures, efficiently3. This can be useful for some machine learning algorithms that require a\n",
    "lot of parameters or store the entire dataset (e.g. k-Nearest Neighbors). The example below\n",
    "demonstrates how you can train a logistic regression model on the dataset, save the model to file using Joblib and load it to make predictions on the unseen test\n",
    "set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using joblib\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.externals.joblib import dump\n",
    "from sklearn.externals.joblib import load\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "array = Train.values\n",
    "X = array[:,0:11]\n",
    "Y = array[:,11]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=7)\n",
    "\n",
    "# Fit the model on 30%\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# save the model to disk\n",
    "\n",
    "dump(model, filename)\n",
    "\n",
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n",
    "\n",
    "\n",
    "test_set = Test.values\n",
    "model.fit(X, Y)\n",
    "output = model.predict(test_set)\n",
    "\n",
    "mcc = matthews_corrcoef(model.predict(X), Y)\n",
    "print('MCC: ',mcc)\n",
    "\n",
    "joblib_report = pd.DataFrame(output)\n",
    "joblib_report.columns = ['CLASS']\n",
    "joblib_report.index.name = 'Index'\n",
    "picklej_report['CLASS'] = pickle_report['CLASS'].map({0.0:False, 1.0:True})\n",
    "\n",
    "pickle_report.to_csv('pickle.csv')\n",
    "\n",
    "print(pickle_report['CLASS'].unique())\n",
    "print('False: ',pickle_report.groupby('CLASS').size()[0].sum())\n",
    "print('True: ',pickle_report.groupby('CLASS').size()[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
