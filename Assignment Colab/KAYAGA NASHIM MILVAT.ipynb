{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References\n#### https://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/\n#### https://www.dataquest.io/blog/top-10-machine-learning-algorithms-for-beginners/\n#### https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/\n#### https://towardsdatascience.com/understanding-random-forest-58381e0602d2"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/ace-class-assignment/Test.csv\")\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#read in the data\ndata = pd.read_csv(\"../input/ace-class-assignment/AMP_TrainSet.csv\")\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Analyze data by describing\n\n#### This step helped me know which features are in my dataset, are they categorical or numerical.\n#### How many rows and columns does the dataset have\n#### The data types for the various features\n#### Checked whether the dataset has null or missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check the dimensions to the number of rows and columns\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Generate descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution, excluding NaN values\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of null values in each column\ndata.isnull().sum()\n#since my data has no null values then its good to go","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"#### needed to know how balanced the class values are"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata.groupby('CLASS').size().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Its a good idea to review all the pairwise correlations of the attributes in the dataset because some machine learning algorithm like linear and logistic regression can suffer poor performance if there are highly correlated attributes in the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr(method='pearson')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####  heat map to show the correlation of the data; plots that show the interactions between multiple variables in the dataset\n#### Correlation gives an indication of how related the changes are between two variables. If two variables change in the same direction they are positively correlated. If they change in opposite directions together (one goes up, one goes down), then they are negatively correlated. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.heatmap(data.corr(method='pearson'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### also checked the corelation in regards to the class since am trying to build a ML agorithm for that class"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata.corr(method='pearson')['CLASS']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most of my variables are positively skewed"},{"metadata":{"trusted":true},"cell_type":"code","source":" data.skew().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## understanding data with visualization\n#### Data can be visualised in many ways that is univariate plots and multivariate plots             #### Used the Histogram for univariate plot as shown below and the correlation matrix plot as the multivariate plot as shown above"},{"metadata":{},"cell_type":"markdown","source":"## Histogram\n#### This helps to understand each attribute of my dataset independently"},{"metadata":{},"cell_type":"markdown","source":"## Data pre-processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,18))\ndata.hist()\nplt.subplots_adjust(bottom=3, right=2, top=5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Standardize data\n#### Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\narray = data.values\n#separate array into input and output components\nX = array[:,0:11]\nY = array[:,11]\nscaler = StandardScaler().fit(X)\nrescaledX = scaler.transform(X)\n# summarize transformed data\n#set_printoptions(precision=3)\nprint(rescaledX[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array = test.values\nscaler = StandardScaler().fit(array)\nrescaledt = scaler.transform(array)\n# summarize transformed data\n#set_printoptions(precision=3)\nprint(rescaledt[0:5,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Feature selection\n\n"},{"metadata":{},"cell_type":"markdown","source":"####  it's the process of selecting a subset of relevant features for use in model construction"},{"metadata":{},"cell_type":"markdown","source":"### Chose Recursive Feature Elimination\n#### This is an automatic feature selection technique\n#### Used logistic regression it is a good baseline as it is fast to train and predict and scales well.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n\narray = data.values\nX = array[:,0:11]\nY = array[:,11]\n# feature extraction\nmodel = LogisticRegression()\nrfe = RFE(model,8)\nfit = rfe.fit(X,Y)\nprint(\"Num Features:\", fit.n_features_)\nprint(\"Selected Features:\", fit.support_)\nprint(\"Feature Ranking:\", fit.ranking_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[:,fit.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop=data.drop(['FULL_AcidicMolPerc', 'FULL_DAYM780201', 'AS_DAYM780201'],axis=1)\ndrop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_test = test.drop(['FULL_AcidicMolPerc', 'FULL_DAYM780201', 'AS_DAYM780201'],axis=1)\ndrop_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. #### Decided to first use all the  first\n"},{"metadata":{},"cell_type":"markdown","source":"# Evaluate the Performance of Machine Learning Algorithms with Resampling¶\n"},{"metadata":{},"cell_type":"markdown","source":"#### The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answers."},{"metadata":{},"cell_type":"markdown","source":"## Split into Train and Test Sets"},{"metadata":{},"cell_type":"markdown","source":"#### This algorithm evaluation technique is very fast. It is ideal for large datasets where there is strong evidence that both splits of the data are representative of the underlying problem. Because of the speed, it is useful to use this approach when the algorithm you are investigating is slow to train.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\narray = data.values\nX = array[:,0:11]\nY = array[:,11]\ntest_size = 0.30\nseed = 7\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\nrandom_state=seed)\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\nresult = model.score(X_test, Y_test)\nprint(\"Accuracy: \",  (result*100.0))\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport = pd.DataFrame(output)\nreport.columns = ['CLASS']\nreport.index.name = \"Index\"\nreport['CLASS']=report['CLASS'].map({0.0:False, 1.0:True})\nreport.to_csv(\"report.csv\")\n\nprint(report['CLASS'].unique())\nprint('False: ',report.groupby('CLASS').size()[0].sum())\nprint('True: ',report.groupby('CLASS').size()[1].sum())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K-fold Cross Validation"},{"metadata":{},"cell_type":"markdown","source":"#### It is more accurate because the algorithm is trained and evaluated multiple times on different data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\nnum_folds = 10 #number of folds to use\nseed = 7 #reproducibility\n\nkfold = KFold(n_splits=num_folds, random_state=seed)\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=kfold)\n\nprint(f\"Accuracy:\", (results.mean()*100.0, results.std()*100.0))\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_kf = pd.DataFrame(output)\nreport_kf.columns = ['CLASS']\nreport_kf.index.name = \"Index\"\nreport_kf['CLASS']=report_kf['CLASS'].map({0.0:False, 1.0:True})\nreport_kf.to_csv(\"report_kf.csv\")\n\nprint(report_kf['CLASS'].unique())\nprint('False: ',report_kf.groupby('CLASS').size()[0].sum())\nprint('True: ',report_kf.groupby('CLASS').size()[1].sum())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Leave One Out Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import cross_val_score\n\nnum_folds = 10\nloocv = LeaveOneOut()\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=loocv)\nprint(\"Accuracy:\",  (results.mean()*100.0, results.std()*100.0))\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_l = pd.DataFrame(output)\nreport_l.columns = ['CLASS']\nreport_l.index.name = \"Index\"\nreport_l['CLASS']=report_l['CLASS'].map({0.0:False, 1.0:True})\nreport_l.to_csv(\"report_l.csv\")\n\nprint(report_l['CLASS'].unique())\nprint('False: ',report_l.groupby('CLASS').size()[0].sum())\nprint('True: ',report_l.groupby('CLASS').size()[1].sum())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Repeated Random Test-Train Splits"},{"metadata":{},"cell_type":"markdown","source":"#### Creates a random split of the data like the train/test split , but repeats the process of splitting and evaluation of the algorithm multiple times, like cross validation. Repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size\n#### In this I prefered using Repeated Random Test_Train Splits because when you look at the dataset the zeros are one side and the ones on the otherside in the 'class' column. So I would prefer to first shuffle the data and then split it to reduce on the bias"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\nn_splits = 10\ntest_size = 0.30\nseed = 7\nkfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(\"Accuracy: \" , (results.mean()*100.0, results.std()*100.0))\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_rrt = pd.DataFrame(output)\nreport_rrt.columns = ['CLASS']\nreport_rrt.index.name = \"Index\"\nreport_rrt['CLASS']=report_rrt['CLASS'].map({0.0:False, 1.0:True})\nreport_rrt.to_csv(\"report_rrt.csv\")\n\nprint(report_rrt['CLASS'].unique())\nprint('False: ',report_rrt.groupby('CLASS').size()[0].sum())\nprint('True: ',report_rrt.groupby('CLASS').size()[1].sum())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Algorithm Performance Metrics"},{"metadata":{},"cell_type":"markdown","source":"## Algorithms Overview\n### linear machine learning algorithms:\n\n    Logistic Regression.\n    Linear Discriminant Analysis.\n### onlinear machine learning algorithms\n\n    k-Nearest Neighbors.\n    Naive Bayes.\n    Classication and Regression Trees.\n    Support Vector Machines.\n"},{"metadata":{},"cell_type":"markdown","source":"## Linear Machine Learning Algorithms"},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{},"cell_type":"markdown","source":"#### Logistic regression is best suited for binary classification: data sets where y = 0 or 1"},{"metadata":{},"cell_type":"markdown","source":"### Using standardized data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic regression on standardized data\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\nmodel.fit(rescaledX,Y)\noutput = model.predict(rescaledt)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_scaled = pd.DataFrame(output)\nreport_scaled.columns = ['CLASS']\nreport_scaled.index.name = \"Index\"\nreport_scaled['CLASS']=report_scaled['CLASS'].map({0.0:False, 1.0:True})\nreport_scaled.to_csv(\"report_scaled.csv\")\n\nprint(report_scaled['CLASS'].unique())\nprint('False: ',report_scaled.groupby('CLASS').size()[0].sum())\nprint('True: ',report_scaled.groupby('CLASS').size()[1].sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression Classification\n\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = LogisticRegression()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nmy_report = pd.DataFrame(output)\nmy_report.columns = ['CLASS']\nmy_report.index.name = \"Index\"\nmy_report['CLASS']=my_report['CLASS'].map({0.0:False, 1.0:True})\nmy_report.to_csv(\"report_XGB.csv\")\n\nprint(my_report['CLASS'].unique())\nprint('False: ',my_report.groupby('CLASS').size()[0].sum())\nprint('True: ',my_report.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Linear Discriminant Analysis¶\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = LinearDiscriminantAnalysis()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nlda_report = pd.DataFrame(output)\nlda_report.columns = ['CLASS']\nlda_report.index.name = \"Index\"\nlda_report['CLASS']=lda_report['CLASS'].map({0.0:False, 1.0:True})\nlda_report.to_csv(\"ldareport.csv\")\n\nprint(lda_report['CLASS'].unique())\nprint('False: ',lda_report.groupby('CLASS').size()[0].sum())\nprint('True: ',lda_report.groupby('CLASS').size()[1].sum())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Nonlinear Machine Learning Algorithms"},{"metadata":{},"cell_type":"markdown","source":"### k-Nearest Neighbors"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nnum_folds = 10\nkfold = KFold(n_splits=10, random_state=7)\nmodel = KNeighborsClassifier()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_k = pd.DataFrame(output)\nreport_k.columns = ['CLASS']\nreport_k.index.name = \"Index\"\nreport_k['CLASS']=report_k['CLASS'].map({0.0:False, 1.0:True})\nreport_k.to_csv(\"report_k.csv\")\n\n\nprint(report_k['CLASS'].unique())\nprint('False: ',report_k.groupby('CLASS').size()[0].sum())\nprint('True: ',report_k.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes"},{"metadata":{},"cell_type":"markdown","source":"### Tried using Standardised data on Naive Bayes\n\n### When I predicted Naive Bayes on Standardised data gave me a score of 0.98235, after feature selection it gave 0.90 and on unstandardised data it gave a score of 0.9959"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes on standardised data\nfrom sklearn.naive_bayes import GaussianNB\n\nkfold = KFold(n_splits=10, random_state=7)\nmodel = GaussianNB()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\n\nmodel.fit(rescaledX,Y)\noutput = model.predict(rescaledt)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_rebayes = pd.DataFrame(output)\nreport_rebayes.columns = ['CLASS']\nreport_rebayes.index.name = \"Index\"\nreport_rebayes['CLASS']=report_rebayes['CLASS'].map({0.0:False, 1.0:True})\nreport_rebayes.to_csv(\"report_rebayes.csv\")\n\n\nprint(report_rebayes['CLASS'].unique())\nprint('False: ',report_rebayes.groupby('CLASS').size()[0].sum())\nprint('True: ',report_rebayes.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Naive Bayes on selected features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naive Bayes on selected features\n\narray = data.values\nX = array[:,0:11]\nY = array[:,11]\n\nselectedX = X[:,fit.support_]\n\narray2 =test.values\nselectedT = array2[:,fit.support_]\n\nkfold = KFold(n_splits=10, random_state=7)\nmodel = GaussianNB()\nresults = cross_val_score(model, selectedX, Y, cv=kfold)\nprint(results.mean())\n\n\nmodel.fit(selectedX,Y)\noutput = model.predict(selectedT)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(selectedX),Y)\nprint('MCC:',mcc)\n                       \nreport_sel = pd.DataFrame(output)\nreport_sel.columns = ['CLASS']\nreport_sel.index.name = \"Index\"\nreport_sel['CLASS']=report_sel['CLASS'].map({0.0:False, 1.0:True})\nreport_sel.to_csv(\"report_sel.csv\")\n\n\nprint(report_sel['CLASS'].unique())\nprint('False: ',report_sel.groupby('CLASS').size()[0].sum())\nprint('True: ',report_sel.groupby('CLASS').size()[1].sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nkfold = KFold(n_splits=10, random_state=7)\nmodel = GaussianNB()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_bayes = pd.DataFrame(output)\nreport_bayes.columns = ['CLASS']\nreport_bayes.index.name = \"Index\"\nreport_bayes['CLASS']=report_bayes['CLASS'].map({0.0:False, 1.0:True})\nreport_bayes.to_csv(\"report_bayes.csv\")\n\n\nprint(report_bayes['CLASS'].unique())\nprint('False: ',report_bayes.groupby('CLASS').size()[0].sum())\nprint('True: ',report_bayes.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Classiffication and Regression Trees"},{"metadata":{},"cell_type":"markdown","source":"#### used for classification or regression predictive modeling problems"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nkfold = KFold(n_splits=10, random_state=7)\nmodel = DecisionTreeClassifier()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_tree = pd.DataFrame(output)\nreport_tree.columns = ['CLASS']\nreport_tree.index.name = \"Index\"\nreport_tree['CLASS']=report_tree['CLASS'].map({0.0:False, 1.0:True})\nreport_tree.to_csv(\"report_tree.csv\")\n\n\nprint(report_tree['CLASS'].unique())\nprint('False: ',report_tree.groupby('CLASS').size()[0].sum())\nprint('True: ',report_tree.groupby('CLASS').size()[1].sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Machines "},{"metadata":{},"cell_type":"markdown","source":"#### A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nkfold = KFold(n_splits=10, random_state=7)\nmodel = SVC()\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_svm = pd.DataFrame(output)\nreport_svm.columns = ['CLASS']\nreport_svm.index.name = \"Index\"\nreport_svm['CLASS']=report_svm['CLASS'].map({0.0:False, 1.0:True})\nreport_svm.to_csv(\"report_svm.csv\")\n\n\nprint(report_svm['CLASS'].unique())\nprint('False: ',report_svm.groupby('CLASS').size()[0].sum())\nprint('True: ',report_svm.groupby('CLASS').size()[1].sum())\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Combine Models Into Ensemble Predictions\n\nThe three most popular methods for combining the predictions from different models are:\n   \n   Bagging\n   Boosting\n   Voting"},{"metadata":{},"cell_type":"markdown","source":"> # BoostingAlgorithms"},{"metadata":{},"cell_type":"markdown","source":"####  These seek to improve the prediction power by training a sequence of weak models, each compensating the weaknesses of its predecessors.\n"},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost"},{"metadata":{},"cell_type":"markdown","source":"#### This is specifically designed for classification problems"},{"metadata":{"trusted":true},"cell_type":"code","source":"# AdaBoost Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\nX = array[:,0:11]\nY = array[:,11]\n\nnum_trees = 39\nseed=10\n\nkfold = KFold(n_splits=10, random_state=seed)\n\nmodel = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\n\nprint(results.mean())\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_ada = pd.DataFrame(output)\nreport_ada.columns = ['CLASS']\nreport_ada.index.name = \"Index\"\nreport_ada['CLASS']=report_ada['CLASS'].map({0.0:False, 1.0:True})\nreport_ada.to_csv(\"report_ada.csv\")\n\n\nprint(report_ada['CLASS'].unique())\nprint('False: ',report_ada.groupby('CLASS').size()[0].sum())\nprint('True: ',report_ada.groupby('CLASS').size()[1].sum())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bagging Algorithms"},{"metadata":{},"cell_type":"markdown","source":"#### Bagging is used with decision trees where it significantly raises the stability of models in the reduction of variance and improving accuracy, which eliminates the challenge of overfitting."},{"metadata":{},"cell_type":"markdown","source":"## Bagged Decision Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bagged Decision Trees for Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n#split the data in portions\nX = array[:,0:11]\nY = array[:,11]\nseed = 7 #duplication\n\n#split according to cross validation\nkfold = KFold(n_splits=10, random_state=seed)\n\n#initialize the model\ncart = DecisionTreeClassifier()\n\n#bagging\nnum_trees = 250\n\n#model\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_bag = pd.DataFrame(output)\nreport_bag.columns = ['CLASS']\nreport_bag.index.name = \"Index\"\nreport_bag['CLASS']=report_bag['CLASS'].map({0.0:False, 1.0:True})\nreport_bag.to_csv(\"report_bag.csv\")\n\n\nprint(report_bag['CLASS'].unique())\nprint('False: ',report_bag.groupby('CLASS').size()[0].sum())\nprint('True: ',report_bag.groupby('CLASS').size()[1].sum())\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random Forest Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nX = array[:,0:11]\nY = array[:,11]\n\nnum_trees = 1000\n\nmax_features = 3\n\nkfold = KFold(n_splits=10, random_state=7)\nmodel = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_rf = pd.DataFrame(output)\nreport_rf.columns = ['CLASS']\nreport_rf.index.name = \"Index\"\nreport_rf['CLASS']=report_rf['CLASS'].map({0.0:False, 1.0:True})\nreport_rf.to_csv(\"report_rf.csv\")\n\n\nprint(report_rf['CLASS'].unique())\nprint('False: ',report_rf.groupby('CLASS').size()[0].sum())\nprint('True: ',report_rf.groupby('CLASS').size()[1].sum())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## Extra Trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\n\nX = array[:,0:11]\nY = array[:,11]\n\nnum_trees = 100\nmax_features = 7\n\nkfold = KFold(n_splits=10, random_state=7)\n\nmodel = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\n\nresults = cross_val_score(model, X, Y, cv=kfold)\n\nprint(results.mean())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Voting Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Voting Ensemble for Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\n\n\nX = array[:,0:11]\nY = array[:,11]\nkfold = KFold(n_splits=10, random_state=7)\n\n# create the sub models\nestimators = []\nmodel1 = LogisticRegression()\nestimators.append(('logistic', model1))\n\nmodel2 = DecisionTreeClassifier()\nestimators.append(('cart', model2))\n\nmodel3 = SVC()\nestimators.append(('svm', model3))\n\nmodel4 = XGBClassifier()\nestimators.append(('xgb', model4))\n\nmodel5 = RandomForestClassifier()\nestimators.append(('rfc', model5))\n\n# create the ensemble model\nensemble = VotingClassifier(estimators)\nresults = cross_val_score(ensemble, X, Y, cv=kfold)\nprint(results.mean())\n\n\nmodel.fit(X,Y)\noutput = model.predict(test.values)\n\nfrom sklearn.metrics import matthews_corrcoef\nmcc = matthews_corrcoef(model.predict(X),Y)\nprint('MCC:',mcc)\n                       \nreport_v = pd.DataFrame(output)\nreport_v.columns = ['CLASS']\nreport_v.index.name = \"Index\"\nreport_v['CLASS']=report_v['CLASS'].map({0.0:False, 1.0:True})\nreport_v.to_csv(\"report_v.csv\")\n\n\nprint(report_v['CLASS'].unique())\nprint('False: ',report_v.groupby('CLASS').size()[0].sum())\nprint('True: ',report_v.groupby('CLASS').size()[1].sum())\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## comparing the algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# prepare models and add them to a list\nfrom matplotlib import pyplot\n\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\nmodels.append(('ETC', ExtraTreesClassifier()))\nmodels.append(('RFC', RandomForestClassifier()))\n\n# evaluate each model in turn\nresults = []\nnames = []\nscoring = 'accuracy'\n\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=7)\n    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = (name, cv_results.mean(), cv_results.std())\n    print(msg)\n\n# boxplot algorithm comparison\nfig = pyplot.figure()\nfig.suptitle('Algorithm Comparison')\nax = fig.add_subplot(111)\npyplot.boxplot(results)\nax.set_xticklabels(names)\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# '''''''''''''''''''''''''''''''END''''''''''''''''''''''''''''''"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}